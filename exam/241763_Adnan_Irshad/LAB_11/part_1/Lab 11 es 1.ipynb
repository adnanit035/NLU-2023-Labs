{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af16c9b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T19:14:20.408463600Z",
     "start_time": "2023-07-17T19:14:18.772462600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package subjectivity to\n",
      "[nltk_data]     C:\\Users\\adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package subjectivity is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downloading data\n",
    "import nltk\n",
    "nltk.download('subjectivity')\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "460c89a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T19:14:23.706463700Z",
     "start_time": "2023-07-17T19:14:20.396462800Z"
    }
   },
   "outputs": [],
   "source": [
    "# all imports\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec38f713",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T19:14:23.874463100Z",
     "start_time": "2023-07-17T19:14:23.709461700Z"
    }
   },
   "outputs": [],
   "source": [
    "# get all sents and associate to them their subjectivity\n",
    "all_sents = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')] + \\\n",
    "            [(sent, 'obj') for sent in subjectivity.sents(categories='obj')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4020391",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T19:14:23.890463500Z",
     "start_time": "2023-07-17T19:14:23.883466200Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert sentences into string\n",
    "sentences = [' '.join(sent) for (sent, label) in all_sents]\n",
    "\n",
    "# defining labels\n",
    "labels = [1 if label == 'subj' else 0 for (sent, label) in all_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea4804df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T19:14:23.906462Z",
     "start_time": "2023-07-17T19:14:23.890463500Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb535a39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T19:14:24.252463400Z",
     "start_time": "2023-07-17T19:14:23.904461700Z"
    }
   },
   "outputs": [],
   "source": [
    "train_features = vectorizer.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "227a52ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T19:14:24.260461300Z",
     "start_time": "2023-07-17T19:14:24.249462100Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# defining the MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f74cb96d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T19:14:24.278461400Z",
     "start_time": "2023-07-17T19:14:24.262464800Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_features, train_labels, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(train_features)\n",
    "        loss = criterion(outputs, train_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if(epoch + 1) % 10 == 0:\n",
    "             print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7325fd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T19:15:01.404463100Z",
     "start_time": "2023-07-17T19:14:24.284462900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Score: 0.438\n"
     ]
    }
   ],
   "source": [
    "num_folds = 10\n",
    "scores = []\n",
    "f1_scores = []\n",
    "# init model\n",
    "input_size = train_features.shape[1]\n",
    "hidden_size = 180\n",
    "output_size = 2 # 0 or 1\n",
    "lr = 0.0004\n",
    "epochs = 100\n",
    "\n",
    "#device = torch.device(\"cuda\")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "for (train_index, test_index) in skf.split(train_features, labels):\n",
    "    # represents the folds\n",
    "    x_train, x_test = train_features[train_index], train_features[test_index]\n",
    "    y_train, y_test = [labels[i] for i in train_index], [labels[i] for i in test_index]\n",
    "    \n",
    "    x_train = torch.tensor(x_train.toarray(), dtype=torch.float32) #.to(device)\n",
    "    y_train = torch.tensor(y_train) #.to(device)\n",
    " \n",
    "    \n",
    "    \n",
    "    model = MLP(x_train.shape[1], hidden_size, output_size) #.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss() #.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "    \n",
    "    # train the model\n",
    "    train_model(model, criterion, optimizer, x_train, y_train)\n",
    "    \n",
    "    # evaluate\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x_test = torch.tensor(x_test.toarray(), dtype=torch.float32) #.to(device)\n",
    "        y_test = torch.tensor(y_test) #.to(device)\n",
    "        outputs = model(x_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "       # predicted = predicted.cpu()\n",
    "        #y_test = y_test.cpu()\n",
    "        f1 = f1_score(y_test, predicted, average='macro')\n",
    "        scores.append(f1)\n",
    "\n",
    "# Print average F1 score\n",
    "average_f1 = sum(scores) / num_folds\n",
    "print('Average F1 Score:', round(average_f1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19b60405",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T19:15:01.418460600Z",
     "start_time": "2023-07-17T19:15:01.404463100Z"
    }
   },
   "outputs": [],
   "source": [
    "# SECOND PART BEGINS HERE (WITHOUT REMOVING OBJ SENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8081b1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T19:15:01.456461800Z",
     "start_time": "2023-07-17T19:15:01.421462700Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def lol2str(doc):\n",
    "    # flatten & join\n",
    "    return \" \".join([w for sent in doc for w in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2494a01d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T19:15:01.699474500Z",
     "start_time": "2023-07-17T19:15:01.435462800Z"
    }
   },
   "outputs": [],
   "source": [
    "rev_neg = movie_reviews.paras(categories=\"neg\")\n",
    "rev_pos = movie_reviews.paras(categories=\"pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84964a8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T19:15:06.251287600Z",
     "start_time": "2023-07-17T19:15:01.714475900Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.util import mark_negation\n",
    "new_neg = []\n",
    "for rev in rev_neg:\n",
    "    new_rev = []\n",
    "    for sentence in rev:\n",
    "        new_rev.append(mark_negation(sentence)) # Apply or not the negation\n",
    "    new_neg.append(new_rev)\n",
    "    \n",
    "new_pos = []\n",
    "for rev in rev_pos:\n",
    "    new_rev = []\n",
    "    for sentence in rev:\n",
    "        new_rev.append(mark_negation(sentence)) # Apply or not the negation\n",
    "    new_pos.append(new_rev)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1ed33e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T19:15:07.164294800Z",
     "start_time": "2023-07-17T19:15:06.256283500Z"
    }
   },
   "outputs": [],
   "source": [
    "rev_corpus = [lol2str(d) for d in new_neg] + [lol2str(d) for d in new_pos]\n",
    "rev_labels = ([0] * len(rev_neg) + [1] * len(rev_pos))\n",
    "rev_vectors = vectorizer.fit_transform(rev_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "544dc85f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T19:15:28.389293700Z",
     "start_time": "2023-07-17T19:15:07.173295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Score: 0.54\n"
     ]
    }
   ],
   "source": [
    "num_folds = 10\n",
    "scores = []\n",
    "f1_scores = []\n",
    "# init model\n",
    "\n",
    "hidden_size = 180\n",
    "output_size = 2 # 0 or 1\n",
    "lr = 0.0004\n",
    "epochs = 5\n",
    "\n",
    "#device = torch.device(\"cuda\")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=num_folds, random_state=42, shuffle=True)\n",
    "\n",
    "for (train_index, test_index) in skf.split(rev_vectors, rev_labels):\n",
    "    # represents the folds\n",
    "    x_train, x_test = rev_vectors[train_index], rev_vectors[test_index]\n",
    "    y_train, y_test = [rev_labels[i] for i in train_index], [rev_labels[i] for i in test_index]\n",
    "    \n",
    "    x_train = torch.tensor(x_train.toarray(), dtype=torch.float32) #.to(device)\n",
    "    y_train = torch.tensor(y_train) #.to(device)\n",
    " \n",
    "    model = MLP(x_train.shape[1], hidden_size, output_size) #.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss() #.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "    \n",
    "    # train the model\n",
    "    train_model(model, criterion, optimizer, x_train, y_train)\n",
    "    \n",
    "    # evaluate\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x_test = torch.tensor(x_test.toarray(), dtype=torch.float32) #.to(device)\n",
    "        y_test = torch.tensor(y_test) #.to(device)\n",
    "        outputs = model(x_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "       # predicted = predicted.cpu()\n",
    "        #y_test = y_test.cpu()\n",
    "        f1 = f1_score(y_test, predicted, average='macro')\n",
    "        scores.append(f1)\n",
    "\n",
    "# Print average F1 score\n",
    "average_f1 = sum(scores) / num_folds\n",
    "print('Average F1 Score:', round(average_f1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d720b43a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T19:15:28.422291900Z",
     "start_time": "2023-07-17T19:15:28.391295Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# FROM HERE WITHOUT OBJ JUDGMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "094d0952",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T19:15:28.432292800Z",
     "start_time": "2023-07-17T19:15:28.405293700Z"
    }
   },
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d3e02cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T19:15:41.935299400Z",
     "start_time": "2023-07-17T19:15:28.435293200Z"
    }
   },
   "outputs": [],
   "source": [
    "def rm_objective_sentences(document, analyzer):\n",
    "    new_doc = []\n",
    "    for sentence in document:\n",
    "        value = analyzer.polarity_scores(\" \".join(sentence))\n",
    "        if value[\"compound\"] != 0: # Add into new_doc the sentences with a polarity\n",
    "            new_doc.append(\" \".join(sentence))\n",
    "    return new_doc\n",
    "\n",
    "rev_neg_wo_objective = [\" \".join(rm_objective_sentences(doc, analyzer)) for doc in rev_neg]\n",
    "rev_pos_wo_objective = [\" \".join(rm_objective_sentences(doc, analyzer)) for doc in rev_pos]\n",
    "corpus_wo_objective = rev_neg_wo_objective + rev_pos_wo_objective\n",
    "wo_obj_vectors = vectorizer.fit_transform(corpus_wo_objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "635d5cb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T19:16:03.504829Z",
     "start_time": "2023-07-17T19:15:41.950296700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Score: 0.563\n"
     ]
    }
   ],
   "source": [
    "num_folds = 10\n",
    "scores = []\n",
    "f1_scores = []\n",
    "# init model\n",
    "\n",
    "hidden_size = 180\n",
    "output_size = 2 # 0 or 1\n",
    "lr = 0.0004\n",
    "epochs = 5\n",
    "\n",
    "#device = torch.device(\"cuda\")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=num_folds, random_state=42, shuffle=True)\n",
    "\n",
    "for (train_index, test_index) in skf.split(wo_obj_vectors, rev_labels):\n",
    "    # represents the folds\n",
    "    x_train, x_test = rev_vectors[train_index], rev_vectors[test_index]\n",
    "    y_train, y_test = [rev_labels[i] for i in train_index], [rev_labels[i] for i in test_index]\n",
    "    \n",
    "    x_train = torch.tensor(x_train.toarray(), dtype=torch.float32) #.to(device)\n",
    "    y_train = torch.tensor(y_train) #.to(device)\n",
    " \n",
    "    model = MLP(x_train.shape[1], hidden_size, output_size) #.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss() #.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "    \n",
    "    # train the model\n",
    "    train_model(model, criterion, optimizer, x_train, y_train)\n",
    "    \n",
    "    # evaluate\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x_test = torch.tensor(x_test.toarray(), dtype=torch.float32) #.to(device)\n",
    "        y_test = torch.tensor(y_test) #.to(device)\n",
    "        outputs = model(x_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "       # predicted = predicted.cpu()\n",
    "        #y_test = y_test.cpu()\n",
    "        f1 = f1_score(y_test, predicted, average='macro')\n",
    "        scores.append(f1)\n",
    "\n",
    "# Print average F1 score\n",
    "average_f1 = sum(scores) / num_folds\n",
    "print('Average F1 Score:', round(average_f1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24c514f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T19:16:03.520829100Z",
     "start_time": "2023-07-17T19:16:03.505831100Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
