{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dependency Grammars with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- Understanding:\n",
    "    - Dependency Relations and Grammars\n",
    "    - Probabilistic Dependency Grammars\n",
    "    - Projective and Non-Projective Parses\n",
    "    - Transition-based Dependency Parsing\n",
    "\n",
    "- Learning how to:\n",
    "    - define dependency grammar in NLTK\n",
    "    - identify a syntactic relation between Head and Dependent\n",
    "    - parse with dependency grammar\n",
    "    - evaluate dependency parser\n",
    "    - use dependency parser of spacy and stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommended Reading\n",
    "- Dan Jurafsky and James H. Martin. [__Speech and Language Processing__ (SLP)](https://web.stanford.edu/~jurafsky/slp3/) (3rd ed. draft)\n",
    "- Steven Bird, Ewan Klein, and Edward Loper. [__Natural Language Processing with Python__ (NLTK)](https://www.nltk.org/book/)\n",
    "- Kübler, McDonald, and Nivre (2009) Dependency Parsing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covered Material\n",
    "- SLP\n",
    "    - [Chapter 18: Dependency Parsing](https://web.stanford.edu/~jurafsky/slp3/18.pdf) \n",
    "- NLTK \n",
    "    - [Chapter 8: Analyzing Sentence Structure](https://www.nltk.org/book/ch08.html)\n",
    "- Kübler, McDonald, and Nivre (2009) Dependency Parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Requirements\n",
    "\n",
    "- [NLTK](https://www.nltk.org/)\n",
    "    - run `pip install nltk`\n",
    "- [spaCy](https://spacy.io/)\n",
    "    - run `pip install spacy`\n",
    "    - run `python -m spacy download en_core_web_sm` to install English models\n",
    "- [stanza](https://stanfordnlp.github.io/stanza/) for Stanford Parser\n",
    "    - run `pip install stanza`\n",
    "    - run `stanza.download('en')` to intall English models\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Dependency Grammars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Unlike Constituency (Phrase Structure) Grammar that addresses how words and sequences of words combine to form constituents, Dependency Grammar addresses on how words relate to each other. \n",
    "\n",
    "Dependency Grammar assumes that syntactic structure consists of words linked by binary, asymmetrical relations called __dependency relations__. A dependency relation is a binary asymmetric relation that holds between a syntactically subordinate word, called the __dependent__, and another word on which it depends, called the __head__.\n",
    "\n",
    "The __head of a sentence__ is usually taken to be the tensed verb, and every other word is either dependent on the sentence head, or connects to it through a path of dependencies. Thus, a dependency parse is a __directed graph__, where the nodes are the lexical items (words) and the arcs represent dependency relations from heads to dependents. \n",
    "\n",
    "A __typed dependency structure__ contains of the __labeled__ arcs are drawn from a fixed inventory of grammatical relations, that also includes a __root node__ that explicitly marks the root of the tree, the head of the entire structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.1. Dependency Relation Types\n",
    "\n",
    "Universal Dependency set defines the following __core__ relations (from Jurafsky & Martin). \n",
    "\n",
    "(See https://universaldependencies.org/u/dep/index.html for the full set.)\n",
    "\n",
    "| __Clausal Argument Relations__ | Description | Example |\n",
    "|:-------------------------------|:------------|:--------\n",
    "| NSUBJ  | Nominal subject       | __We__ booked her the cheapest morning flight to Miami.\n",
    "| DOBJ   | Direct object         | We booked her the cheapest morning __flight__ to Miami.\n",
    "| IOBJ   | Indirect object       | We booked __her__ the cheapest morning flight to Miami.\n",
    "| CCOMP  | Clausal complement    |\n",
    "| XCOMP  | Open clausal complement (subject of clause is out of its span) \n",
    "| __Nominal Modifier Relations__ ||\n",
    "| NMOD   | Nominal modifier      | We booked her the cheapest __morning__ flight to Miami.\n",
    "| AMOD   | Adjectival modifier   | We booked her the __cheapest__ morning flight to Miami.\n",
    "| NUMMOD | Numeric modifier\n",
    "| APPOS  | Appositional modifier\n",
    "| DET    | Determiner            | We booked her __the__ cheapest morning flight to Miami.\n",
    "| CASE   | Prepositions, postpositions and other case markers | We booked her the cheapest morning flight __to__ Miami.\n",
    "| __Other Notable Relations__ | \n",
    "| CONJ   | Conjunct\n",
    "| CC     | Coordinating conjunction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.2. Defining Dependency Grammar in NLTK\n",
    "\n",
    "Similar to Phrase Structure Grammar, Dependecy Grammar is defined as a list of production rules.\n",
    "\n",
    "Below is an example grammar that defines only __bare__ dependency relations without specifying their types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "ExecuteTime": {
     "end_time": "2023-05-31T00:30:27.056500400Z",
     "start_time": "2023-05-31T00:30:24.470254200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency grammar with 9 productions\n",
      "  'saw' -> 'i'\n",
      "  'saw' -> 'man'\n",
      "  'saw' -> 'with'\n",
      "  'man' -> 'telescope'\n",
      "  'man' -> 'the'\n",
      "  'man' -> 'with'\n",
      "  'telescope' -> 'the'\n",
      "  'telescope' -> 'with'\n",
      "  'telescope' -> 'a'\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "s_bold = '\\033[1m'\n",
    "e_bold = '\\033[0m'\n",
    "\n",
    "# for sentence \"i saw the man with the telescope\"\n",
    "# only string input is accepted\n",
    "\n",
    "rules = \"\"\"\n",
    "    'saw' -> 'i' | 'man' | 'with'\n",
    "    'man' ->  'telescope' | 'the' | 'with'\n",
    "    'telescope' -> 'the' | 'with' | 'a'\n",
    "\"\"\"\n",
    "\n",
    "toy_grammar = nltk.DependencyGrammar.fromstring(rules)\n",
    "\n",
    "print(toy_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Unlike Phrase Structure Grammar, \n",
    "\n",
    "- there is no start symbol (thus, no method to access it)\n",
    "- there is no method to access productions, but it is still possible using the attribute\n",
    "\n",
    "    - `grammar._productions`\n",
    "\n",
    "- there is a method to check if grammar contains a production\n",
    "\n",
    "    - `grammar.contains(head, mod)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Dependency Production__ has 2 attributes:\n",
    "\n",
    "- `_lhs` (left-hand side) -- head\n",
    "- `_rhs` (right-hand side) -- modifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "ExecuteTime": {
     "end_time": "2023-05-31T00:39:10.972804900Z",
     "start_time": "2023-05-31T00:39:10.946807400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['saw' -> 'i', 'saw' -> 'man', 'saw' -> 'with', 'man' -> 'telescope', 'man' -> 'the', 'man' -> 'with', 'telescope' -> 'the', 'telescope' -> 'with', 'telescope' -> 'a']\n",
      "saw ('i',)\n",
      "saw ('man',)\n",
      "saw ('with',)\n",
      "man ('telescope',)\n",
      "man ('the',)\n",
      "man ('with',)\n",
      "telescope ('the',)\n",
      "telescope ('with',)\n",
      "telescope ('a',)\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(toy_grammar._productions)\n",
    "\n",
    "for production in toy_grammar._productions:\n",
    "    print(production._lhs, production._rhs)\n",
    "\n",
    "print(toy_grammar.contains('man', 'the'))  # True\n",
    "print(toy_grammar.contains('the', 'man'))  # False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### How to Identify a Syntactic Relation between Head and Dependent\n",
    "(From Kübler et al. & NLTK Book)\n",
    "\n",
    "Here is a list of some of the more common criteria that have been proposed for identifying a syntactic relation between a head __H__ and a dependent __D__ in a linguistic construction __C__:\n",
    "\n",
    "1. __H__ determines the syntactic category of __C__ and can often replace __C__.\n",
    "2. __H__ determines the semantic category of __C__; __D__ gives semantic specification.\n",
    "3. __H__ is obligatory; __D__ may be optional.\n",
    "4. __H__ selects __D__ and determines whether __D__ is obligatory or optional. \n",
    "5. The form of __D__ depends on __H__ (agreement or government).\n",
    "6. The linear position of __D__ is specified with reference to __H__ .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example__:\n",
    "\n",
    "_I prefer a morning flight_\n",
    "\n",
    "- **C**: _morning flight_\n",
    "- **H**: _flight_\n",
    "    - determines syntactic category: whole construction is nominal\n",
    "    - determines semantic category\n",
    "    - comes after _morning_ (English is head final)\n",
    "- **D**: _morning_\n",
    "    - optional w.r.t. _flight_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.3. Parsing with Dependency Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since Dependency Graphs can be projective and non-projective (allow crossing dependencies), there are __projective__ and __non-projective__ parsers. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 1.3.1. Projective Dependency Parser (Rule-based)\n",
    ">**Definition**:\n",
    "A dependecy tree is projective if **all the arcs of the tree are projective**. An arc from a head to a dependent is said to be projective projective <mark style=\"background-color: rgba(0, 255, 0, 0.2)\"> if there is a path from the head to every word that lies between the head and the dependent </mark> in the sentence. *(Dan Jurafsky and James H. Martin, 2022)*\n",
    "\n",
    "> **NLTK**: A projective, rule-based, dependency parser. A [`ProjectiveDependencyParser`](http://www.nltk.org/api/nltk.parse.html#module-nltk.parse.projectivedependencyparser) is created with a `DependencyGrammar`, a set of productions specifying word-to-word dependency relations. The `parse()` method will then return the set of all parses, in tree representation, for a given input sequence of tokens. \n",
    "`parse()` method returns iterator over [`Tree`](http://www.nltk.org/_modules/nltk/tree.html) objects.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "ExecuteTime": {
     "end_time": "2023-05-31T01:42:23.631479200Z",
     "start_time": "2023-05-31T01:42:23.550759900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              saw                     \n",
      " ┌─────────────┴──────┐                   \n",
      " │                   man              \n",
      " │      ┌─────────────┼──────────┐        \n",
      " │      │             │      telescope\n",
      " │      │             │          │        \n",
      " i     the           with        a    \n",
      "\n",
      "None\n",
      "The ROOT is '\u001B[1msaw\u001B[0m'\n",
      "              saw                            \n",
      " ┌─────────────┴──────┐                          \n",
      " │                   man                     \n",
      " │      ┌─────────────┴──────────┐               \n",
      " │      │                    telescope       \n",
      " │      │             ┌──────────┴─────────┐     \n",
      " i     the           with                  a \n",
      "\n",
      "None\n",
      "The ROOT is '\u001B[1msaw\u001B[0m'\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.ProjectiveDependencyParser(toy_grammar)\n",
    "\n",
    "sent = \"i saw the man with a telescope\"\n",
    "\n",
    "for tree in parser.parse(sent.split()):\n",
    "    print(tree.pretty_print(unicodelines=True, nodedist=4))\n",
    "    # print ROOT node\n",
    "    print(\"The ROOT is '{}'\".format(s_bold + tree.label() + e_bold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 1.3.2. Non-Projective Dependency Parser (Rule-Based)\n",
    "\n",
    ">**Definition**:\n",
    "A dependecy tree is projective if **one or more arcs of the tree are non-projective**. An arc non-projective  when there some words that lies between the head and the dependent in the sentence do not have a path from the head.\n",
    "\n",
    "\n",
    "> A non-projective, rule-based, dependency parser. This parser will return the set of all possible non-projective parses based on the word-to-word relations defined in the parser’s dependency grammar, and <mark style=\"background-color: rgba(0, 255, 0, 0.2)\"> will allow the branches of the parse tree to cross</mark> in order to capture a variety of linguistic phenomena that a projective parser will not .\n",
    "\n",
    "`parse()` method returns iterator over [`DependencyGraph`](https://www.nltk.org/api/nltk.parse.html#nltk.parse.dependencygraph.DependencyGraph) objects. \n",
    "\n",
    "`tree()` method of the `DependencyGraph` object builds a dependency tree using the NLTK Tree constructor, starting with the `root` node and omitting labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](https://i.postimg.cc/hvQDRNDg/Screenshot-2022-12-19-at-17-22-53.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flight -> was **is not projective**, since *this morning* is not reachable from *flight*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "ExecuteTime": {
     "end_time": "2023-05-31T01:52:55.694438500Z",
     "start_time": "2023-05-31T01:52:55.653405700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              saw                    \n",
      " ┌─────────────┴─────────┐               \n",
      " │                      man          \n",
      " │                       │               \n",
      " │                   telescope       \n",
      " │      ┌────────────────┼─────────┐     \n",
      " i     the              with       a \n",
      "\n",
      "The ROOT is '\u001B[1msaw\u001B[0m'\n",
      "               saw                           \n",
      " ┌──────────────┴──────┐                         \n",
      " │                    man                    \n",
      " │      ┌──────────────┴─────────┐               \n",
      " │      │                    telescope       \n",
      " │      │              ┌─────────┴─────────┐     \n",
      " i     with           the                  a \n",
      "\n",
      "The ROOT is '\u001B[1msaw\u001B[0m'\n",
      "       saw                            \n",
      " ┌──────┼─────────────────┐               \n",
      " │      │                man          \n",
      " │      │                 │               \n",
      " │      │             telescope       \n",
      " │      │       ┌─────────┴─────────┐     \n",
      " i     with    the                  a \n",
      "\n",
      "The ROOT is '\u001B[1msaw\u001B[0m'\n",
      "              saw                            \n",
      " ┌─────────────┴──────┐                          \n",
      " │                   man                     \n",
      " │      ┌─────────────┴──────────┐               \n",
      " │      │                    telescope       \n",
      " │      │             ┌──────────┴─────────┐     \n",
      " i     the           with                  a \n",
      "\n",
      "The ROOT is '\u001B[1msaw\u001B[0m'\n",
      "              saw                     \n",
      " ┌─────────────┴──────┐                   \n",
      " │                   man              \n",
      " │      ┌─────────────┼──────────┐        \n",
      " │      │             │      telescope\n",
      " │      │             │          │        \n",
      " i     the           with        a    \n",
      "\n",
      "The ROOT is '\u001B[1msaw\u001B[0m'\n",
      "       saw                            \n",
      " ┌──────┼──────────────┐                  \n",
      " │      │             man             \n",
      " │      │       ┌──────┴─────────┐        \n",
      " │      │       │            telescope\n",
      " │      │       │                │        \n",
      " i     with    the               a    \n",
      "\n",
      "The ROOT is '\u001B[1msaw\u001B[0m'\n"
     ]
    }
   ],
   "source": [
    "np_parser = nltk.NonprojectiveDependencyParser(toy_grammar)\n",
    "\n",
    "for graph in np_parser.parse(sent.split()):\n",
    "    graph.tree().pretty_print(unicodelines=True, nodedist=4)\n",
    "    print(\"The ROOT is '{}'\".format(s_bold + graph.root['word'] + e_bold))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since the sentence is ambiguous, similar to Phrase Structure Grammar, our Dependency Grammar yields 2 parses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 1.3.3. Accessing the Graph\n",
    "\n",
    "- `DependencyGraph` object has 2 attrubutes\n",
    "    - nodes (of `defaultdict` type)\n",
    "    - root (of `dict` type), which is also a node\n",
    "\n",
    "- Each node in a graph is represented as a dict that defines its:\n",
    "    - address (sentence index starting from 1) -- required\n",
    "    - word (string form) -- required\n",
    "    - head (address)\n",
    "    - deps (dependents)\n",
    "    - rel (dependency relation to head)\n",
    "\n",
    "Thus, we can print the graph as a list of tokens with their attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "ExecuteTime": {
     "end_time": "2023-05-31T01:54:28.091355600Z",
     "start_time": "2023-05-31T01:54:28.074393700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 saw\n",
      "2 saw\n",
      "2 saw\n",
      "2 saw\n",
      "2 saw\n",
      "2 saw\n"
     ]
    }
   ],
   "source": [
    "# printing root address and word\n",
    "for graph in np_parser.parse(sent.split()): \n",
    "    print(graph.root['address'], graph.root['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "ExecuteTime": {
     "end_time": "2023-05-31T01:55:41.601203800Z",
     "start_time": "2023-05-31T01:55:41.525203700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\ti:\t[]\n",
      "2\tsaw:\t[1, 4]\n",
      "3\tthe:\t[]\n",
      "4\tman:\t[7]\n",
      "5\twith:\t[]\n",
      "6\ta:\t[]\n",
      "7\ttelescope:\t[3, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "# printing all the nodes with dependent positions\n",
    "for graph in np_parser.parse(sent.split()):    \n",
    "    # sorting is required since graph starts from root, which is not the first token\n",
    "    for _, node in sorted(graph.nodes.items()):\n",
    "        if node['word'] is not None:\n",
    "            print('{address}\\t{word}:\\t{dependents}'.format(dependents=node['deps'][''], **node))\n",
    "    break  # just to print 1 graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It is also possible to convert the graph into other supported formats, such as CoNLL using `to_conll(style)` method, where [style](https://www.nltk.org/api/nltk.parse.html#nltk.parse.dependencygraph.DependencyGraph) is either 3, 4, or 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\tNone\tNone\n",
      "saw\tNone\tNone\n",
      "the\tNone\tNone\n",
      "man\tNone\tNone\n",
      "with\tNone\tNone\n",
      "a\tNone\tNone\n",
      "telescope\tNone\tNone\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for graph in np_parser.parse(sent.split()):\n",
    "    print(graph.to_conll(3))\n",
    "    break  # just to print 1 graph"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T01:57:05.475255400Z",
     "start_time": "2023-05-31T01:57:05.401257200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise\n",
    "\n",
    "- Define grammar that covers the following sentences.\n",
    "\n",
    "    - show flights from new york to los angeles\n",
    "    - list flights from new york to los angeles\n",
    "    - show flights from new york\n",
    "    - list flights to los angeles\n",
    "    - list flights\n",
    "    \n",
    "- Use one of the parsers to parse the sentences (i.e. test your grammar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "ExecuteTime": {
     "end_time": "2023-05-31T02:05:47.556862300Z",
     "start_time": "2023-05-31T02:05:47.532863300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: show flights from new york to los angeles\n",
      "           show                   \n",
      "   ┌────────┴───────┐                 \n",
      "   │               from           \n",
      "   │                │                 \n",
      "   │               new            \n",
      "   │                │                 \n",
      "   │               york           \n",
      "   │                │                 \n",
      "   │                to            \n",
      "   │        ┌───────┴─────────┐       \n",
      "flights    los             angeles\n",
      "\n",
      "The ROOT is '\u001B[1mshow\u001B[0m' \n",
      "\n",
      "Sentence: show flights from new york to los angeles\n",
      "                  show                           \n",
      "   ┌───────────────┴───────┐                         \n",
      "   │                      from                   \n",
      "   │        ┌──────────────┴───────┐                 \n",
      "   │        │                     york           \n",
      "   │        │                      │                 \n",
      "   │        │                      to            \n",
      "   │        │              ┌───────┴─────────┐       \n",
      "flights    new            los             angeles\n",
      "\n",
      "The ROOT is '\u001B[1mshow\u001B[0m' \n",
      "\n",
      "Sentence: show flights from new york to los angeles\n",
      "           show           \n",
      "   ┌────────┼─────────┐       \n",
      "   │       from       to  \n",
      "   │        │         │       \n",
      "   │       new       los  \n",
      "   │        │         │       \n",
      "flights    york    angeles\n",
      "\n",
      "The ROOT is '\u001B[1mshow\u001B[0m' \n",
      "\n",
      "Sentence: show flights from new york to los angeles\n",
      "                          show                         \n",
      "   ┌───────────────┬───────┴──────────────┐                \n",
      "   │              from                    to           \n",
      "   │        ┌──────┴───────┐       ┌──────┴────────┐       \n",
      "flights    new            york    los           angeles\n",
      "\n",
      "The ROOT is '\u001B[1mshow\u001B[0m' \n",
      "\n",
      "Sentence: show flights from new york to los angeles\n",
      "           show                   \n",
      "   ┌────────┴───────┐                 \n",
      "   │               from           \n",
      "   │        ┌───────┴─────────┐       \n",
      "   │        │                york \n",
      "   │        │                 │       \n",
      "   │        │                 to  \n",
      "   │        │                 │       \n",
      "   │        │                los  \n",
      "   │        │                 │       \n",
      "flights    new             angeles\n",
      "\n",
      "The ROOT is '\u001B[1mshow\u001B[0m' \n",
      "\n",
      "Sentence: show flights from new york to los angeles\n",
      "           show                         \n",
      "   ┌────────┼──────────────┐                \n",
      "   │       from            │            \n",
      "   │        │              │                \n",
      "   │       new             to           \n",
      "   │        │       ┌──────┴────────┐       \n",
      "flights    york    los           angeles\n",
      "\n",
      "The ROOT is '\u001B[1mshow\u001B[0m' \n",
      "\n",
      "Sentence: show flights from new york to los angeles\n",
      "           show           \n",
      "   ┌────────┴─────────┐       \n",
      "   │                 from \n",
      "   │                  │       \n",
      "   │                 new  \n",
      "   │                  │       \n",
      "   │                 york \n",
      "   │                  │       \n",
      "   │                  to  \n",
      "   │                  │       \n",
      "   │                 los  \n",
      "   │                  │       \n",
      "flights            angeles\n",
      "\n",
      "The ROOT is '\u001B[1mshow\u001B[0m' \n",
      "\n",
      "Sentence: show flights from new york to los angeles\n",
      "           show                           \n",
      "   ┌────────┴───────┬─────────────────┐       \n",
      "   │                │                 to  \n",
      "   │                │                 │       \n",
      "   │               from              los  \n",
      "   │        ┌───────┴───────┐         │       \n",
      "flights    new             york    angeles\n",
      "\n",
      "The ROOT is '\u001B[1mshow\u001B[0m' \n",
      "\n",
      "Sentence: show flights from new york\n",
      "           show                \n",
      "   ┌────────┴───────┐              \n",
      "   │               from        \n",
      "   │        ┌───────┴───────┐      \n",
      "flights    new             york\n",
      "\n",
      "The ROOT is '\u001B[1mshow\u001B[0m' \n",
      "\n",
      "Sentence: show flights from new york\n",
      "           show        \n",
      "   ┌────────┴───────┐      \n",
      "   │               from\n",
      "   │                │      \n",
      "   │               new \n",
      "   │                │      \n",
      "flights            york\n",
      "\n",
      "The ROOT is '\u001B[1mshow\u001B[0m' \n",
      "\n",
      "Sentence: list flights\n",
      "flights\n",
      "   │       \n",
      "  list \n",
      "\n",
      "The ROOT is '\u001B[1mflights\u001B[0m' \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"show flights from new york to los angeles\",\n",
    "            \"list flights from new york to los angeles\",\n",
    "            \"show flights from new york\",\n",
    "            \"list flights to los angeles\",\n",
    "            \"list flights\"]\n",
    "\n",
    "# Follow the logic described in How to Identify a Syntactic Relation between Head and Dependent. \n",
    "# The tensed verb is the root. \n",
    "# Are prepositions heads or dependants?  \n",
    "\n",
    "rules = \"\"\"\n",
    "    'show' -> 'flights' | 'from' | 'to'\n",
    "    'flights' -> 'list'\n",
    "    'from' -> 'new' | 'york'\n",
    "    'new' -> 'york'\n",
    "    'york' -> 'to'\n",
    "    'to' -> 'los' | 'angeles'\n",
    "    'los' -> 'angeles'\n",
    "\"\"\"\n",
    "\n",
    "toy_grammar = nltk.DependencyGrammar.fromstring(rules)\n",
    "\n",
    "np_parser = nltk.ProjectiveDependencyParser(toy_grammar)\n",
    "\n",
    "for sent in sentences:\n",
    "    for graph in np_parser.parse(sent.split()):\n",
    "        print(\"Sentence:\", sent)\n",
    "\n",
    "        if type(graph) != nltk.tree.Tree:\n",
    "            graph.tree().pretty_print(unicodelines=True, nodedist=4)\n",
    "            print(\"The ROOT is '{}'\".format(s_bold + graph.root['word'] + e_bold), '\\n')\n",
    "        else:\n",
    "            graph.pretty_print(unicodelines=True, nodedist=4)\n",
    "            print(\"The ROOT is '{}'\".format(s_bold + graph.label() + e_bold), '\\n')      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Probabilistic Dependency Grammars & Parsing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Similar to CFGs, we can learn dependency grammar from data using treebanks.\n",
    "NLTK provides `ProbabilisticProjectiveDependencyParser` that returns the most probable projective parse derived from the probabilistic dependency grammar derived from the `train()` method. \n",
    "\n",
    "> The probabilistic model is an implementation of Eisner's (1996) Model C, which conditions on head-word, head-tag, child-word, and child-tag. The decoding uses a bottom-up chart-based span concatenation algorithm that's identical to the one utilized by the rule-based projective parser.\n",
    "\n",
    "Without going into details, that is an example of Dynamic Programming approach to Dependency Parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "ExecuteTime": {
     "end_time": "2023-05-31T02:23:44.260683400Z",
     "start_time": "2023-05-31T02:23:43.271674400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package dependency_treebank to\n",
      "[nltk_data]     C:\\Users\\adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\dependency_treebank.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downloading treebank\n",
    "import nltk\n",
    "nltk.download('dependency_treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "ExecuteTime": {
     "end_time": "2023-05-31T02:24:19.084699400Z",
     "start_time": "2023-05-31T02:24:18.572699100Z"
    }
   },
   "outputs": [],
   "source": [
    "# example from NLTK\n",
    "from nltk.parse.dependencygraph import DependencyGraph\n",
    "from nltk.parse import ProbabilisticProjectiveDependencyParser\n",
    "from nltk.corpus import dependency_treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tPierre\tPierre\tNNP\tNNP\t\t2\t\t_\t_\n",
      "2\tVinken\tVinken\tNNP\tNNP\t\t8\t\t_\t_\n",
      "3\t,\t,\t,\t,\t\t2\t\t_\t_\n",
      "4\t61\t61\tCD\tCD\t\t5\t\t_\t_\n",
      "5\tyears\tyears\tNNS\tNNS\t\t6\t\t_\t_\n",
      "6\told\told\tJJ\tJJ\t\t2\t\t_\t_\n",
      "7\t,\t,\t,\t,\t\t2\t\t_\t_\n",
      "8\twill\twill\tMD\tMD\t\t0\t\t_\t_\n",
      "9\tjoin\tjoin\tVB\tVB\t\t8\t\t_\t_\n",
      "10\tthe\tthe\tDT\tDT\t\t11\t\t_\t_\n",
      "11\tboard\tboard\tNN\tNN\t\t9\t\t_\t_\n",
      "12\tas\tas\tIN\tIN\t\t9\t\t_\t_\n",
      "13\ta\ta\tDT\tDT\t\t15\t\t_\t_\n",
      "14\tnonexecutive\tnonexecutive\tJJ\tJJ\t\t15\t\t_\t_\n",
      "15\tdirector\tdirector\tNN\tNN\t\t12\t\t_\t_\n",
      "16\tNov.\tNov.\tNNP\tNNP\t\t9\t\t_\t_\n",
      "17\t29\t29\tCD\tCD\t\t16\t\t_\t_\n",
      "18\t.\t.\t.\t.\t\t8\t\t_\t_\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print dependency graph in CoNLL format\n",
    "print(dependency_treebank.parsed_sents()[0].to_conll(10))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T02:24:21.683761Z",
     "start_time": "2023-05-31T02:24:20.657763100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "ppdp = ProbabilisticProjectiveDependencyParser()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T02:24:33.469372700Z",
     "start_time": "2023-05-31T02:24:33.451370800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# train parser on graphs\n",
    "ppdp.train(dependency_treebank.parsed_sents())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T02:24:51.881366500Z",
     "start_time": "2023-05-31T02:24:49.812649600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(fell (stock (of (price the)) the))\n",
      "(fell (stock (of (price the) the)))\n",
      "(fell (stock (of the price) the))\n",
      "(fell (stock (of the price the)))\n",
      "(fell (stock the (of price) the))\n",
      "(fell (stock the (of price the)))\n"
     ]
    }
   ],
   "source": [
    "# parse the sentence\n",
    "parse = ppdp.parse(['the', 'price', 'of', 'the', 'stock', 'fell'])\n",
    "\n",
    "# returns set of trees ordered by probability score\n",
    "for tree in parse:\n",
    "    # print(tree.pretty_print(unicodelines=True, nodedist=4))\n",
    "    print(tree)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T02:31:08.558260Z",
     "start_time": "2023-05-31T02:31:06.942262Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Exercise\n",
    "\n",
    "Write a function that given a dependency graph, for each token (word), produces list of words from it to ROOT.\n",
    "\n",
    "(Construct normal `dict` for simplicity first.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "ExecuteTime": {
     "end_time": "2023-05-31T02:35:34.688540100Z",
     "start_time": "2023-05-31T02:35:32.830394800Z"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# With .nodes we get a dict\n",
    "dg_tree = dependency_treebank.parsed_sents()[0].tree()\n",
    "dg = dependency_treebank.parsed_sents()[0].nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function DependencyGraph.__init__.<locals>.<lambda> at 0x0000022CE175D430>,\n",
      "            {0: {'address': 0,\n",
      "                 'ctag': 'TOP',\n",
      "                 'deps': defaultdict(<class 'list'>, {'ROOT': [8]}),\n",
      "                 'feats': None,\n",
      "                 'head': None,\n",
      "                 'lemma': None,\n",
      "                 'rel': None,\n",
      "                 'tag': 'TOP',\n",
      "                 'word': None},\n",
      "             1: {'address': 1,\n",
      "                 'ctag': 'NNP',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 2,\n",
      "                 'lemma': 'Pierre',\n",
      "                 'rel': '',\n",
      "                 'tag': 'NNP',\n",
      "                 'word': 'Pierre'},\n",
      "             2: {'address': 2,\n",
      "                 'ctag': 'NNP',\n",
      "                 'deps': defaultdict(<class 'list'>, {'': [1, 3, 6, 7]}),\n",
      "                 'feats': '',\n",
      "                 'head': 8,\n",
      "                 'lemma': 'Vinken',\n",
      "                 'rel': '',\n",
      "                 'tag': 'NNP',\n",
      "                 'word': 'Vinken'},\n",
      "             3: {'address': 3,\n",
      "                 'ctag': ',',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 2,\n",
      "                 'lemma': ',',\n",
      "                 'rel': '',\n",
      "                 'tag': ',',\n",
      "                 'word': ','},\n",
      "             4: {'address': 4,\n",
      "                 'ctag': 'CD',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 5,\n",
      "                 'lemma': '61',\n",
      "                 'rel': '',\n",
      "                 'tag': 'CD',\n",
      "                 'word': '61'},\n",
      "             5: {'address': 5,\n",
      "                 'ctag': 'NNS',\n",
      "                 'deps': defaultdict(<class 'list'>, {'': [4]}),\n",
      "                 'feats': '',\n",
      "                 'head': 6,\n",
      "                 'lemma': 'years',\n",
      "                 'rel': '',\n",
      "                 'tag': 'NNS',\n",
      "                 'word': 'years'},\n",
      "             6: {'address': 6,\n",
      "                 'ctag': 'JJ',\n",
      "                 'deps': defaultdict(<class 'list'>, {'': [5]}),\n",
      "                 'feats': '',\n",
      "                 'head': 2,\n",
      "                 'lemma': 'old',\n",
      "                 'rel': '',\n",
      "                 'tag': 'JJ',\n",
      "                 'word': 'old'},\n",
      "             7: {'address': 7,\n",
      "                 'ctag': ',',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 2,\n",
      "                 'lemma': ',',\n",
      "                 'rel': '',\n",
      "                 'tag': ',',\n",
      "                 'word': ','},\n",
      "             8: {'address': 8,\n",
      "                 'ctag': 'MD',\n",
      "                 'deps': defaultdict(<class 'list'>, {'': [2, 9, 18]}),\n",
      "                 'feats': '',\n",
      "                 'head': 0,\n",
      "                 'lemma': 'will',\n",
      "                 'rel': '',\n",
      "                 'tag': 'MD',\n",
      "                 'word': 'will'},\n",
      "             9: {'address': 9,\n",
      "                 'ctag': 'VB',\n",
      "                 'deps': defaultdict(<class 'list'>, {'': [11, 12, 16]}),\n",
      "                 'feats': '',\n",
      "                 'head': 8,\n",
      "                 'lemma': 'join',\n",
      "                 'rel': '',\n",
      "                 'tag': 'VB',\n",
      "                 'word': 'join'},\n",
      "             10: {'address': 10,\n",
      "                  'ctag': 'DT',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 11,\n",
      "                  'lemma': 'the',\n",
      "                  'rel': '',\n",
      "                  'tag': 'DT',\n",
      "                  'word': 'the'},\n",
      "             11: {'address': 11,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>, {'': [10]}),\n",
      "                  'feats': '',\n",
      "                  'head': 9,\n",
      "                  'lemma': 'board',\n",
      "                  'rel': '',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'board'},\n",
      "             12: {'address': 12,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {'': [15]}),\n",
      "                  'feats': '',\n",
      "                  'head': 9,\n",
      "                  'lemma': 'as',\n",
      "                  'rel': '',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'as'},\n",
      "             13: {'address': 13,\n",
      "                  'ctag': 'DT',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 15,\n",
      "                  'lemma': 'a',\n",
      "                  'rel': '',\n",
      "                  'tag': 'DT',\n",
      "                  'word': 'a'},\n",
      "             14: {'address': 14,\n",
      "                  'ctag': 'JJ',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 15,\n",
      "                  'lemma': 'nonexecutive',\n",
      "                  'rel': '',\n",
      "                  'tag': 'JJ',\n",
      "                  'word': 'nonexecutive'},\n",
      "             15: {'address': 15,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>, {'': [13, 14]}),\n",
      "                  'feats': '',\n",
      "                  'head': 12,\n",
      "                  'lemma': 'director',\n",
      "                  'rel': '',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'director'},\n",
      "             16: {'address': 16,\n",
      "                  'ctag': 'NNP',\n",
      "                  'deps': defaultdict(<class 'list'>, {'': [17]}),\n",
      "                  'feats': '',\n",
      "                  'head': 9,\n",
      "                  'lemma': 'Nov.',\n",
      "                  'rel': '',\n",
      "                  'tag': 'NNP',\n",
      "                  'word': 'Nov.'},\n",
      "             17: {'address': 17,\n",
      "                  'ctag': 'CD',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 16,\n",
      "                  'lemma': '29',\n",
      "                  'rel': '',\n",
      "                  'tag': 'CD',\n",
      "                  'word': '29'},\n",
      "             18: {'address': 18,\n",
      "                  'ctag': '.',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 8,\n",
      "                  'lemma': '.',\n",
      "                  'rel': '',\n",
      "                  'tag': '.',\n",
      "                  'word': '.'}})\n"
     ]
    }
   ],
   "source": [
    "# Let's print to see what it contains\n",
    "pprint(dg)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T02:35:35.765317800Z",
     "start_time": "2023-05-31T02:35:35.752318Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   will                                                     \n",
      " ┌─────────────────┬────────────────┴────────────────┐                                          \n",
      " │               Vinken                             join                                    \n",
      " │       ┌─────────┼────────┬───────┐        ┌───────┴─────────┬─────────────────────────┐      \n",
      " │       │         │        │      old       │                 as                        │  \n",
      " │       │         │        │       │        │                 │                         │      \n",
      " │       │         │        │     years    board            director                    Nov.\n",
      " │       │         │        │       │        │       ┌─────────┴─────────────┐           │      \n",
      " .     Pierre      ,        ,       61      the      a                  nonexecutive     29 \n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dg_tree.pretty_print(unicodelines=True, nodedist=4))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T02:36:34.568437400Z",
     "start_time": "2023-05-31T02:36:34.524443800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pierre : ['Pierre', 'Vinken', 'will']\n",
      "Vinken : ['Vinken', 'will']\n",
      ", : [',', 'Vinken', 'will']\n",
      "61 : ['61', 'years', 'old', 'Vinken', 'will']\n",
      "years : ['years', 'old', 'Vinken', 'will']\n",
      "old : ['old', 'Vinken', 'will']\n",
      ", : [',', 'Vinken', 'will']\n",
      "will : ['will']\n",
      "join : ['join', 'will']\n",
      "the : ['the', 'board', 'join', 'will']\n",
      "board : ['board', 'join', 'will']\n",
      "as : ['as', 'join', 'will']\n",
      "a : ['a', 'director', 'as', 'join', 'will']\n",
      "nonexecutive : ['nonexecutive', 'director', 'as', 'join', 'will']\n",
      "director : ['director', 'as', 'join', 'will']\n",
      "Nov. : ['Nov.', 'join', 'will']\n",
      "29 : ['29', 'Nov.', 'join', 'will']\n",
      ". : ['.', 'will']\n"
     ]
    }
   ],
   "source": [
    "# The first element is the root, sentence starts from the second element in the dict\n",
    "def go_to_root(token, head, dg):\n",
    "    path = list()\n",
    "\n",
    "    # We start from the token\n",
    "    path.append(token)\n",
    "\n",
    "    # We go up until we reach the root\n",
    "    while head != 0:\n",
    "        # We add the head to the path\n",
    "        path.append(dg[head]['word'])\n",
    "        # We update the head\n",
    "        head = dg[head]['head']\n",
    "\n",
    "    # From token to the root\n",
    "    return path\n",
    "\n",
    "for k, v in sorted(dg.items()):\n",
    "    if k != 0:\n",
    "        print(v['word'],\":\" ,go_to_root(v['word'], v['head'], dg))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T02:41:38.501344900Z",
     "start_time": "2023-05-31T02:41:38.484346100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Transition-Based Dependency Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are several methods for data-driven dependency parsing\n",
    "- Dynamic Programming-based (e.g. `ProbabilisticProjectiveDependencyParser`)\n",
    "- Graph-based (e.g. [Minimum Spanning Tree Parser](https://www.seas.upenn.edu/~strctlrn/MSTParser/MSTParser.html))\n",
    "- Transition-Based Dependency Parsing (e.g. NLTK's interface to [MaltParser](https://www.nltk.org/_modules/nltk/parse/malt.html))\n",
    "\n",
    "Transition-based parsing (or \"deterministic dependency parsing\") proved to be very effective and is the State-of-the-Art approach (with neural twist)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(from Jurafsky & Martin)\n",
    "\n",
    "In transition-based parsing there is:\n",
    "- a **stack** on which we build the parse\n",
    "- a **buffer** of tokens to be parsed\n",
    "- a **parser** which takes actions on the parse via a predictor called an **oracle**\n",
    "\n",
    "The parser walks through the sentence left-to-right, successively shifting items from the buffer onto the stack. At each time point we examine the top two elements on the stack, and the oracle makes a decision about what transition to apply to build the parse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arc-Standard Transition System (there are alternatives, i.e. Arc Eager) defines 3 transition operators that will operate on the top two elements of the stack:\n",
    "\n",
    "- __LEFTARC__: \n",
    "    - Assert a head-dependent relation between the word at the top of the stack and the word directly beneath it;\n",
    "    - Remove the lower word from the stack.\n",
    "- __RIGHTARC__: \n",
    "    - Assert a head-dependent relation between the second word on the stack and the word at the top; \n",
    "    - Remove the word at the top of the stack;\n",
    "- __SHIFT__: \n",
    "    - Remove the word from the front of the input buffer and push it onto the stack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally fits into Machine Learning framework where \n",
    "- configuration (buffer & stack) are features, \n",
    "- operations are labels\n",
    "- oracle is a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Transition Parser in NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "ExecuteTime": {
     "end_time": "2023-05-31T02:49:14.157420Z",
     "start_time": "2023-05-31T02:49:04.258294700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 100\n",
      " Number of valid (projective) examples : 100\n",
      "[LibSVM]<nltk.parse.transitionparser.TransitionParser object at 0x0000022CF2A44F70>\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.transitionparser import TransitionParser\n",
    "\n",
    "tp = TransitionParser('arc-standard')\n",
    "tp.train(dependency_treebank.parsed_sents()[:100], 'tp.model')\n",
    "print(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "ExecuteTime": {
     "end_time": "2023-05-31T02:49:21.449947400Z",
     "start_time": "2023-05-31T02:49:19.543476600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "defaultdict(<function DependencyGraph.__init__.<locals>.<lambda> at 0x0000022CFD36BA60>,\n",
      "            {0: {'address': 0,\n",
      "                 'ctag': 'TOP',\n",
      "                 'deps': defaultdict(<class 'list'>, {'ROOT': [5]}),\n",
      "                 'feats': None,\n",
      "                 'head': 0,\n",
      "                 'lemma': None,\n",
      "                 'rel': '',\n",
      "                 'tag': 'TOP',\n",
      "                 'word': None},\n",
      "             1: {'address': 1,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 4,\n",
      "                 'lemma': 'A',\n",
      "                 'rel': '',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'A'},\n",
      "             2: {'address': 2,\n",
      "                 'ctag': 'NNP',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 4,\n",
      "                 'lemma': 'White',\n",
      "                 'rel': '',\n",
      "                 'tag': 'NNP',\n",
      "                 'word': 'White'},\n",
      "             3: {'address': 3,\n",
      "                 'ctag': 'NNP',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 4,\n",
      "                 'lemma': 'House',\n",
      "                 'rel': '',\n",
      "                 'tag': 'NNP',\n",
      "                 'word': 'House'},\n",
      "             4: {'address': 4,\n",
      "                 'ctag': 'NN',\n",
      "                 'deps': defaultdict(<class 'list'>, {'': [1, 2, 3]}),\n",
      "                 'feats': '',\n",
      "                 'head': 5,\n",
      "                 'lemma': 'spokesman',\n",
      "                 'rel': '',\n",
      "                 'tag': 'NN',\n",
      "                 'word': 'spokesman'},\n",
      "             5: {'address': 5,\n",
      "                 'ctag': 'VBD',\n",
      "                 'deps': defaultdict(<class 'list'>, {'': [4, 7, 8, 31]}),\n",
      "                 'feats': '',\n",
      "                 'head': 0,\n",
      "                 'lemma': 'said',\n",
      "                 'rel': '',\n",
      "                 'tag': 'VBD',\n",
      "                 'word': 'said'},\n",
      "             6: {'address': 6,\n",
      "                 'ctag': 'JJ',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 7,\n",
      "                 'lemma': 'last',\n",
      "                 'rel': '',\n",
      "                 'tag': 'JJ',\n",
      "                 'word': 'last'},\n",
      "             7: {'address': 7,\n",
      "                 'ctag': 'NN',\n",
      "                 'deps': defaultdict(<class 'list'>, {'': [6]}),\n",
      "                 'feats': '',\n",
      "                 'head': 5,\n",
      "                 'lemma': 'week',\n",
      "                 'rel': '',\n",
      "                 'tag': 'NN',\n",
      "                 'word': 'week'},\n",
      "             8: {'address': 8,\n",
      "                 'ctag': 'IN',\n",
      "                 'deps': defaultdict(<class 'list'>, {'': [11]}),\n",
      "                 'feats': '',\n",
      "                 'head': 7,\n",
      "                 'lemma': 'that',\n",
      "                 'rel': '',\n",
      "                 'tag': 'IN',\n",
      "                 'word': 'that'},\n",
      "             9: {'address': 9,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 10,\n",
      "                 'lemma': 'the',\n",
      "                 'rel': '',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'the'},\n",
      "             10: {'address': 10,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>, {'': [9]}),\n",
      "                  'feats': '',\n",
      "                  'head': 11,\n",
      "                  'lemma': 'president',\n",
      "                  'rel': '',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'president'},\n",
      "             11: {'address': 11,\n",
      "                  'ctag': 'VBZ',\n",
      "                  'deps': defaultdict(<class 'list'>, {'': [10, 12]}),\n",
      "                  'feats': '',\n",
      "                  'head': 8,\n",
      "                  'lemma': 'is',\n",
      "                  'rel': '',\n",
      "                  'tag': 'VBZ',\n",
      "                  'word': 'is'},\n",
      "             12: {'address': 12,\n",
      "                  'ctag': 'VBG',\n",
      "                  'deps': defaultdict(<class 'list'>, {'': [13]}),\n",
      "                  'feats': '',\n",
      "                  'head': 11,\n",
      "                  'lemma': 'considering',\n",
      "                  'rel': '',\n",
      "                  'tag': 'VBG',\n",
      "                  'word': 'considering'},\n",
      "             13: {'address': 13,\n",
      "                  'ctag': 'VBG',\n",
      "                  'deps': defaultdict(<class 'list'>, {'': [14, 27]}),\n",
      "                  'feats': '',\n",
      "                  'head': 12,\n",
      "                  'lemma': 'declaring',\n",
      "                  'rel': '',\n",
      "                  'tag': 'VBG',\n",
      "                  'word': 'declaring'},\n",
      "             14: {'address': 14,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {'': [18]}),\n",
      "                  'feats': '',\n",
      "                  'head': 13,\n",
      "                  'lemma': 'that',\n",
      "                  'rel': '',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'that'},\n",
      "             15: {'address': 15,\n",
      "                  'ctag': 'DT',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 16,\n",
      "                  'lemma': 'the',\n",
      "                  'rel': '',\n",
      "                  'tag': 'DT',\n",
      "                  'word': 'the'},\n",
      "             16: {'address': 16,\n",
      "                  'ctag': 'NNP',\n",
      "                  'deps': defaultdict(<class 'list'>, {'': [15]}),\n",
      "                  'feats': '',\n",
      "                  'head': 18,\n",
      "                  'lemma': 'Constitution',\n",
      "                  'rel': '',\n",
      "                  'tag': 'NNP',\n",
      "                  'word': 'Constitution'},\n",
      "             17: {'address': 17,\n",
      "                  'ctag': 'RB',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 18,\n",
      "                  'lemma': 'implicitly',\n",
      "                  'rel': '',\n",
      "                  'tag': 'RB',\n",
      "                  'word': 'implicitly'},\n",
      "             18: {'address': 18,\n",
      "                  'ctag': 'VBZ',\n",
      "                  'deps': defaultdict(<class 'list'>, {'': [16, 17, 19, 21]}),\n",
      "                  'feats': '',\n",
      "                  'head': 14,\n",
      "                  'lemma': 'gives',\n",
      "                  'rel': '',\n",
      "                  'tag': 'VBZ',\n",
      "                  'word': 'gives'},\n",
      "             19: {'address': 19,\n",
      "                  'ctag': 'PRP',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 21,\n",
      "                  'lemma': 'him',\n",
      "                  'rel': '',\n",
      "                  'tag': 'PRP',\n",
      "                  'word': 'him'},\n",
      "             20: {'address': 20,\n",
      "                  'ctag': 'DT',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 21,\n",
      "                  'lemma': 'the',\n",
      "                  'rel': '',\n",
      "                  'tag': 'DT',\n",
      "                  'word': 'the'},\n",
      "             21: {'address': 21,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>, {'': [20, 22]}),\n",
      "                  'feats': '',\n",
      "                  'head': 18,\n",
      "                  'lemma': 'authority',\n",
      "                  'rel': '',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'authority'},\n",
      "             22: {'address': 22,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {'': [25]}),\n",
      "                  'feats': '',\n",
      "                  'head': 21,\n",
      "                  'lemma': 'for',\n",
      "                  'rel': '',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'for'},\n",
      "             23: {'address': 23,\n",
      "                  'ctag': 'DT',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 25,\n",
      "                  'lemma': 'a',\n",
      "                  'rel': '',\n",
      "                  'tag': 'DT',\n",
      "                  'word': 'a'},\n",
      "             24: {'address': 24,\n",
      "                  'ctag': 'JJ',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 25,\n",
      "                  'lemma': 'line-item',\n",
      "                  'rel': '',\n",
      "                  'tag': 'JJ',\n",
      "                  'word': 'line-item'},\n",
      "             25: {'address': 25,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>, {'': [23, 24]}),\n",
      "                  'feats': '',\n",
      "                  'head': 22,\n",
      "                  'lemma': 'veto',\n",
      "                  'rel': '',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'veto'},\n",
      "             26: {'address': 26,\n",
      "                  'ctag': 'TO',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 27,\n",
      "                  'lemma': 'to',\n",
      "                  'rel': '',\n",
      "                  'tag': 'TO',\n",
      "                  'word': 'to'},\n",
      "             27: {'address': 27,\n",
      "                  'ctag': 'VB',\n",
      "                  'deps': defaultdict(<class 'list'>, {'': [26, 30]}),\n",
      "                  'feats': '',\n",
      "                  'head': 21,\n",
      "                  'lemma': 'provoke',\n",
      "                  'rel': '',\n",
      "                  'tag': 'VB',\n",
      "                  'word': 'provoke'},\n",
      "             28: {'address': 28,\n",
      "                  'ctag': 'DT',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 30,\n",
      "                  'lemma': 'a',\n",
      "                  'rel': '',\n",
      "                  'tag': 'DT',\n",
      "                  'word': 'a'},\n",
      "             29: {'address': 29,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 30,\n",
      "                  'lemma': 'test',\n",
      "                  'rel': '',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'test'},\n",
      "             30: {'address': 30,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>, {'': [28, 29]}),\n",
      "                  'feats': '',\n",
      "                  'head': 27,\n",
      "                  'lemma': 'case',\n",
      "                  'rel': '',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'case'},\n",
      "             31: {'address': 31,\n",
      "                  'ctag': '.',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 5,\n",
      "                  'lemma': '.',\n",
      "                  'rel': '',\n",
      "                  'tag': '.',\n",
      "                  'word': '.'}})\n"
     ]
    }
   ],
   "source": [
    "# parsing takes a list of dependency graphs and a model as arguments\n",
    "parses = tp.parse(dependency_treebank.parsed_sents()[-10:], 'tp.model')\n",
    "print(len(parses))\n",
    "print(parses[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. Evaluation of Dependency Parsing\n",
    "\n",
    "Dependency Parsing performance is evaluated as __labeled__ and __unlabeled attachment scores__ which are calculated as \n",
    "\n",
    "$$ UAS/LAS = \\frac{\\text{# of corrent dependency relations}}{\\text{# of dependency relations}}$$\n",
    "\n",
    "the difference between the two is whether the relation labels are considered or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "NLTK provides `DependencyEvaluator` class to perform the evaluation, that takes predicted and reference parses as arguments. The evaluation ignores punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "ExecuteTime": {
     "end_time": "2023-05-31T02:50:55.514126800Z",
     "start_time": "2023-05-31T02:50:54.864397700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7791666666666667\n",
      "0.7791666666666667\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse import DependencyEvaluator\n",
    "\n",
    "de = DependencyEvaluator(parses, dependency_treebank.parsed_sents()[-10:])\n",
    "las, uas = de.eval()\n",
    "\n",
    "# no labels, thus identical\n",
    "print(las)\n",
    "print(uas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise\n",
    "- Train `arc-standard` and `arc-eager` transition parsers on the same portion (slightly bigger than 100, otherwise it takes a lot of time)\n",
    "- Evaluate both of them comparing the attachment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "ExecuteTime": {
     "end_time": "2023-05-31T02:57:01.740777600Z",
     "start_time": "2023-05-31T02:56:06.548976800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 250\n",
      " Number of valid (projective) examples : 250\n",
      "0.8187292984040951\n",
      "0.8187292984040951\n"
     ]
    }
   ],
   "source": [
    "tp = TransitionParser('arc-standard')\n",
    "n_training = 250\n",
    "tp.train(dependency_treebank.parsed_sents()[:n_training], 'tp.model', verbose=False)\n",
    "\n",
    "parses = tp.parse(dependency_treebank.parsed_sents()[-150:], 'tp.model')\n",
    "\n",
    "de = DependencyEvaluator(parses, dependency_treebank.parsed_sents()[-150:])\n",
    "arc_standard_las, arc_standard_uas = de.eval()\n",
    "\n",
    "# no labels, thus identical\n",
    "print(arc_standard_las)\n",
    "print(arc_standard_uas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 250\n",
      " Number of valid (projective) examples : 250\n",
      "0.8181270701595905\n",
      "0.8181270701595905\n"
     ]
    }
   ],
   "source": [
    "tp = TransitionParser('arc-eager')\n",
    "n_training = 250\n",
    "tp.train(dependency_treebank.parsed_sents()[:n_training], 'tp.model', verbose=False)\n",
    "\n",
    "parses = tp.parse(dependency_treebank.parsed_sents()[-150:], 'tp.model')\n",
    "\n",
    "de = DependencyEvaluator(parses, dependency_treebank.parsed_sents()[-150:])\n",
    "\n",
    "arc_eager_las, arc_eager_uas = de.eval()\n",
    "\n",
    "# no labels, thus identical\n",
    "print(arc_eager_las)\n",
    "print(arc_eager_uas)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T02:55:55.105747700Z",
     "start_time": "2023-05-31T02:54:45.260135500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T02:57:01.753805500Z",
     "start_time": "2023-05-31T02:57:01.740777600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arc-standard LAS:  0.8187292984040951\n",
      "Arc-standard UAS:  0.8187292984040951\n",
      "\n",
      "Arc-eager LAS:  0.8181270701595905\n",
      "Arc-eager UAS:  0.8181270701595905\n"
     ]
    }
   ],
   "source": [
    "# Print Arc-standard results\n",
    "print(\"Arc-standard LAS: \", arc_standard_las)\n",
    "print(\"Arc-standard UAS: \", arc_standard_uas)\n",
    "print()\n",
    "# Print Acr-eager results\n",
    "print(\"Arc-eager LAS: \", arc_eager_las)\n",
    "print(\"Arc-eager UAS: \", arc_eager_uas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5. Dependency Parsing with Stanza and Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Both spaCy and Stanza (python package Stanford NLP Tools) provide pre-trained dependency parsing models.\n",
    "The libraries are quite similar in usage.\n",
    "\n",
    "- initialize pipeline (with other processing steps such as tokenization, POS-tagging)\n",
    "- process a sentence \n",
    "- iterate over tokens accessing dependency parsing attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.1. Stanford Dependency Parser\n",
    "\n",
    "[paper on stanza](https://arxiv.org/pdf/2003.07082.pdf)\n",
    "\n",
    "A neural graph-based dependency parser. \n",
    "[paper on parser](https://nlp.stanford.edu/pubs/dozat2017deep.pdf)\n",
    "\n",
    "> We implement a Bi-LSTM-based deep biaffine neural dependency parser (Dozat and Manning, 2017). We\n",
    "further augment this model with two linguistically motivated features: one that predicts the linearization order of two words in a given language, and the other that predicts the typical distance in linear order between them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.2. Spacy Dependency Parser\n",
    "\n",
    "> A transition-based dependency parser component. The dependency parser jointly learns sentence segmentation and labelled dependency parsing, and can optionally learn to merge tokens that had been over-segmented by the tokenizer. The parser uses a variant of the non-monotonic arc-eager transition-system described by Honnibal and Johnson (2014), with the addition of a \"break\" transition to perform the sentence segmentation. Nivre (2005)’s pseudo-projective dependency transformation is used to allow the parser to predict non-projective parses.\n",
    "\n",
    "> The parser is trained using an imitation learning objective. It follows the actions predicted by the current weights, and at each state, determines which actions are compatible with the optimal parse that could be reached from the current state. The weights are updated such that the scores assigned to the set of optimal actions is increased, while scores assigned to other actions are decreased. Note that more than one action may be optimal for a given state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "ExecuteTime": {
     "end_time": "2023-06-01T02:36:03.103142100Z",
     "start_time": "2023-06-01T02:36:03.039016600Z"
    }
   },
   "outputs": [],
   "source": [
    "example = 'I saw the man with a telescope.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install stanza"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T03:02:34.287085Z",
     "start_time": "2023-05-31T02:58:28.243645700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "ExecuteTime": {
     "end_time": "2023-05-31T03:18:32.405500Z",
     "start_time": "2023-05-31T03:07:36.950783900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2e5efad32a54ddbb4c3e005cb2461a3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 05:07:42 INFO: Downloading default packages for language: en (English) ...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.5.0/models/default.zip:   0%|          | 0…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eee64ff2af254daebaa883742f3ef327"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 05:18:32 INFO: Finished downloading models and saved to C:\\Users\\adnan\\stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "# stanza example\n",
    "import stanza\n",
    "\n",
    "# Download the stanza model if necessary\n",
    "stanza.download(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "[\n  [\n    {\n      \"id\": 1,\n      \"text\": \"I\",\n      \"lemma\": \"I\",\n      \"upos\": \"PRON\",\n      \"xpos\": \"PRP\",\n      \"feats\": \"Case=Nom|Number=Sing|Person=1|PronType=Prs\",\n      \"head\": 2,\n      \"deprel\": \"nsubj\",\n      \"start_char\": 0,\n      \"end_char\": 1,\n      \"ner\": \"O\",\n      \"multi_ner\": [\n        \"O\"\n      ]\n    },\n    {\n      \"id\": 2,\n      \"text\": \"saw\",\n      \"lemma\": \"see\",\n      \"upos\": \"VERB\",\n      \"xpos\": \"VBD\",\n      \"feats\": \"Mood=Ind|Number=Sing|Person=1|Tense=Past|VerbForm=Fin\",\n      \"head\": 0,\n      \"deprel\": \"root\",\n      \"start_char\": 2,\n      \"end_char\": 5,\n      \"ner\": \"O\",\n      \"multi_ner\": [\n        \"O\"\n      ]\n    },\n    {\n      \"id\": 3,\n      \"text\": \"the\",\n      \"lemma\": \"the\",\n      \"upos\": \"DET\",\n      \"xpos\": \"DT\",\n      \"feats\": \"Definite=Def|PronType=Art\",\n      \"head\": 4,\n      \"deprel\": \"det\",\n      \"start_char\": 6,\n      \"end_char\": 9,\n      \"ner\": \"O\",\n      \"multi_ner\": [\n        \"O\"\n      ]\n    },\n    {\n      \"id\": 4,\n      \"text\": \"man\",\n      \"lemma\": \"man\",\n      \"upos\": \"NOUN\",\n      \"xpos\": \"NN\",\n      \"feats\": \"Number=Sing\",\n      \"head\": 2,\n      \"deprel\": \"obj\",\n      \"start_char\": 10,\n      \"end_char\": 13,\n      \"ner\": \"O\",\n      \"multi_ner\": [\n        \"O\"\n      ]\n    },\n    {\n      \"id\": 5,\n      \"text\": \"with\",\n      \"lemma\": \"with\",\n      \"upos\": \"ADP\",\n      \"xpos\": \"IN\",\n      \"head\": 7,\n      \"deprel\": \"case\",\n      \"start_char\": 14,\n      \"end_char\": 18,\n      \"ner\": \"O\",\n      \"multi_ner\": [\n        \"O\"\n      ]\n    },\n    {\n      \"id\": 6,\n      \"text\": \"a\",\n      \"lemma\": \"a\",\n      \"upos\": \"DET\",\n      \"xpos\": \"DT\",\n      \"feats\": \"Definite=Ind|PronType=Art\",\n      \"head\": 7,\n      \"deprel\": \"det\",\n      \"start_char\": 19,\n      \"end_char\": 20,\n      \"ner\": \"O\",\n      \"multi_ner\": [\n        \"O\"\n      ]\n    },\n    {\n      \"id\": 7,\n      \"text\": \"telescope\",\n      \"lemma\": \"telescope\",\n      \"upos\": \"NOUN\",\n      \"xpos\": \"NN\",\n      \"feats\": \"Number=Sing\",\n      \"head\": 2,\n      \"deprel\": \"obl\",\n      \"start_char\": 21,\n      \"end_char\": 30,\n      \"ner\": \"O\",\n      \"multi_ner\": [\n        \"O\"\n      ]\n    },\n    {\n      \"id\": 8,\n      \"text\": \".\",\n      \"lemma\": \".\",\n      \"upos\": \"PUNCT\",\n      \"xpos\": \".\",\n      \"head\": 2,\n      \"deprel\": \"punct\",\n      \"start_char\": 30,\n      \"end_char\": 31,\n      \"ner\": \"O\",\n      \"multi_ner\": [\n        \"O\"\n      ]\n    }\n  ]\n]"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stanza_nlp = stanza.Pipeline(lang='en', verbose=False)\n",
    "stanza_doc = stanza_nlp(example)\n",
    "stanza_doc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T03:27:59.951191300Z",
     "start_time": "2023-05-31T03:27:55.873388100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "[[\n   {\n     \"id\": 1,\n     \"text\": \"I\",\n     \"lemma\": \"I\",\n     \"upos\": \"PRON\",\n     \"xpos\": \"PRP\",\n     \"feats\": \"Case=Nom|Number=Sing|Person=1|PronType=Prs\",\n     \"head\": 2,\n     \"deprel\": \"nsubj\",\n     \"start_char\": 0,\n     \"end_char\": 1,\n     \"ner\": \"O\",\n     \"multi_ner\": [\n       \"O\"\n     ]\n   },\n   {\n     \"id\": 2,\n     \"text\": \"saw\",\n     \"lemma\": \"see\",\n     \"upos\": \"VERB\",\n     \"xpos\": \"VBD\",\n     \"feats\": \"Mood=Ind|Number=Sing|Person=1|Tense=Past|VerbForm=Fin\",\n     \"head\": 0,\n     \"deprel\": \"root\",\n     \"start_char\": 2,\n     \"end_char\": 5,\n     \"ner\": \"O\",\n     \"multi_ner\": [\n       \"O\"\n     ]\n   },\n   {\n     \"id\": 3,\n     \"text\": \"the\",\n     \"lemma\": \"the\",\n     \"upos\": \"DET\",\n     \"xpos\": \"DT\",\n     \"feats\": \"Definite=Def|PronType=Art\",\n     \"head\": 4,\n     \"deprel\": \"det\",\n     \"start_char\": 6,\n     \"end_char\": 9,\n     \"ner\": \"O\",\n     \"multi_ner\": [\n       \"O\"\n     ]\n   },\n   {\n     \"id\": 4,\n     \"text\": \"man\",\n     \"lemma\": \"man\",\n     \"upos\": \"NOUN\",\n     \"xpos\": \"NN\",\n     \"feats\": \"Number=Sing\",\n     \"head\": 2,\n     \"deprel\": \"obj\",\n     \"start_char\": 10,\n     \"end_char\": 13,\n     \"ner\": \"O\",\n     \"multi_ner\": [\n       \"O\"\n     ]\n   },\n   {\n     \"id\": 5,\n     \"text\": \"with\",\n     \"lemma\": \"with\",\n     \"upos\": \"ADP\",\n     \"xpos\": \"IN\",\n     \"head\": 7,\n     \"deprel\": \"case\",\n     \"start_char\": 14,\n     \"end_char\": 18,\n     \"ner\": \"O\",\n     \"multi_ner\": [\n       \"O\"\n     ]\n   },\n   {\n     \"id\": 6,\n     \"text\": \"a\",\n     \"lemma\": \"a\",\n     \"upos\": \"DET\",\n     \"xpos\": \"DT\",\n     \"feats\": \"Definite=Ind|PronType=Art\",\n     \"head\": 7,\n     \"deprel\": \"det\",\n     \"start_char\": 19,\n     \"end_char\": 20,\n     \"ner\": \"O\",\n     \"multi_ner\": [\n       \"O\"\n     ]\n   },\n   {\n     \"id\": 7,\n     \"text\": \"telescope\",\n     \"lemma\": \"telescope\",\n     \"upos\": \"NOUN\",\n     \"xpos\": \"NN\",\n     \"feats\": \"Number=Sing\",\n     \"head\": 2,\n     \"deprel\": \"obl\",\n     \"start_char\": 21,\n     \"end_char\": 30,\n     \"ner\": \"O\",\n     \"multi_ner\": [\n       \"O\"\n     ]\n   },\n   {\n     \"id\": 8,\n     \"text\": \".\",\n     \"lemma\": \".\",\n     \"upos\": \"PUNCT\",\n     \"xpos\": \".\",\n     \"head\": 2,\n     \"deprel\": \"punct\",\n     \"start_char\": 30,\n     \"end_char\": 31,\n     \"ner\": \"O\",\n     \"multi_ner\": [\n       \"O\"\n     ]\n   }\n ]]"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stanza_doc.sentences"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T03:28:16.385672900Z",
     "start_time": "2023-05-31T03:28:16.339429700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I', 2, 'nsubj')\n",
      "('saw', 0, 'root')\n",
      "('the', 4, 'det')\n",
      "('man', 2, 'obj')\n",
      "('with', 7, 'case')\n",
      "('a', 7, 'det')\n",
      "('telescope', 2, 'obl')\n",
      "('.', 2, 'punct')\n"
     ]
    }
   ],
   "source": [
    "stanza_doc.sentences[0].print_dependencies()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T03:28:25.952231600Z",
     "start_time": "2023-05-31T03:28:25.933233600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tI\t2\tnsubj\n",
      "2\tsaw\t0\troot\n",
      "3\tthe\t4\tdet\n",
      "4\tman\t2\tobj\n",
      "5\twith\t7\tcase\n",
      "6\ta\t7\tdet\n",
      "7\ttelescope\t2\tobl\n",
      "8\t.\t2\tpunct\n"
     ]
    }
   ],
   "source": [
    "for sent in stanza_doc.sentences:\n",
    "    for word in sent.words:\n",
    "        print(\"{}\\t{}\\t{}\\t{}\".format(word.id, word.text, word.head, word.deprel))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T03:28:35.702316800Z",
     "start_time": "2023-05-31T03:28:35.687321Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "ExecuteTime": {
     "end_time": "2023-06-01T02:35:45.527013100Z",
     "start_time": "2023-06-01T02:35:22.249224400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/12.8 MB 2.0 MB/s eta 0:00:07\n",
      "     ---------------------------------------- 0.1/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     ---------------------------------------- 0.1/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     ---------------------------------------- 0.1/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     ---------------------------------------- 0.1/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "      --------------------------------------- 0.3/12.8 MB 1.0 MB/s eta 0:00:13\n",
      "      --------------------------------------- 0.3/12.8 MB 1.0 MB/s eta 0:00:13\n",
      "     - -------------------------------------- 0.4/12.8 MB 1.0 MB/s eta 0:00:13\n",
      "     - ------------------------------------- 0.4/12.8 MB 958.4 kB/s eta 0:00:13\n",
      "     - ------------------------------------- 0.4/12.8 MB 958.4 kB/s eta 0:00:13\n",
      "     - ------------------------------------- 0.5/12.8 MB 992.3 kB/s eta 0:00:13\n",
      "     - ------------------------------------- 0.5/12.8 MB 992.3 kB/s eta 0:00:13\n",
      "     - ------------------------------------- 0.6/12.8 MB 948.1 kB/s eta 0:00:13\n",
      "     - ------------------------------------- 0.6/12.8 MB 982.6 kB/s eta 0:00:13\n",
      "     -- ------------------------------------ 0.7/12.8 MB 967.4 kB/s eta 0:00:13\n",
      "     -- ------------------------------------ 0.7/12.8 MB 968.5 kB/s eta 0:00:13\n",
      "     -- ------------------------------------ 0.8/12.8 MB 975.9 kB/s eta 0:00:13\n",
      "     -- ------------------------------------ 0.8/12.8 MB 952.3 kB/s eta 0:00:13\n",
      "     -- ------------------------------------ 0.8/12.8 MB 964.5 kB/s eta 0:00:13\n",
      "     -- ------------------------------------ 0.9/12.8 MB 972.0 kB/s eta 0:00:13\n",
      "     -- ------------------------------------ 0.9/12.8 MB 967.1 kB/s eta 0:00:13\n",
      "     -- ------------------------------------ 1.0/12.8 MB 977.2 kB/s eta 0:00:13\n",
      "     --- ----------------------------------- 1.0/12.8 MB 958.5 kB/s eta 0:00:13\n",
      "     --- ----------------------------------- 1.0/12.8 MB 963.3 kB/s eta 0:00:13\n",
      "     --- ----------------------------------- 1.1/12.8 MB 964.8 kB/s eta 0:00:13\n",
      "     --- ----------------------------------- 1.1/12.8 MB 969.8 kB/s eta 0:00:13\n",
      "     --- ----------------------------------- 1.2/12.8 MB 961.8 kB/s eta 0:00:13\n",
      "     --- ----------------------------------- 1.2/12.8 MB 951.3 kB/s eta 0:00:13\n",
      "     --- ----------------------------------- 1.3/12.8 MB 960.0 kB/s eta 0:00:12\n",
      "     --- ----------------------------------- 1.3/12.8 MB 956.2 kB/s eta 0:00:13\n",
      "     ---- ---------------------------------- 1.4/12.8 MB 950.5 kB/s eta 0:00:13\n",
      "     ---- ---------------------------------- 1.4/12.8 MB 955.0 kB/s eta 0:00:12\n",
      "     ---- ---------------------------------- 1.5/12.8 MB 959.2 kB/s eta 0:00:12\n",
      "     ---- ---------------------------------- 1.5/12.8 MB 950.0 kB/s eta 0:00:12\n",
      "     ---- ---------------------------------- 1.5/12.8 MB 954.0 kB/s eta 0:00:12\n",
      "     ---- ---------------------------------- 1.6/12.8 MB 946.1 kB/s eta 0:00:12\n",
      "     ---- ---------------------------------- 1.6/12.8 MB 938.0 kB/s eta 0:00:12\n",
      "     ----- --------------------------------- 1.7/12.8 MB 950.2 kB/s eta 0:00:12\n",
      "     ----- --------------------------------- 1.7/12.8 MB 945.9 kB/s eta 0:00:12\n",
      "     ----- --------------------------------- 1.7/12.8 MB 946.7 kB/s eta 0:00:12\n",
      "     ----- --------------------------------- 1.8/12.8 MB 947.6 kB/s eta 0:00:12\n",
      "     ----- --------------------------------- 1.8/12.8 MB 948.3 kB/s eta 0:00:12\n",
      "     ----- --------------------------------- 1.9/12.8 MB 944.0 kB/s eta 0:00:12\n",
      "     ----- --------------------------------- 1.9/12.8 MB 947.9 kB/s eta 0:00:12\n",
      "     ------ -------------------------------- 2.0/12.8 MB 951.1 kB/s eta 0:00:12\n",
      "     ------ -------------------------------- 2.0/12.8 MB 951.2 kB/s eta 0:00:12\n",
      "     ------ -------------------------------- 2.0/12.8 MB 945.2 kB/s eta 0:00:12\n",
      "     ------ -------------------------------- 2.1/12.8 MB 948.2 kB/s eta 0:00:12\n",
      "     ------ -------------------------------- 2.2/12.8 MB 949.0 kB/s eta 0:00:12\n",
      "     ------ -------------------------------- 2.2/12.8 MB 945.7 kB/s eta 0:00:12\n",
      "     ------ -------------------------------- 2.3/12.8 MB 950.8 kB/s eta 0:00:12\n",
      "     ------- ------------------------------- 2.3/12.8 MB 949.2 kB/s eta 0:00:12\n",
      "     ------- ------------------------------- 2.4/12.8 MB 953.9 kB/s eta 0:00:11\n",
      "     ------- ------------------------------- 2.4/12.8 MB 948.8 kB/s eta 0:00:11\n",
      "     ------- ------------------------------- 2.5/12.8 MB 949.3 kB/s eta 0:00:11\n",
      "     ------- ------------------------------- 2.5/12.8 MB 946.1 kB/s eta 0:00:11\n",
      "     ------- ------------------------------- 2.6/12.8 MB 948.6 kB/s eta 0:00:11\n",
      "     ------- ------------------------------- 2.6/12.8 MB 951.0 kB/s eta 0:00:11\n",
      "     -------- ------------------------------ 2.6/12.8 MB 951.4 kB/s eta 0:00:11\n",
      "     -------- ------------------------------ 2.7/12.8 MB 953.7 kB/s eta 0:00:11\n",
      "     -------- ------------------------------ 2.7/12.8 MB 952.4 kB/s eta 0:00:11\n",
      "     -------- ------------------------------ 2.8/12.8 MB 949.7 kB/s eta 0:00:11\n",
      "     -------- ------------------------------ 2.8/12.8 MB 950.1 kB/s eta 0:00:11\n",
      "     -------- ------------------------------ 2.9/12.8 MB 953.7 kB/s eta 0:00:11\n",
      "     -------- ------------------------------ 2.9/12.8 MB 949.4 kB/s eta 0:00:11\n",
      "     -------- ------------------------------ 2.9/12.8 MB 949.9 kB/s eta 0:00:11\n",
      "     --------- ----------------------------- 3.0/12.8 MB 952.0 kB/s eta 0:00:11\n",
      "     --------- ----------------------------- 3.0/12.8 MB 952.3 kB/s eta 0:00:11\n",
      "     --------- ----------------------------- 3.1/12.8 MB 951.5 kB/s eta 0:00:11\n",
      "     --------- ----------------------------- 3.1/12.8 MB 951.9 kB/s eta 0:00:11\n",
      "     --------- ----------------------------- 3.2/12.8 MB 953.8 kB/s eta 0:00:11\n",
      "     --------- ----------------------------- 3.2/12.8 MB 952.7 kB/s eta 0:00:11\n",
      "     --------- ----------------------------- 3.3/12.8 MB 950.1 kB/s eta 0:00:11\n",
      "     ---------- ---------------------------- 3.3/12.8 MB 950.5 kB/s eta 0:00:10\n",
      "     ---------- ---------------------------- 3.4/12.8 MB 952.4 kB/s eta 0:00:10\n",
      "     ---------- ---------------------------- 3.4/12.8 MB 954.2 kB/s eta 0:00:10\n",
      "     ---------- ---------------------------- 3.5/12.8 MB 949.1 kB/s eta 0:00:10\n",
      "     ---------- ---------------------------- 3.5/12.8 MB 952.3 kB/s eta 0:00:10\n",
      "     ---------- ---------------------------- 3.5/12.8 MB 954.0 kB/s eta 0:00:10\n",
      "     ---------- ---------------------------- 3.6/12.8 MB 954.1 kB/s eta 0:00:10\n",
      "     ----------- --------------------------- 3.6/12.8 MB 952.0 kB/s eta 0:00:10\n",
      "     ----------- --------------------------- 3.7/12.8 MB 953.7 kB/s eta 0:00:10\n",
      "     ----------- --------------------------- 3.7/12.8 MB 954.0 kB/s eta 0:00:10\n",
      "     ----------- --------------------------- 3.8/12.8 MB 951.7 kB/s eta 0:00:10\n",
      "     ----------- --------------------------- 3.8/12.8 MB 950.8 kB/s eta 0:00:10\n",
      "     ----------- --------------------------- 3.9/12.8 MB 952.6 kB/s eta 0:00:10\n",
      "     ----------- --------------------------- 3.9/12.8 MB 952.7 kB/s eta 0:00:10\n",
      "     ----------- --------------------------- 3.9/12.8 MB 950.8 kB/s eta 0:00:10\n",
      "     ------------ -------------------------- 4.0/12.8 MB 952.3 kB/s eta 0:00:10\n",
      "     ------------ -------------------------- 4.0/12.8 MB 953.9 kB/s eta 0:00:10\n",
      "     ------------ -------------------------- 4.1/12.8 MB 955.3 kB/s eta 0:00:10\n",
      "     ------------ -------------------------- 4.1/12.8 MB 951.1 kB/s eta 0:00:10\n",
      "     ------------ -------------------------- 4.2/12.8 MB 952.6 kB/s eta 0:00:10\n",
      "     ------------ -------------------------- 4.2/12.8 MB 950.6 kB/s eta 0:00:10\n",
      "     ------------- ------------------------- 4.3/12.8 MB 952.1 kB/s eta 0:00:09\n",
      "     ------------- ------------------------- 4.3/12.8 MB 953.7 kB/s eta 0:00:09\n",
      "     ------------- ------------------------- 4.4/12.8 MB 952.9 kB/s eta 0:00:09\n",
      "     ------------- ------------------------- 4.4/12.8 MB 952.0 kB/s eta 0:00:09\n",
      "     ------------- ------------------------- 4.5/12.8 MB 951.2 kB/s eta 0:00:09\n",
      "     ------------- ------------------------- 4.5/12.8 MB 953.7 kB/s eta 0:00:09\n",
      "     ------------- ------------------------- 4.5/12.8 MB 949.7 kB/s eta 0:00:09\n",
      "     ------------- ------------------------- 4.6/12.8 MB 951.0 kB/s eta 0:00:09\n",
      "     -------------- ------------------------ 4.6/12.8 MB 951.3 kB/s eta 0:00:09\n",
      "     -------------- ------------------------ 4.7/12.8 MB 952.6 kB/s eta 0:00:09\n",
      "     -------------- ------------------------ 4.7/12.8 MB 951.0 kB/s eta 0:00:09\n",
      "     -------------- ------------------------ 4.8/12.8 MB 941.1 kB/s eta 0:00:09\n",
      "     --------------- ----------------------- 5.0/12.8 MB 947.3 kB/s eta 0:00:09\n",
      "     --------------- ----------------------- 5.2/12.8 MB 950.9 kB/s eta 0:00:09\n",
      "     --------------- ----------------------- 5.2/12.8 MB 950.9 kB/s eta 0:00:09\n",
      "     --------------- ----------------------- 5.2/12.8 MB 949.5 kB/s eta 0:00:08\n",
      "     ---------------- ---------------------- 5.3/12.8 MB 948.9 kB/s eta 0:00:08\n",
      "     ---------------- ---------------------- 5.3/12.8 MB 950.0 kB/s eta 0:00:08\n",
      "     ---------------- ---------------------- 5.4/12.8 MB 948.7 kB/s eta 0:00:08\n",
      "     ---------------- ---------------------- 5.4/12.8 MB 949.8 kB/s eta 0:00:08\n",
      "     ---------------- ---------------------- 5.5/12.8 MB 949.9 kB/s eta 0:00:08\n",
      "     ---------------- ---------------------- 5.5/12.8 MB 951.2 kB/s eta 0:00:08\n",
      "     ---------------- ---------------------- 5.6/12.8 MB 949.7 kB/s eta 0:00:08\n",
      "     ----------------- --------------------- 5.6/12.8 MB 949.9 kB/s eta 0:00:08\n",
      "     ----------------- --------------------- 5.6/12.8 MB 951.0 kB/s eta 0:00:08\n",
      "     ----------------- --------------------- 5.7/12.8 MB 948.7 kB/s eta 0:00:08\n",
      "     ----------------- --------------------- 5.7/12.8 MB 946.4 kB/s eta 0:00:08\n",
      "     ----------------- --------------------- 5.8/12.8 MB 949.2 kB/s eta 0:00:08\n",
      "     ----------------- --------------------- 5.8/12.8 MB 948.6 kB/s eta 0:00:08\n",
      "     ----------------- --------------------- 5.8/12.8 MB 948.1 kB/s eta 0:00:08\n",
      "     ----------------- --------------------- 5.9/12.8 MB 949.2 kB/s eta 0:00:08\n",
      "     ------------------ -------------------- 5.9/12.8 MB 949.3 kB/s eta 0:00:08\n",
      "     ------------------ -------------------- 6.0/12.8 MB 948.1 kB/s eta 0:00:08\n",
      "     ------------------ -------------------- 6.0/12.8 MB 946.6 kB/s eta 0:00:08\n",
      "     ------------------ -------------------- 6.1/12.8 MB 947.7 kB/s eta 0:00:08\n",
      "     ------------------ -------------------- 6.1/12.8 MB 947.1 kB/s eta 0:00:08\n",
      "     ------------------ -------------------- 6.2/12.8 MB 946.8 kB/s eta 0:00:08\n",
      "     ------------------ -------------------- 6.2/12.8 MB 947.0 kB/s eta 0:00:07\n",
      "     ------------------- ------------------- 6.2/12.8 MB 948.0 kB/s eta 0:00:07\n",
      "     ------------------- ------------------- 6.3/12.8 MB 946.7 kB/s eta 0:00:07\n",
      "     ------------------- ------------------- 6.3/12.8 MB 946.2 kB/s eta 0:00:07\n",
      "     ------------------- ------------------- 6.4/12.8 MB 948.0 kB/s eta 0:00:07\n",
      "     ------------------- ------------------- 6.4/12.8 MB 947.4 kB/s eta 0:00:07\n",
      "     ------------------- ------------------- 6.5/12.8 MB 946.3 kB/s eta 0:00:07\n",
      "     ------------------- ------------------- 6.5/12.8 MB 946.4 kB/s eta 0:00:07\n",
      "     ------------------- ------------------- 6.6/12.8 MB 947.5 kB/s eta 0:00:07\n",
      "     -------------------- ------------------ 6.6/12.8 MB 947.5 kB/s eta 0:00:07\n",
      "     -------------------- ------------------ 6.7/12.8 MB 947.2 kB/s eta 0:00:07\n",
      "     -------------------- ------------------ 6.7/12.8 MB 948.2 kB/s eta 0:00:07\n",
      "     -------------------- ------------------ 6.7/12.8 MB 947.7 kB/s eta 0:00:07\n",
      "     -------------------- ------------------ 6.8/12.8 MB 949.3 kB/s eta 0:00:07\n",
      "     -------------------- ------------------ 6.8/12.8 MB 946.8 kB/s eta 0:00:07\n",
      "     -------------------- ------------------ 6.9/12.8 MB 947.7 kB/s eta 0:00:07\n",
      "     --------------------- ----------------- 6.9/12.8 MB 948.6 kB/s eta 0:00:07\n",
      "     --------------------- ----------------- 7.0/12.8 MB 948.8 kB/s eta 0:00:07\n",
      "     --------------------- ----------------- 7.0/12.8 MB 947.7 kB/s eta 0:00:07\n",
      "     --------------------- ----------------- 7.0/12.8 MB 948.5 kB/s eta 0:00:07\n",
      "     --------------------- ----------------- 7.1/12.8 MB 948.7 kB/s eta 0:00:07\n",
      "     --------------------- ----------------- 7.2/12.8 MB 949.1 kB/s eta 0:00:06\n",
      "     --------------------- ----------------- 7.2/12.8 MB 947.9 kB/s eta 0:00:06\n",
      "     ---------------------- ---------------- 7.2/12.8 MB 948.1 kB/s eta 0:00:06\n",
      "     ---------------------- ---------------- 7.3/12.8 MB 949.0 kB/s eta 0:00:06\n",
      "     ---------------------- ---------------- 7.3/12.8 MB 947.9 kB/s eta 0:00:06\n",
      "     ---------------------- ---------------- 7.4/12.8 MB 948.9 kB/s eta 0:00:06\n",
      "     ---------------------- ---------------- 7.4/12.8 MB 948.9 kB/s eta 0:00:06\n",
      "     ---------------------- ---------------- 7.5/12.8 MB 949.7 kB/s eta 0:00:06\n",
      "     ---------------------- ---------------- 7.5/12.8 MB 948.8 kB/s eta 0:00:06\n",
      "     ----------------------- --------------- 7.6/12.8 MB 948.3 kB/s eta 0:00:06\n",
      "     ----------------------- --------------- 7.6/12.8 MB 949.8 kB/s eta 0:00:06\n",
      "     ----------------------- --------------- 7.6/12.8 MB 949.9 kB/s eta 0:00:06\n",
      "     ----------------------- --------------- 7.7/12.8 MB 948.2 kB/s eta 0:00:06\n",
      "     ----------------------- --------------- 7.7/12.8 MB 948.4 kB/s eta 0:00:06\n",
      "     ----------------------- --------------- 7.8/12.8 MB 949.2 kB/s eta 0:00:06\n",
      "     ----------------------- --------------- 7.8/12.8 MB 950.0 kB/s eta 0:00:06\n",
      "     ----------------------- --------------- 7.9/12.8 MB 950.2 kB/s eta 0:00:06\n",
      "     ------------------------ -------------- 7.9/12.8 MB 949.2 kB/s eta 0:00:06\n",
      "     ------------------------ -------------- 8.0/12.8 MB 950.0 kB/s eta 0:00:06\n",
      "     ------------------------ -------------- 8.0/12.8 MB 950.8 kB/s eta 0:00:06\n",
      "     ------------------------ -------------- 8.1/12.8 MB 948.6 kB/s eta 0:00:06\n",
      "     ------------------------- ------------- 8.2/12.8 MB 949.2 kB/s eta 0:00:05\n",
      "     ------------------------- ------------- 8.3/12.8 MB 942.5 kB/s eta 0:00:05\n",
      "     ------------------------- ------------- 8.5/12.8 MB 943.6 kB/s eta 0:00:05\n",
      "     -------------------------- ------------ 8.5/12.8 MB 949.4 kB/s eta 0:00:05\n",
      "     -------------------------- ------------ 8.6/12.8 MB 950.2 kB/s eta 0:00:05\n",
      "     -------------------------- ------------ 8.6/12.8 MB 950.2 kB/s eta 0:00:05\n",
      "     -------------------------- ------------ 8.7/12.8 MB 950.4 kB/s eta 0:00:05\n",
      "     -------------------------- ------------ 8.7/12.8 MB 949.5 kB/s eta 0:00:05\n",
      "     -------------------------- ------------ 8.8/12.8 MB 950.2 kB/s eta 0:00:05\n",
      "     -------------------------- ------------ 8.8/12.8 MB 950.3 kB/s eta 0:00:05\n",
      "     -------------------------- ------------ 8.8/12.8 MB 950.5 kB/s eta 0:00:05\n",
      "     --------------------------- ----------- 8.9/12.8 MB 950.7 kB/s eta 0:00:05\n",
      "     --------------------------- ----------- 8.9/12.8 MB 949.7 kB/s eta 0:00:05\n",
      "     --------------------------- ----------- 9.0/12.8 MB 950.4 kB/s eta 0:00:05\n",
      "     --------------------------- ----------- 9.0/12.8 MB 951.1 kB/s eta 0:00:04\n",
      "     --------------------------- ----------- 9.1/12.8 MB 950.8 kB/s eta 0:00:04\n",
      "     --------------------------- ----------- 9.1/12.8 MB 950.4 kB/s eta 0:00:04\n",
      "     --------------------------- ----------- 9.2/12.8 MB 951.1 kB/s eta 0:00:04\n",
      "     ---------------------------- ---------- 9.2/12.8 MB 951.3 kB/s eta 0:00:04\n",
      "     ---------------------------- ---------- 9.3/12.8 MB 947.5 kB/s eta 0:00:04\n",
      "     ---------------------------- ---------- 9.4/12.8 MB 949.9 kB/s eta 0:00:04\n",
      "     ---------------------------- ---------- 9.4/12.8 MB 950.0 kB/s eta 0:00:04\n",
      "     ---------------------------- ---------- 9.5/12.8 MB 949.1 kB/s eta 0:00:04\n",
      "     ---------------------------- ---------- 9.5/12.8 MB 949.6 kB/s eta 0:00:04\n",
      "     ----------------------------- --------- 9.6/12.8 MB 947.2 kB/s eta 0:00:04\n",
      "     ----------------------------- --------- 9.7/12.8 MB 947.9 kB/s eta 0:00:04\n",
      "     ------------------------------ -------- 9.9/12.8 MB 949.5 kB/s eta 0:00:04\n",
      "     ------------------------------ -------- 9.9/12.8 MB 950.6 kB/s eta 0:00:04\n",
      "     ------------------------------ -------- 9.9/12.8 MB 950.6 kB/s eta 0:00:04\n",
      "     ----------------------------- -------- 10.0/12.8 MB 949.4 kB/s eta 0:00:03\n",
      "     ----------------------------- -------- 10.0/12.8 MB 949.5 kB/s eta 0:00:03\n",
      "     ----------------------------- -------- 10.1/12.8 MB 950.2 kB/s eta 0:00:03\n",
      "     ------------------------------ ------- 10.1/12.8 MB 949.4 kB/s eta 0:00:03\n",
      "     ------------------------------ ------- 10.2/12.8 MB 949.1 kB/s eta 0:00:03\n",
      "     ------------------------------ ------- 10.2/12.8 MB 950.1 kB/s eta 0:00:03\n",
      "     ------------------------------ ------- 10.3/12.8 MB 948.9 kB/s eta 0:00:03\n",
      "     ------------------------------ ------- 10.3/12.8 MB 947.5 kB/s eta 0:00:03\n",
      "     ------------------------------ ------- 10.3/12.8 MB 947.5 kB/s eta 0:00:03\n",
      "     ------------------------------ ------- 10.4/12.8 MB 958.6 kB/s eta 0:00:03\n",
      "     ------------------------------ ------- 10.4/12.8 MB 954.4 kB/s eta 0:00:03\n",
      "     ------------------------------- ------ 10.5/12.8 MB 948.9 kB/s eta 0:00:03\n",
      "     ------------------------------- ------ 10.5/12.8 MB 948.8 kB/s eta 0:00:03\n",
      "     ------------------------------- ------ 10.6/12.8 MB 948.8 kB/s eta 0:00:03\n",
      "     ------------------------------- ------ 10.6/12.8 MB 951.6 kB/s eta 0:00:03\n",
      "     ------------------------------- ------ 10.6/12.8 MB 954.4 kB/s eta 0:00:03\n",
      "     -------------------------------- ----- 10.8/12.8 MB 952.9 kB/s eta 0:00:03\n",
      "     -------------------------------- ----- 10.9/12.8 MB 947.5 kB/s eta 0:00:02\n",
      "     -------------------------------- ----- 11.0/12.8 MB 948.9 kB/s eta 0:00:02\n",
      "     -------------------------------- ----- 11.0/12.8 MB 947.5 kB/s eta 0:00:02\n",
      "     -------------------------------- ----- 11.1/12.8 MB 948.8 kB/s eta 0:00:02\n",
      "     --------------------------------- ---- 11.2/12.8 MB 944.8 kB/s eta 0:00:02\n",
      "     --------------------------------- ---- 11.2/12.8 MB 946.1 kB/s eta 0:00:02\n",
      "     --------------------------------- ---- 11.2/12.8 MB 947.5 kB/s eta 0:00:02\n",
      "     --------------------------------- ---- 11.3/12.8 MB 947.5 kB/s eta 0:00:02\n",
      "     --------------------------------- ---- 11.3/12.8 MB 947.5 kB/s eta 0:00:02\n",
      "     --------------------------------- ---- 11.4/12.8 MB 947.5 kB/s eta 0:00:02\n",
      "     --------------------------------- ---- 11.4/12.8 MB 948.9 kB/s eta 0:00:02\n",
      "     ---------------------------------- --- 11.5/12.8 MB 948.9 kB/s eta 0:00:02\n",
      "     ---------------------------------- --- 11.5/12.8 MB 947.5 kB/s eta 0:00:02\n",
      "     ---------------------------------- --- 11.6/12.8 MB 950.3 kB/s eta 0:00:02\n",
      "     ---------------------------------- --- 11.6/12.8 MB 948.9 kB/s eta 0:00:02\n",
      "     ---------------------------------- --- 11.7/12.8 MB 948.9 kB/s eta 0:00:02\n",
      "     ---------------------------------- --- 11.7/12.8 MB 950.2 kB/s eta 0:00:02\n",
      "     ---------------------------------- --- 11.7/12.8 MB 950.2 kB/s eta 0:00:02\n",
      "     ----------------------------------- -- 11.8/12.8 MB 950.2 kB/s eta 0:00:02\n",
      "     ----------------------------------- -- 11.8/12.8 MB 951.6 kB/s eta 0:00:02\n",
      "     ----------------------------------- -- 11.9/12.8 MB 951.6 kB/s eta 0:00:01\n",
      "     ----------------------------------- -- 12.0/12.8 MB 950.3 kB/s eta 0:00:01\n",
      "     ----------------------------------- -- 12.0/12.8 MB 951.6 kB/s eta 0:00:01\n",
      "     ----------------------------------- -- 12.0/12.8 MB 950.3 kB/s eta 0:00:01\n",
      "     ----------------------------------- -- 12.1/12.8 MB 951.6 kB/s eta 0:00:01\n",
      "     ----------------------------------- -- 12.1/12.8 MB 950.3 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 12.2/12.8 MB 950.2 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 12.2/12.8 MB 950.2 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 12.3/12.8 MB 950.3 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 12.3/12.8 MB 951.6 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 12.3/12.8 MB 951.6 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 12.4/12.8 MB 951.6 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 12.5/12.8 MB 950.2 kB/s eta 0:00:01\n",
      "     -------------------------------------  12.5/12.8 MB 951.6 kB/s eta 0:00:01\n",
      "     -------------------------------------  12.5/12.8 MB 950.2 kB/s eta 0:00:01\n",
      "     -------------------------------------  12.6/12.8 MB 950.2 kB/s eta 0:00:01\n",
      "     -------------------------------------  12.6/12.8 MB 951.6 kB/s eta 0:00:01\n",
      "     -------------------------------------  12.7/12.8 MB 950.3 kB/s eta 0:00:01\n",
      "     -------------------------------------  12.7/12.8 MB 950.3 kB/s eta 0:00:01\n",
      "     -------------------------------------  12.8/12.8 MB 951.6 kB/s eta 0:00:01\n",
      "     -------------------------------------  12.8/12.8 MB 951.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 12.8/12.8 MB 946.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from en-core-web-sm==3.5.0) (3.5.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.6)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.2)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (65.6.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.24.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adnan\\appdata\\roaming\\python\\python39\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adnan\\anaconda3\\envs\\nlu-labs-venv\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
      "\u001B[38;5;2m[+] Download and installation successful\u001B[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# spacy example\n",
    "import spacy\n",
    "# download the spacy model if necessary\n",
    "!python -m spacy download en_core_web_sm\n",
    "import en_core_web_sm\n",
    "\n",
    "spacy_nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tI\tsaw\tnsubj\n",
      "1\tsaw\tsaw\tROOT\n",
      "2\tthe\tman\tdet\n",
      "3\tman\tsaw\tdobj\n",
      "4\twith\tman\tprep\n",
      "5\ta\ttelescope\tdet\n",
      "6\ttelescope\twith\tpobj\n",
      "7\t.\tsaw\tpunct\n"
     ]
    }
   ],
   "source": [
    "spacy_doc = spacy_nlp(example)\n",
    "\n",
    "for sent in spacy_doc.sents:\n",
    "    for token in sent:\n",
    "        print(\"{}\\t{}\\t{}\\t{}\".format(token.i, token.text, token.head, token.dep_))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T02:36:09.158169500Z",
     "start_time": "2023-06-01T02:36:09.112985100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Lab Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Parse 100 last sentences from dependency treebank using `spacy` and `stanza`\n",
    "    - are the depedency tags of spacy the same of stanza?\n",
    "- Evaluate the parses using DependencyEvaluator\n",
    "    - print LAS and UAS for each parser\n",
    "\n",
    "**BUT!** To evaluate the parsers, the sentences parsed by spacy and stanza have to be [`DependencyGraph`](https://www.nltk.org/_modules/nltk/parse/dependencygraph.html) objects.  To do this , you have to covert the output of the spacy/stanza to [ConLL](https://universaldependencies.org/format.html) formant, from this format extract the columns following the [Malt-Tab](https://cl.lingfil.uu.se/~nivre/research/MaltXML.html) format and finally convert the resulting string into a DependecyGraph. Luckly, there is a library that gets the job done.  You have to install the library [spacy_conll](https://github.com/BramVanroy/spacy_conll) and use and adapt to your needs the code that you can find below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Load the dependency treebank"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "['The Corps Army is cutting the flow of the River Missouri about weeks two earlier than normal because of low levels water in the reservoirs that feed it .',\n 'Barge rates sank on the River Mississippi yesterday on speculation that widespread rain might this week in the Midwest temporarily alleviate the situation .',\n 'But expects the Corps Army of Engineers the level river continue to falling this month .']"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import dependency_treebank\n",
    "\n",
    "# getting the last 100 sentences from the dependency treebank\n",
    "dependency_treebank_graphs = [sent for sent in dependency_treebank.parsed_sents()[-100:]]\n",
    "\n",
    "sentences = [\n",
    "    \" \".join([node['word'] for node in dependency_graph.nodes.values() if node['word']])\n",
    "    for dependency_graph in dependency_treebank_graphs\n",
    "]\n",
    "\n",
    "sentences[0:3]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T02:44:30.805301100Z",
     "start_time": "2023-06-01T02:44:29.026299200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Spacy Dependency Parser"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-06-01T02:45:42.662680200Z",
     "start_time": "2023-06-01T02:45:41.660683200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Spacy version \n",
    "from nltk.parse.dependencygraph import DependencyGraph\n",
    "from spacy.tokenizer import Tokenizer\n",
    "import spacy\n",
    "\n",
    "# Load the spacy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# Set up the conll formatter\n",
    "config = {\n",
    "    \"ext_names\": {\n",
    "        \"conll_pd\": \"pandas\"\n",
    "    },\n",
    "    \"conversion_maps\": {\n",
    "        \"deprel\": {\n",
    "            \"nsubj\": \"subj\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add the formatter to the pipeline\n",
    "nlp.add_pipe(\"conll_formatter\", config=config, last=True)\n",
    "\n",
    "# Split by white space\n",
    "nlp.tokenizer = Tokenizer(nlp.vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T02:45:53.537450800Z",
     "start_time": "2023-06-01T02:45:53.484448800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 Parse a sentence with spacy and convert it to a DependencyGraph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "    ID        FORM      LEMMA   UPOS XPOS  \\\n0    1         The        the    DET   DT   \n1    2       Corps      Corps  PROPN  NNP   \n2    3        Army       Army  PROPN  NNP   \n3    4          is         be    AUX  VBZ   \n4    5     cutting        cut   VERB  VBG   \n5    6         the        the    DET   DT   \n6    7        flow       flow   NOUN   NN   \n7    8          of         of    ADP   IN   \n8    9         the        the    DET   DT   \n9   10       River      River  PROPN  NNP   \n10  11    Missouri   Missouri  PROPN  NNP   \n11  12       about      about    ADP   IN   \n12  13       weeks       week   NOUN  NNS   \n13  14         two        two    NUM   CD   \n14  15     earlier      early    ADJ  JJR   \n15  16        than       than    ADP   IN   \n16  17      normal     normal    ADJ   JJ   \n17  18     because    because  SCONJ   IN   \n18  19          of         of    ADP   IN   \n19  20         low        low    ADJ   JJ   \n20  21      levels      level   NOUN  NNS   \n21  22       water      water   NOUN   NN   \n22  23          in         in    ADP   IN   \n23  24         the        the    DET   DT   \n24  25  reservoirs  reservoir   NOUN  NNS   \n25  26        that       that   PRON  WDT   \n26  27        feed       feed   VERB  VBP   \n27  28          it         it   PRON  PRP   \n28  29           .          .  PUNCT    .   \n\n                                                FEATS  HEAD    DEPREL DEPS  \\\n0                           Definite=Def|PronType=Art     3       det    _   \n1                                         Number=Sing     3  compound    _   \n2                                         Number=Sing     5     nsubj    _   \n3   Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbF...     5       aux    _   \n4                Aspect=Prog|Tense=Pres|VerbForm=Part     0      ROOT    _   \n5                           Definite=Def|PronType=Art     7       det    _   \n6                                         Number=Sing     5      dobj    _   \n7                                                   _     7      prep    _   \n8                           Definite=Def|PronType=Art    10       det    _   \n9                                         Number=Sing     8      pobj    _   \n10                                        Number=Sing    10     appos    _   \n11                                                  _     5      prep    _   \n12                                        Number=Plur    12      pobj    _   \n13                                       NumType=Card    13    nummod    _   \n14                                         Degree=Cmp    14      amod    _   \n15                                                  _    15      prep    _   \n16                                         Degree=Pos    16      amod    _   \n17                                                  _     5      prep    _   \n18                                                  _    18     pcomp    _   \n19                                         Degree=Pos    21      amod    _   \n20                                        Number=Plur    22  compound    _   \n21                                        Number=Sing    18      pobj    _   \n22                                                  _    22      prep    _   \n23                          Definite=Def|PronType=Art    25       det    _   \n24                                        Number=Plur    23      pobj    _   \n25                                       PronType=Rel    27     nsubj    _   \n26                            Tense=Pres|VerbForm=Fin    25     relcl    _   \n27  Case=Acc|Gender=Neut|Number=Sing|Person=3|Pron...    27      dobj    _   \n28                                     PunctType=Peri     5     punct    _   \n\n             MISC  \n0               _  \n1               _  \n2               _  \n3               _  \n4               _  \n5               _  \n6               _  \n7               _  \n8               _  \n9               _  \n10              _  \n11              _  \n12              _  \n13              _  \n14              _  \n15              _  \n16              _  \n17              _  \n18              _  \n19              _  \n20              _  \n21              _  \n22              _  \n23              _  \n24              _  \n25              _  \n26              _  \n27              _  \n28  SpaceAfter=No  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>FORM</th>\n      <th>LEMMA</th>\n      <th>UPOS</th>\n      <th>XPOS</th>\n      <th>FEATS</th>\n      <th>HEAD</th>\n      <th>DEPREL</th>\n      <th>DEPS</th>\n      <th>MISC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>The</td>\n      <td>the</td>\n      <td>DET</td>\n      <td>DT</td>\n      <td>Definite=Def|PronType=Art</td>\n      <td>3</td>\n      <td>det</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Corps</td>\n      <td>Corps</td>\n      <td>PROPN</td>\n      <td>NNP</td>\n      <td>Number=Sing</td>\n      <td>3</td>\n      <td>compound</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Army</td>\n      <td>Army</td>\n      <td>PROPN</td>\n      <td>NNP</td>\n      <td>Number=Sing</td>\n      <td>5</td>\n      <td>nsubj</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>is</td>\n      <td>be</td>\n      <td>AUX</td>\n      <td>VBZ</td>\n      <td>Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbF...</td>\n      <td>5</td>\n      <td>aux</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>cutting</td>\n      <td>cut</td>\n      <td>VERB</td>\n      <td>VBG</td>\n      <td>Aspect=Prog|Tense=Pres|VerbForm=Part</td>\n      <td>0</td>\n      <td>ROOT</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>the</td>\n      <td>the</td>\n      <td>DET</td>\n      <td>DT</td>\n      <td>Definite=Def|PronType=Art</td>\n      <td>7</td>\n      <td>det</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>flow</td>\n      <td>flow</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>Number=Sing</td>\n      <td>5</td>\n      <td>dobj</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>of</td>\n      <td>of</td>\n      <td>ADP</td>\n      <td>IN</td>\n      <td>_</td>\n      <td>7</td>\n      <td>prep</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>the</td>\n      <td>the</td>\n      <td>DET</td>\n      <td>DT</td>\n      <td>Definite=Def|PronType=Art</td>\n      <td>10</td>\n      <td>det</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>River</td>\n      <td>River</td>\n      <td>PROPN</td>\n      <td>NNP</td>\n      <td>Number=Sing</td>\n      <td>8</td>\n      <td>pobj</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>Missouri</td>\n      <td>Missouri</td>\n      <td>PROPN</td>\n      <td>NNP</td>\n      <td>Number=Sing</td>\n      <td>10</td>\n      <td>appos</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>about</td>\n      <td>about</td>\n      <td>ADP</td>\n      <td>IN</td>\n      <td>_</td>\n      <td>5</td>\n      <td>prep</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>weeks</td>\n      <td>week</td>\n      <td>NOUN</td>\n      <td>NNS</td>\n      <td>Number=Plur</td>\n      <td>12</td>\n      <td>pobj</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>two</td>\n      <td>two</td>\n      <td>NUM</td>\n      <td>CD</td>\n      <td>NumType=Card</td>\n      <td>13</td>\n      <td>nummod</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>earlier</td>\n      <td>early</td>\n      <td>ADJ</td>\n      <td>JJR</td>\n      <td>Degree=Cmp</td>\n      <td>14</td>\n      <td>amod</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16</td>\n      <td>than</td>\n      <td>than</td>\n      <td>ADP</td>\n      <td>IN</td>\n      <td>_</td>\n      <td>15</td>\n      <td>prep</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>normal</td>\n      <td>normal</td>\n      <td>ADJ</td>\n      <td>JJ</td>\n      <td>Degree=Pos</td>\n      <td>16</td>\n      <td>amod</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>because</td>\n      <td>because</td>\n      <td>SCONJ</td>\n      <td>IN</td>\n      <td>_</td>\n      <td>5</td>\n      <td>prep</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>19</td>\n      <td>of</td>\n      <td>of</td>\n      <td>ADP</td>\n      <td>IN</td>\n      <td>_</td>\n      <td>18</td>\n      <td>pcomp</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>20</td>\n      <td>low</td>\n      <td>low</td>\n      <td>ADJ</td>\n      <td>JJ</td>\n      <td>Degree=Pos</td>\n      <td>21</td>\n      <td>amod</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>21</td>\n      <td>levels</td>\n      <td>level</td>\n      <td>NOUN</td>\n      <td>NNS</td>\n      <td>Number=Plur</td>\n      <td>22</td>\n      <td>compound</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>22</td>\n      <td>water</td>\n      <td>water</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>Number=Sing</td>\n      <td>18</td>\n      <td>pobj</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>23</td>\n      <td>in</td>\n      <td>in</td>\n      <td>ADP</td>\n      <td>IN</td>\n      <td>_</td>\n      <td>22</td>\n      <td>prep</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>24</td>\n      <td>the</td>\n      <td>the</td>\n      <td>DET</td>\n      <td>DT</td>\n      <td>Definite=Def|PronType=Art</td>\n      <td>25</td>\n      <td>det</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>25</td>\n      <td>reservoirs</td>\n      <td>reservoir</td>\n      <td>NOUN</td>\n      <td>NNS</td>\n      <td>Number=Plur</td>\n      <td>23</td>\n      <td>pobj</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>26</td>\n      <td>that</td>\n      <td>that</td>\n      <td>PRON</td>\n      <td>WDT</td>\n      <td>PronType=Rel</td>\n      <td>27</td>\n      <td>nsubj</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>27</td>\n      <td>feed</td>\n      <td>feed</td>\n      <td>VERB</td>\n      <td>VBP</td>\n      <td>Tense=Pres|VerbForm=Fin</td>\n      <td>25</td>\n      <td>relcl</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>28</td>\n      <td>it</td>\n      <td>it</td>\n      <td>PRON</td>\n      <td>PRP</td>\n      <td>Case=Acc|Gender=Neut|Number=Sing|Person=3|Pron...</td>\n      <td>27</td>\n      <td>dobj</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>29</td>\n      <td>.</td>\n      <td>.</td>\n      <td>PUNCT</td>\n      <td>.</td>\n      <td>PunctType=Peri</td>\n      <td>5</td>\n      <td>punct</td>\n      <td>_</td>\n      <td>SpaceAfter=No</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse the sentence\n",
    "doc = nlp(sentences[0])\n",
    "\n",
    "# Convert doc to a pandas object\n",
    "df = doc._.pandas\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T02:46:51.136440700Z",
     "start_time": "2023-06-01T02:46:51.058177300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       The  DT  3      det\n",
      "     Corps NNP  3 compound\n",
      "      Army NNP  5    nsubj\n",
      "        is VBZ  5      aux\n",
      "   cutting VBG  0     ROOT\n",
      "       the  DT  7      det\n",
      "      flow  NN  5     dobj\n",
      "        of  IN  7     prep\n",
      "       the  DT 10      det\n",
      "     River NNP  8     pobj\n",
      "  Missouri NNP 10    appos\n",
      "     about  IN  5     prep\n",
      "     weeks NNS 12     pobj\n",
      "       two  CD 13   nummod\n",
      "   earlier JJR 14     amod\n",
      "      than  IN 15     prep\n",
      "    normal  JJ 16     amod\n",
      "   because  IN  5     prep\n",
      "        of  IN 18    pcomp\n",
      "       low  JJ 21     amod\n",
      "    levels NNS 22 compound\n",
      "     water  NN 18     pobj\n",
      "        in  IN 22     prep\n",
      "       the  DT 25      det\n",
      "reservoirs NNS 23     pobj\n",
      "      that WDT 27    nsubj\n",
      "      feed VBP 25    relcl\n",
      "        it PRP 27     dobj\n",
      "         .   .  5    punct\n"
     ]
    }
   ],
   "source": [
    "# Columns according to Malt-Tab format\n",
    "tmp = df[[\"FORM\", 'XPOS', 'HEAD', 'DEPREL']].to_string(header=False, index=False)\n",
    "\n",
    "# See the outcome\n",
    "print(tmp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T02:47:56.822739400Z",
     "start_time": "2023-06-01T02:47:56.789742400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function DependencyGraph.__init__.<locals>.<lambda> at 0x00000181FA56B5E0>,\n",
      "            {0: {'address': 0,\n",
      "                 'ctag': 'TOP',\n",
      "                 'deps': defaultdict(<class 'list'>, {'ROOT': [5]}),\n",
      "                 'feats': None,\n",
      "                 'head': None,\n",
      "                 'lemma': None,\n",
      "                 'rel': None,\n",
      "                 'tag': 'TOP',\n",
      "                 'word': None},\n",
      "             1: {'address': 1,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 3,\n",
      "                 'lemma': 'The',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'The'},\n",
      "             2: {'address': 2,\n",
      "                 'ctag': 'NNP',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 3,\n",
      "                 'lemma': 'Corps',\n",
      "                 'rel': 'compound',\n",
      "                 'tag': 'NNP',\n",
      "                 'word': 'Corps'},\n",
      "             3: {'address': 3,\n",
      "                 'ctag': 'NNP',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'compound': [2],\n",
      "                                      'det': [1]}),\n",
      "                 'feats': '',\n",
      "                 'head': 5,\n",
      "                 'lemma': 'Army',\n",
      "                 'rel': 'nsubj',\n",
      "                 'tag': 'NNP',\n",
      "                 'word': 'Army'},\n",
      "             4: {'address': 4,\n",
      "                 'ctag': 'VBZ',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 5,\n",
      "                 'lemma': 'is',\n",
      "                 'rel': 'aux',\n",
      "                 'tag': 'VBZ',\n",
      "                 'word': 'is'},\n",
      "             5: {'address': 5,\n",
      "                 'ctag': 'VBG',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'aux': [4],\n",
      "                                      'dobj': [7],\n",
      "                                      'nsubj': [3],\n",
      "                                      'prep': [12, 18],\n",
      "                                      'punct': [29]}),\n",
      "                 'feats': '',\n",
      "                 'head': 0,\n",
      "                 'lemma': 'cutting',\n",
      "                 'rel': 'ROOT',\n",
      "                 'tag': 'VBG',\n",
      "                 'word': 'cutting'},\n",
      "             6: {'address': 6,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 7,\n",
      "                 'lemma': 'the',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'the'},\n",
      "             7: {'address': 7,\n",
      "                 'ctag': 'NN',\n",
      "                 'deps': defaultdict(<class 'list'>, {'det': [6], 'prep': [8]}),\n",
      "                 'feats': '',\n",
      "                 'head': 5,\n",
      "                 'lemma': 'flow',\n",
      "                 'rel': 'dobj',\n",
      "                 'tag': 'NN',\n",
      "                 'word': 'flow'},\n",
      "             8: {'address': 8,\n",
      "                 'ctag': 'IN',\n",
      "                 'deps': defaultdict(<class 'list'>, {'pobj': [10]}),\n",
      "                 'feats': '',\n",
      "                 'head': 7,\n",
      "                 'lemma': 'of',\n",
      "                 'rel': 'prep',\n",
      "                 'tag': 'IN',\n",
      "                 'word': 'of'},\n",
      "             9: {'address': 9,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 10,\n",
      "                 'lemma': 'the',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'the'},\n",
      "             10: {'address': 10,\n",
      "                  'ctag': 'NNP',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'appos': [11],\n",
      "                                       'det': [9]}),\n",
      "                  'feats': '',\n",
      "                  'head': 8,\n",
      "                  'lemma': 'River',\n",
      "                  'rel': 'pobj',\n",
      "                  'tag': 'NNP',\n",
      "                  'word': 'River'},\n",
      "             11: {'address': 11,\n",
      "                  'ctag': 'NNP',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 10,\n",
      "                  'lemma': 'Missouri',\n",
      "                  'rel': 'appos',\n",
      "                  'tag': 'NNP',\n",
      "                  'word': 'Missouri'},\n",
      "             12: {'address': 12,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {'pobj': [13]}),\n",
      "                  'feats': '',\n",
      "                  'head': 5,\n",
      "                  'lemma': 'about',\n",
      "                  'rel': 'prep',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'about'},\n",
      "             13: {'address': 13,\n",
      "                  'ctag': 'NNS',\n",
      "                  'deps': defaultdict(<class 'list'>, {'nummod': [14]}),\n",
      "                  'feats': '',\n",
      "                  'head': 12,\n",
      "                  'lemma': 'weeks',\n",
      "                  'rel': 'pobj',\n",
      "                  'tag': 'NNS',\n",
      "                  'word': 'weeks'},\n",
      "             14: {'address': 14,\n",
      "                  'ctag': 'CD',\n",
      "                  'deps': defaultdict(<class 'list'>, {'amod': [15]}),\n",
      "                  'feats': '',\n",
      "                  'head': 13,\n",
      "                  'lemma': 'two',\n",
      "                  'rel': 'nummod',\n",
      "                  'tag': 'CD',\n",
      "                  'word': 'two'},\n",
      "             15: {'address': 15,\n",
      "                  'ctag': 'JJR',\n",
      "                  'deps': defaultdict(<class 'list'>, {'prep': [16]}),\n",
      "                  'feats': '',\n",
      "                  'head': 14,\n",
      "                  'lemma': 'earlier',\n",
      "                  'rel': 'amod',\n",
      "                  'tag': 'JJR',\n",
      "                  'word': 'earlier'},\n",
      "             16: {'address': 16,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {'amod': [17]}),\n",
      "                  'feats': '',\n",
      "                  'head': 15,\n",
      "                  'lemma': 'than',\n",
      "                  'rel': 'prep',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'than'},\n",
      "             17: {'address': 17,\n",
      "                  'ctag': 'JJ',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 16,\n",
      "                  'lemma': 'normal',\n",
      "                  'rel': 'amod',\n",
      "                  'tag': 'JJ',\n",
      "                  'word': 'normal'},\n",
      "             18: {'address': 18,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'pcomp': [19],\n",
      "                                       'pobj': [22]}),\n",
      "                  'feats': '',\n",
      "                  'head': 5,\n",
      "                  'lemma': 'because',\n",
      "                  'rel': 'prep',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'because'},\n",
      "             19: {'address': 19,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 18,\n",
      "                  'lemma': 'of',\n",
      "                  'rel': 'pcomp',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'of'},\n",
      "             20: {'address': 20,\n",
      "                  'ctag': 'JJ',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 21,\n",
      "                  'lemma': 'low',\n",
      "                  'rel': 'amod',\n",
      "                  'tag': 'JJ',\n",
      "                  'word': 'low'},\n",
      "             21: {'address': 21,\n",
      "                  'ctag': 'NNS',\n",
      "                  'deps': defaultdict(<class 'list'>, {'amod': [20]}),\n",
      "                  'feats': '',\n",
      "                  'head': 22,\n",
      "                  'lemma': 'levels',\n",
      "                  'rel': 'compound',\n",
      "                  'tag': 'NNS',\n",
      "                  'word': 'levels'},\n",
      "             22: {'address': 22,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'compound': [21],\n",
      "                                       'prep': [23]}),\n",
      "                  'feats': '',\n",
      "                  'head': 18,\n",
      "                  'lemma': 'water',\n",
      "                  'rel': 'pobj',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'water'},\n",
      "             23: {'address': 23,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {'pobj': [25]}),\n",
      "                  'feats': '',\n",
      "                  'head': 22,\n",
      "                  'lemma': 'in',\n",
      "                  'rel': 'prep',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'in'},\n",
      "             24: {'address': 24,\n",
      "                  'ctag': 'DT',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 25,\n",
      "                  'lemma': 'the',\n",
      "                  'rel': 'det',\n",
      "                  'tag': 'DT',\n",
      "                  'word': 'the'},\n",
      "             25: {'address': 25,\n",
      "                  'ctag': 'NNS',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'det': [24],\n",
      "                                       'relcl': [27]}),\n",
      "                  'feats': '',\n",
      "                  'head': 23,\n",
      "                  'lemma': 'reservoirs',\n",
      "                  'rel': 'pobj',\n",
      "                  'tag': 'NNS',\n",
      "                  'word': 'reservoirs'},\n",
      "             26: {'address': 26,\n",
      "                  'ctag': 'WDT',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 27,\n",
      "                  'lemma': 'that',\n",
      "                  'rel': 'nsubj',\n",
      "                  'tag': 'WDT',\n",
      "                  'word': 'that'},\n",
      "             27: {'address': 27,\n",
      "                  'ctag': 'VBP',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'dobj': [28],\n",
      "                                       'nsubj': [26]}),\n",
      "                  'feats': '',\n",
      "                  'head': 25,\n",
      "                  'lemma': 'feed',\n",
      "                  'rel': 'relcl',\n",
      "                  'tag': 'VBP',\n",
      "                  'word': 'feed'},\n",
      "             28: {'address': 28,\n",
      "                  'ctag': 'PRP',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 27,\n",
      "                  'lemma': 'it',\n",
      "                  'rel': 'dobj',\n",
      "                  'tag': 'PRP',\n",
      "                  'word': 'it'},\n",
      "             29: {'address': 29,\n",
      "                  'ctag': '.',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 5,\n",
      "                  'lemma': '.',\n",
      "                  'rel': 'punct',\n",
      "                  'tag': '.',\n",
      "                  'word': '.'}})\n"
     ]
    }
   ],
   "source": [
    "# Get finally our the DependencyGraph\n",
    "dp = DependencyGraph(tmp)\n",
    "print(dp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T02:49:05.872017100Z",
     "start_time": "2023-06-01T02:49:05.802017100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree:\n",
      "                                                              cutting                                                                              \n",
      " ┌──────┬─────────────┬───────────────────────┬──────────────────┴───────────┬───────────────────────────┐                                             \n",
      " │      │             │                       │                            about                      because                                      \n",
      " │      │             │                       │                              │        ┌──────────────────┴─────────┐                                   \n",
      " │      │             │                       │                            weeks      │                          water                             \n",
      " │      │             │                       │                              │        │       ┌────────────────────┴──────────┐                        \n",
      " │      │             │                      flow                           two       │       │                               in                   \n",
      " │      │             │                ┌──────┴────────┐                     │        │       │                               │                        \n",
      " │      │             │                │               of                 earlier     │       │                           reservoirs               \n",
      " │      │             │                │               │                     │        │       │          ┌────────────────────┴──────────┐             \n",
      " │      │            Army              │             River                  than      │     levels       │                              feed       \n",
      " │      │      ┌──────┴────────┐       │      ┌────────┴─────────┐           │        │       │          │                    ┌──────────┴───────┐     \n",
      " is     .     The            Corps    the    the              Missouri     normal     of     low        the                  that                it\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Tree:')\n",
    "dp.tree().pretty_print(unicodelines=True, nodedist=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T02:49:12.209135300Z",
     "start_time": "2023-06-01T02:49:12.171137200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Parse all the sentences with spacy and convert them to a DependencyGraph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "parsed_dg = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    df = doc._.pandas\n",
    "    tmp = df[[\"FORM\", 'XPOS', 'HEAD', 'DEPREL']].to_string(header=False, index=False)\n",
    "    dp = DependencyGraph(tmp)\n",
    "\n",
    "    parsed_dg.append(dp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T02:49:46.100617200Z",
     "start_time": "2023-06-01T02:49:43.677152700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree 1\n",
      "defaultdict(<function DependencyGraph.__init__.<locals>.<lambda> at 0x00000181F4569790>,\n",
      "            {0: {'address': 0,\n",
      "                 'ctag': 'TOP',\n",
      "                 'deps': defaultdict(<class 'list'>, {'ROOT': [5]}),\n",
      "                 'feats': None,\n",
      "                 'head': None,\n",
      "                 'lemma': None,\n",
      "                 'rel': None,\n",
      "                 'tag': 'TOP',\n",
      "                 'word': None},\n",
      "             1: {'address': 1,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 3,\n",
      "                 'lemma': 'The',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'The'},\n",
      "             2: {'address': 2,\n",
      "                 'ctag': 'NNP',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 3,\n",
      "                 'lemma': 'Corps',\n",
      "                 'rel': 'compound',\n",
      "                 'tag': 'NNP',\n",
      "                 'word': 'Corps'},\n",
      "             3: {'address': 3,\n",
      "                 'ctag': 'NNP',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'compound': [2],\n",
      "                                      'det': [1]}),\n",
      "                 'feats': '',\n",
      "                 'head': 5,\n",
      "                 'lemma': 'Army',\n",
      "                 'rel': 'nsubj',\n",
      "                 'tag': 'NNP',\n",
      "                 'word': 'Army'},\n",
      "             4: {'address': 4,\n",
      "                 'ctag': 'VBZ',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 5,\n",
      "                 'lemma': 'is',\n",
      "                 'rel': 'aux',\n",
      "                 'tag': 'VBZ',\n",
      "                 'word': 'is'},\n",
      "             5: {'address': 5,\n",
      "                 'ctag': 'VBG',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'aux': [4],\n",
      "                                      'dobj': [7],\n",
      "                                      'nsubj': [3],\n",
      "                                      'prep': [12, 18],\n",
      "                                      'punct': [29]}),\n",
      "                 'feats': '',\n",
      "                 'head': 0,\n",
      "                 'lemma': 'cutting',\n",
      "                 'rel': 'ROOT',\n",
      "                 'tag': 'VBG',\n",
      "                 'word': 'cutting'},\n",
      "             6: {'address': 6,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 7,\n",
      "                 'lemma': 'the',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'the'},\n",
      "             7: {'address': 7,\n",
      "                 'ctag': 'NN',\n",
      "                 'deps': defaultdict(<class 'list'>, {'det': [6], 'prep': [8]}),\n",
      "                 'feats': '',\n",
      "                 'head': 5,\n",
      "                 'lemma': 'flow',\n",
      "                 'rel': 'dobj',\n",
      "                 'tag': 'NN',\n",
      "                 'word': 'flow'},\n",
      "             8: {'address': 8,\n",
      "                 'ctag': 'IN',\n",
      "                 'deps': defaultdict(<class 'list'>, {'pobj': [10]}),\n",
      "                 'feats': '',\n",
      "                 'head': 7,\n",
      "                 'lemma': 'of',\n",
      "                 'rel': 'prep',\n",
      "                 'tag': 'IN',\n",
      "                 'word': 'of'},\n",
      "             9: {'address': 9,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 10,\n",
      "                 'lemma': 'the',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'the'},\n",
      "             10: {'address': 10,\n",
      "                  'ctag': 'NNP',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'appos': [11],\n",
      "                                       'det': [9]}),\n",
      "                  'feats': '',\n",
      "                  'head': 8,\n",
      "                  'lemma': 'River',\n",
      "                  'rel': 'pobj',\n",
      "                  'tag': 'NNP',\n",
      "                  'word': 'River'},\n",
      "             11: {'address': 11,\n",
      "                  'ctag': 'NNP',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 10,\n",
      "                  'lemma': 'Missouri',\n",
      "                  'rel': 'appos',\n",
      "                  'tag': 'NNP',\n",
      "                  'word': 'Missouri'},\n",
      "             12: {'address': 12,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {'pobj': [13]}),\n",
      "                  'feats': '',\n",
      "                  'head': 5,\n",
      "                  'lemma': 'about',\n",
      "                  'rel': 'prep',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'about'},\n",
      "             13: {'address': 13,\n",
      "                  'ctag': 'NNS',\n",
      "                  'deps': defaultdict(<class 'list'>, {'nummod': [14]}),\n",
      "                  'feats': '',\n",
      "                  'head': 12,\n",
      "                  'lemma': 'weeks',\n",
      "                  'rel': 'pobj',\n",
      "                  'tag': 'NNS',\n",
      "                  'word': 'weeks'},\n",
      "             14: {'address': 14,\n",
      "                  'ctag': 'CD',\n",
      "                  'deps': defaultdict(<class 'list'>, {'amod': [15]}),\n",
      "                  'feats': '',\n",
      "                  'head': 13,\n",
      "                  'lemma': 'two',\n",
      "                  'rel': 'nummod',\n",
      "                  'tag': 'CD',\n",
      "                  'word': 'two'},\n",
      "             15: {'address': 15,\n",
      "                  'ctag': 'JJR',\n",
      "                  'deps': defaultdict(<class 'list'>, {'prep': [16]}),\n",
      "                  'feats': '',\n",
      "                  'head': 14,\n",
      "                  'lemma': 'earlier',\n",
      "                  'rel': 'amod',\n",
      "                  'tag': 'JJR',\n",
      "                  'word': 'earlier'},\n",
      "             16: {'address': 16,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {'amod': [17]}),\n",
      "                  'feats': '',\n",
      "                  'head': 15,\n",
      "                  'lemma': 'than',\n",
      "                  'rel': 'prep',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'than'},\n",
      "             17: {'address': 17,\n",
      "                  'ctag': 'JJ',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 16,\n",
      "                  'lemma': 'normal',\n",
      "                  'rel': 'amod',\n",
      "                  'tag': 'JJ',\n",
      "                  'word': 'normal'},\n",
      "             18: {'address': 18,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'pcomp': [19],\n",
      "                                       'pobj': [22]}),\n",
      "                  'feats': '',\n",
      "                  'head': 5,\n",
      "                  'lemma': 'because',\n",
      "                  'rel': 'prep',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'because'},\n",
      "             19: {'address': 19,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 18,\n",
      "                  'lemma': 'of',\n",
      "                  'rel': 'pcomp',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'of'},\n",
      "             20: {'address': 20,\n",
      "                  'ctag': 'JJ',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 21,\n",
      "                  'lemma': 'low',\n",
      "                  'rel': 'amod',\n",
      "                  'tag': 'JJ',\n",
      "                  'word': 'low'},\n",
      "             21: {'address': 21,\n",
      "                  'ctag': 'NNS',\n",
      "                  'deps': defaultdict(<class 'list'>, {'amod': [20]}),\n",
      "                  'feats': '',\n",
      "                  'head': 22,\n",
      "                  'lemma': 'levels',\n",
      "                  'rel': 'compound',\n",
      "                  'tag': 'NNS',\n",
      "                  'word': 'levels'},\n",
      "             22: {'address': 22,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'compound': [21],\n",
      "                                       'prep': [23]}),\n",
      "                  'feats': '',\n",
      "                  'head': 18,\n",
      "                  'lemma': 'water',\n",
      "                  'rel': 'pobj',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'water'},\n",
      "             23: {'address': 23,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {'pobj': [25]}),\n",
      "                  'feats': '',\n",
      "                  'head': 22,\n",
      "                  'lemma': 'in',\n",
      "                  'rel': 'prep',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'in'},\n",
      "             24: {'address': 24,\n",
      "                  'ctag': 'DT',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 25,\n",
      "                  'lemma': 'the',\n",
      "                  'rel': 'det',\n",
      "                  'tag': 'DT',\n",
      "                  'word': 'the'},\n",
      "             25: {'address': 25,\n",
      "                  'ctag': 'NNS',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'det': [24],\n",
      "                                       'relcl': [27]}),\n",
      "                  'feats': '',\n",
      "                  'head': 23,\n",
      "                  'lemma': 'reservoirs',\n",
      "                  'rel': 'pobj',\n",
      "                  'tag': 'NNS',\n",
      "                  'word': 'reservoirs'},\n",
      "             26: {'address': 26,\n",
      "                  'ctag': 'WDT',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 27,\n",
      "                  'lemma': 'that',\n",
      "                  'rel': 'nsubj',\n",
      "                  'tag': 'WDT',\n",
      "                  'word': 'that'},\n",
      "             27: {'address': 27,\n",
      "                  'ctag': 'VBP',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'dobj': [28],\n",
      "                                       'nsubj': [26]}),\n",
      "                  'feats': '',\n",
      "                  'head': 25,\n",
      "                  'lemma': 'feed',\n",
      "                  'rel': 'relcl',\n",
      "                  'tag': 'VBP',\n",
      "                  'word': 'feed'},\n",
      "             28: {'address': 28,\n",
      "                  'ctag': 'PRP',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 27,\n",
      "                  'lemma': 'it',\n",
      "                  'rel': 'dobj',\n",
      "                  'tag': 'PRP',\n",
      "                  'word': 'it'},\n",
      "             29: {'address': 29,\n",
      "                  'ctag': '.',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 5,\n",
      "                  'lemma': '.',\n",
      "                  'rel': 'punct',\n",
      "                  'tag': '.',\n",
      "                  'word': '.'}})\n",
      "\n",
      "Tree 2\n",
      "defaultdict(<function DependencyGraph.__init__.<locals>.<lambda> at 0x00000181F52A7280>,\n",
      "            {0: {'address': 0,\n",
      "                 'ctag': 'TOP',\n",
      "                 'deps': defaultdict(<class 'list'>, {'ROOT': [3]}),\n",
      "                 'feats': None,\n",
      "                 'head': None,\n",
      "                 'lemma': None,\n",
      "                 'rel': None,\n",
      "                 'tag': 'TOP',\n",
      "                 'word': None},\n",
      "             1: {'address': 1,\n",
      "                 'ctag': 'NN',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 2,\n",
      "                 'lemma': 'Barge',\n",
      "                 'rel': 'compound',\n",
      "                 'tag': 'NN',\n",
      "                 'word': 'Barge'},\n",
      "             2: {'address': 2,\n",
      "                 'ctag': 'NNS',\n",
      "                 'deps': defaultdict(<class 'list'>, {'compound': [1]}),\n",
      "                 'feats': '',\n",
      "                 'head': 3,\n",
      "                 'lemma': 'rates',\n",
      "                 'rel': 'nsubj',\n",
      "                 'tag': 'NNS',\n",
      "                 'word': 'rates'},\n",
      "             3: {'address': 3,\n",
      "                 'ctag': 'VBD',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'npadvmod': [8],\n",
      "                                      'nsubj': [2],\n",
      "                                      'prep': [4, 9],\n",
      "                                      'punct': [24]}),\n",
      "                 'feats': '',\n",
      "                 'head': 0,\n",
      "                 'lemma': 'sank',\n",
      "                 'rel': 'ROOT',\n",
      "                 'tag': 'VBD',\n",
      "                 'word': 'sank'},\n",
      "             4: {'address': 4,\n",
      "                 'ctag': 'IN',\n",
      "                 'deps': defaultdict(<class 'list'>, {'pobj': [7]}),\n",
      "                 'feats': '',\n",
      "                 'head': 3,\n",
      "                 'lemma': 'on',\n",
      "                 'rel': 'prep',\n",
      "                 'tag': 'IN',\n",
      "                 'word': 'on'},\n",
      "             5: {'address': 5,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 7,\n",
      "                 'lemma': 'the',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'the'},\n",
      "             6: {'address': 6,\n",
      "                 'ctag': 'NNP',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 7,\n",
      "                 'lemma': 'River',\n",
      "                 'rel': 'compound',\n",
      "                 'tag': 'NNP',\n",
      "                 'word': 'River'},\n",
      "             7: {'address': 7,\n",
      "                 'ctag': 'NNP',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'compound': [6],\n",
      "                                      'det': [5]}),\n",
      "                 'feats': '',\n",
      "                 'head': 4,\n",
      "                 'lemma': 'Mississippi',\n",
      "                 'rel': 'pobj',\n",
      "                 'tag': 'NNP',\n",
      "                 'word': 'Mississippi'},\n",
      "             8: {'address': 8,\n",
      "                 'ctag': 'NN',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 3,\n",
      "                 'lemma': 'yesterday',\n",
      "                 'rel': 'npadvmod',\n",
      "                 'tag': 'NN',\n",
      "                 'word': 'yesterday'},\n",
      "             9: {'address': 9,\n",
      "                 'ctag': 'IN',\n",
      "                 'deps': defaultdict(<class 'list'>, {'pobj': [10]}),\n",
      "                 'feats': '',\n",
      "                 'head': 3,\n",
      "                 'lemma': 'on',\n",
      "                 'rel': 'prep',\n",
      "                 'tag': 'IN',\n",
      "                 'word': 'on'},\n",
      "             10: {'address': 10,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>, {'acl': [21]}),\n",
      "                  'feats': '',\n",
      "                  'head': 9,\n",
      "                  'lemma': 'speculation',\n",
      "                  'rel': 'pobj',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'speculation'},\n",
      "             11: {'address': 11,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 21,\n",
      "                  'lemma': 'that',\n",
      "                  'rel': 'mark',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'that'},\n",
      "             12: {'address': 12,\n",
      "                  'ctag': 'JJ',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 13,\n",
      "                  'lemma': 'widespread',\n",
      "                  'rel': 'amod',\n",
      "                  'tag': 'JJ',\n",
      "                  'word': 'widespread'},\n",
      "             13: {'address': 13,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'amod': [12],\n",
      "                                       'appos': [14],\n",
      "                                       'npadvmod': [16],\n",
      "                                       'prep': [17]}),\n",
      "                  'feats': '',\n",
      "                  'head': 21,\n",
      "                  'lemma': 'rain',\n",
      "                  'rel': 'nsubj',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'rain'},\n",
      "             14: {'address': 14,\n",
      "                  'ctag': 'MD',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 13,\n",
      "                  'lemma': 'might',\n",
      "                  'rel': 'appos',\n",
      "                  'tag': 'MD',\n",
      "                  'word': 'might'},\n",
      "             15: {'address': 15,\n",
      "                  'ctag': 'DT',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 16,\n",
      "                  'lemma': 'this',\n",
      "                  'rel': 'det',\n",
      "                  'tag': 'DT',\n",
      "                  'word': 'this'},\n",
      "             16: {'address': 16,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>, {'det': [15]}),\n",
      "                  'feats': '',\n",
      "                  'head': 13,\n",
      "                  'lemma': 'week',\n",
      "                  'rel': 'npadvmod',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'week'},\n",
      "             17: {'address': 17,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {'pobj': [19]}),\n",
      "                  'feats': '',\n",
      "                  'head': 13,\n",
      "                  'lemma': 'in',\n",
      "                  'rel': 'prep',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'in'},\n",
      "             18: {'address': 18,\n",
      "                  'ctag': 'DT',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 19,\n",
      "                  'lemma': 'the',\n",
      "                  'rel': 'det',\n",
      "                  'tag': 'DT',\n",
      "                  'word': 'the'},\n",
      "             19: {'address': 19,\n",
      "                  'ctag': 'NNP',\n",
      "                  'deps': defaultdict(<class 'list'>, {'det': [18]}),\n",
      "                  'feats': '',\n",
      "                  'head': 17,\n",
      "                  'lemma': 'Midwest',\n",
      "                  'rel': 'pobj',\n",
      "                  'tag': 'NNP',\n",
      "                  'word': 'Midwest'},\n",
      "             20: {'address': 20,\n",
      "                  'ctag': 'RB',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 21,\n",
      "                  'lemma': 'temporarily',\n",
      "                  'rel': 'advmod',\n",
      "                  'tag': 'RB',\n",
      "                  'word': 'temporarily'},\n",
      "             21: {'address': 21,\n",
      "                  'ctag': 'VB',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'advmod': [20],\n",
      "                                       'dobj': [23],\n",
      "                                       'mark': [11],\n",
      "                                       'nsubj': [13]}),\n",
      "                  'feats': '',\n",
      "                  'head': 10,\n",
      "                  'lemma': 'alleviate',\n",
      "                  'rel': 'acl',\n",
      "                  'tag': 'VB',\n",
      "                  'word': 'alleviate'},\n",
      "             22: {'address': 22,\n",
      "                  'ctag': 'DT',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 23,\n",
      "                  'lemma': 'the',\n",
      "                  'rel': 'det',\n",
      "                  'tag': 'DT',\n",
      "                  'word': 'the'},\n",
      "             23: {'address': 23,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>, {'det': [22]}),\n",
      "                  'feats': '',\n",
      "                  'head': 21,\n",
      "                  'lemma': 'situation',\n",
      "                  'rel': 'dobj',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'situation'},\n",
      "             24: {'address': 24,\n",
      "                  'ctag': '.',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 3,\n",
      "                  'lemma': '.',\n",
      "                  'rel': 'punct',\n",
      "                  'tag': '.',\n",
      "                  'word': '.'}})\n",
      "\n",
      "Tree 3\n",
      "defaultdict(<function DependencyGraph.__init__.<locals>.<lambda> at 0x00000181FAB1F280>,\n",
      "            {0: {'address': 0,\n",
      "                 'ctag': 'TOP',\n",
      "                 'deps': defaultdict(<class 'list'>, {'ROOT': [2]}),\n",
      "                 'feats': None,\n",
      "                 'head': None,\n",
      "                 'lemma': None,\n",
      "                 'rel': None,\n",
      "                 'tag': 'TOP',\n",
      "                 'word': None},\n",
      "             1: {'address': 1,\n",
      "                 'ctag': 'CC',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 2,\n",
      "                 'lemma': 'But',\n",
      "                 'rel': 'cc',\n",
      "                 'tag': 'CC',\n",
      "                 'word': 'But'},\n",
      "             2: {'address': 2,\n",
      "                 'ctag': 'VBZ',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'cc': [1],\n",
      "                                      'ccomp': [11],\n",
      "                                      'punct': [16]}),\n",
      "                 'feats': '',\n",
      "                 'head': 0,\n",
      "                 'lemma': 'expects',\n",
      "                 'rel': 'ROOT',\n",
      "                 'tag': 'VBZ',\n",
      "                 'word': 'expects'},\n",
      "             3: {'address': 3,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 5,\n",
      "                 'lemma': 'the',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'the'},\n",
      "             4: {'address': 4,\n",
      "                 'ctag': 'NNP',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 5,\n",
      "                 'lemma': 'Corps',\n",
      "                 'rel': 'compound',\n",
      "                 'tag': 'NNP',\n",
      "                 'word': 'Corps'},\n",
      "             5: {'address': 5,\n",
      "                 'ctag': 'NNP',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'compound': [4],\n",
      "                                      'det': [3],\n",
      "                                      'prep': [6]}),\n",
      "                 'feats': '',\n",
      "                 'head': 11,\n",
      "                 'lemma': 'Army',\n",
      "                 'rel': 'nsubj',\n",
      "                 'tag': 'NNP',\n",
      "                 'word': 'Army'},\n",
      "             6: {'address': 6,\n",
      "                 'ctag': 'IN',\n",
      "                 'deps': defaultdict(<class 'list'>, {'pobj': [7]}),\n",
      "                 'feats': '',\n",
      "                 'head': 5,\n",
      "                 'lemma': 'of',\n",
      "                 'rel': 'prep',\n",
      "                 'tag': 'IN',\n",
      "                 'word': 'of'},\n",
      "             7: {'address': 7,\n",
      "                 'ctag': 'NNP',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 6,\n",
      "                 'lemma': 'Engineers',\n",
      "                 'rel': 'pobj',\n",
      "                 'tag': 'NNP',\n",
      "                 'word': 'Engineers'},\n",
      "             8: {'address': 8,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 10,\n",
      "                 'lemma': 'the',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'the'},\n",
      "             9: {'address': 9,\n",
      "                 'ctag': 'NN',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 10,\n",
      "                 'lemma': 'level',\n",
      "                 'rel': 'compound',\n",
      "                 'tag': 'NN',\n",
      "                 'word': 'level'},\n",
      "             10: {'address': 10,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'compound': [9],\n",
      "                                       'det': [8]}),\n",
      "                  'feats': '',\n",
      "                  'head': 11,\n",
      "                  'lemma': 'river',\n",
      "                  'rel': 'nsubj',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'river'},\n",
      "             11: {'address': 11,\n",
      "                  'ctag': 'VBP',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'nsubj': [5, 10],\n",
      "                                       'prep': [12]}),\n",
      "                  'feats': '',\n",
      "                  'head': 2,\n",
      "                  'lemma': 'continue',\n",
      "                  'rel': 'ccomp',\n",
      "                  'tag': 'VBP',\n",
      "                  'word': 'continue'},\n",
      "             12: {'address': 12,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {'pcomp': [13]}),\n",
      "                  'feats': '',\n",
      "                  'head': 11,\n",
      "                  'lemma': 'to',\n",
      "                  'rel': 'prep',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'to'},\n",
      "             13: {'address': 13,\n",
      "                  'ctag': 'VBG',\n",
      "                  'deps': defaultdict(<class 'list'>, {'npadvmod': [15]}),\n",
      "                  'feats': '',\n",
      "                  'head': 12,\n",
      "                  'lemma': 'falling',\n",
      "                  'rel': 'pcomp',\n",
      "                  'tag': 'VBG',\n",
      "                  'word': 'falling'},\n",
      "             14: {'address': 14,\n",
      "                  'ctag': 'DT',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 15,\n",
      "                  'lemma': 'this',\n",
      "                  'rel': 'det',\n",
      "                  'tag': 'DT',\n",
      "                  'word': 'this'},\n",
      "             15: {'address': 15,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>, {'det': [14]}),\n",
      "                  'feats': '',\n",
      "                  'head': 13,\n",
      "                  'lemma': 'month',\n",
      "                  'rel': 'npadvmod',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'month'},\n",
      "             16: {'address': 16,\n",
      "                  'ctag': '.',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 2,\n",
      "                  'lemma': '.',\n",
      "                  'rel': 'punct',\n",
      "                  'tag': '.',\n",
      "                  'word': '.'}})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the first 3 parses of spacy\n",
    "for i in range(3):\n",
    "    print(\"Tree {}\".format(i+1))\n",
    "    print(parsed_dg[i])\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T02:53:27.139156700Z",
     "start_time": "2023-06-01T02:53:27.036164500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree 1\n",
      "                                                              cutting                                                                              \n",
      " ┌──────┬─────────────┬───────────────────────┬──────────────────┴───────────┬───────────────────────────┐                                             \n",
      " │      │             │                       │                            about                      because                                      \n",
      " │      │             │                       │                              │        ┌──────────────────┴─────────┐                                   \n",
      " │      │             │                       │                            weeks      │                          water                             \n",
      " │      │             │                       │                              │        │       ┌────────────────────┴──────────┐                        \n",
      " │      │             │                      flow                           two       │       │                               in                   \n",
      " │      │             │                ┌──────┴────────┐                     │        │       │                               │                        \n",
      " │      │             │                │               of                 earlier     │       │                           reservoirs               \n",
      " │      │             │                │               │                     │        │       │          ┌────────────────────┴──────────┐             \n",
      " │      │            Army              │             River                  than      │     levels       │                              feed       \n",
      " │      │      ┌──────┴────────┐       │      ┌────────┴─────────┐           │        │       │          │                    ┌──────────┴───────┐     \n",
      " is     .     The            Corps    the    the              Missouri     normal     of     low        the                  that                it\n",
      "\n",
      "\n",
      "Tree 2\n",
      "                                                            sank                                                                            \n",
      "    ┌─────────┬───────┬──────────────────┬───────────────────┴────────────────────────────────────────┐                                         \n",
      "    │         │       │                  │                                                            on                                    \n",
      "    │         │       │                  │                                                            │                                         \n",
      "    │         │       │                  │                                                       speculation                                \n",
      "    │         │       │                  │                                                            │                                         \n",
      "    │         │       │                  │                                                        alleviate                                 \n",
      "    │         │       │                  │                   ┌───────────┬────────────────────────────┼────────────────────────────────┐        \n",
      "    │         │       │                  │                   │           │                           rain                              │    \n",
      "    │         │       │                  │                   │           │             ┌──────────────┼──────────┬─────────┐           │        \n",
      "    │         │       │                  on                  │           │             │              │          │         in          │    \n",
      "    │         │       │                  │                   │           │             │              │          │         │           │        \n",
      "    │         │     rates           Mississippi              │           │             │              │         week    Midwest    situation\n",
      "    │         │       │       ┌──────────┴───────────┐       │           │             │              │          │         │           │        \n",
      "yesterday     .     Barge    the                   River    that    temporarily    widespread       might       this      the         the   \n",
      "\n",
      "\n",
      "Tree 3\n",
      "                     expects                                                 \n",
      " ┌──────┬───────────────┴───────────┐                                            \n",
      " │      │                        continue                                    \n",
      " │      │               ┌───────────┴─────────────────┬──────────────────┐       \n",
      " │      │               │                             │                  to  \n",
      " │      │               │                             │                  │       \n",
      " │      │              Army                           │               falling\n",
      " │      │      ┌────────┼───────────┐                 │                  │       \n",
      " │      │      │        │           of              river              month \n",
      " │      │      │        │           │         ┌───────┴────────┐         │       \n",
      "But     .     the     Corps     Engineers    the             level      this \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the first 3 parses trees of the spacy\n",
    "for i in range(3):\n",
    "    print(\"Tree {}\".format(i+1))\n",
    "    parsed_dg[i].tree().pretty_print(unicodelines=True, nodedist=4)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T02:53:30.665543900Z",
     "start_time": "2023-06-01T02:53:30.624524Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 Spacy Dependency Parser Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sentence sequence is not matched.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[59], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m ground_truth_dg \u001B[38;5;241m=\u001B[39m dependency_treebank\u001B[38;5;241m.\u001B[39mparsed_sents()[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m100\u001B[39m:]\n\u001B[0;32m      7\u001B[0m de \u001B[38;5;241m=\u001B[39m DependencyEvaluator(parsed_dg, ground_truth_dg)\n\u001B[1;32m----> 8\u001B[0m las, uas \u001B[38;5;241m=\u001B[39m \u001B[43mde\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meval\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLAS: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(las))\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUAS: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(uas))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\evaluate.py:116\u001B[0m, in \u001B[0;36mDependencyEvaluator.eval\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m parsed_node[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mword\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m!=\u001B[39m gold_node[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mword\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m--> 116\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSentence sequence is not matched.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;66;03m# Ignore if word is punctuation by default\u001B[39;00m\n\u001B[0;32m    119\u001B[0m \u001B[38;5;66;03m# if (parsed_sent[j][\"word\"] in string.punctuation):\u001B[39;00m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_remove_punct(parsed_node[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mword\u001B[39m\u001B[38;5;124m\"\u001B[39m]) \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[1;31mValueError\u001B[0m: Sentence sequence is not matched."
     ]
    }
   ],
   "source": [
    "# from nltk.parse import DependencyEvaluator\n",
    "from nltk.parse.evaluate import DependencyEvaluator\n",
    "\n",
    "# evaluate the spacy parser using the DependencyEvaluator with ground truth from the dependency treebank\n",
    "ground_truth_dg = dependency_treebank.parsed_sents()[-100:]\n",
    "\n",
    "de = DependencyEvaluator(parsed_dg, ground_truth_dg)\n",
    "las, uas = de.eval()\n",
    "\n",
    "print(\"LAS: {}\".format(las))\n",
    "print(\"UAS: {}\".format(uas))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T02:57:28.424894400Z",
     "start_time": "2023-06-01T02:57:26.723899800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Stanza Dependency Parser"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "# Stanza version\n",
    "from nltk.parse.dependencygraph import DependencyGraph\n",
    "import stanza\n",
    "import spacy_stanza\n",
    "\n",
    "# Download the stanza model if necessary\n",
    "stanza.download(\"en\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T02:58:56.958715300Z",
     "start_time": "2023-06-01T02:58:51.648633600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "ConllFormatter(conversion_maps={'deprel': {'nsubj': 'subj', 'root': 'ROOT'}}, ext_names={'conll_str': 'conll_str', 'conll': 'conll', 'conll_pd': 'pandas'}, field_names={'ID': 'ID', 'FORM': 'FORM', 'LEMMA': 'LEMMA', 'UPOS': 'UPOS', 'XPOS': 'XPOS', 'FEATS': 'FEATS', 'HEAD': 'HEAD', 'DEPREL': 'DEPREL', 'DEPS': 'DEPS', 'MISC': 'MISC'}, include_headers=False, disable_pandas=False)"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the conll formatter\n",
    "# tokenize_pretokenized used to tokenize by whitespace\n",
    "nlp = spacy_stanza.load_pipeline(\"en\", verbose=False, tokenize_pretokenized=True)\n",
    "\n",
    "config = {\n",
    "    \"ext_names\": {\n",
    "        \"conll_pd\": \"pandas\"\n",
    "    },\n",
    "    \"conversion_maps\": {\n",
    "        \"deprel\": {\n",
    "            \"nsubj\": \"subj\",\n",
    "            \"root\":\"ROOT\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add the formatter to the pipeline\n",
    "nlp.add_pipe(\"conll_formatter\", config=config, last=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T03:00:45.689090400Z",
     "start_time": "2023-06-01T03:00:42.338089300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 Parse a sentence with stanza and convert it to a DependencyGraph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "    ID        FORM       LEMMA   UPOS XPOS  \\\n0    1          So          so    ADV   RB   \n1    2         far         far    ADV   RB   \n2    3        have        have    AUX  VBP   \n3    4           ,           ,  PUNCT    ,   \n4    5         the         the    DET   DT   \n5    6          's          's   PART  POS   \n6    7       grain       grain   NOUN   NN   \n7    8    industry    industry   NOUN   NN   \n8    9    problems     problem   NOUN  NNS   \n9   10     budding         bud   VERB  VBG   \n10  11  logistical  logistical    ADJ   JJ   \n11  12         n't         not   PART   RB   \n12  13        been          be    AUX  VBN   \n13  14           a           a    DET   DT   \n14  15      factor      factor   NOUN   NN   \n15  16       major       major    ADJ   JJ   \n16  17          in          in    ADP   IN   \n17  18         the         the    DET   DT   \n18  19     trading     trading   NOUN   NN   \n19  20          of          of    ADP   IN   \n20  21        corn        corn   NOUN   NN   \n21  22   contracts    contract   NOUN  NNS   \n22  23          at          at    ADP   IN   \n23  24         the         the    DET   DT   \n24  25       Board       Board  PROPN  NNP   \n25  26     Chicago     Chicago  PROPN  NNP   \n26  27          of          of    ADP   IN   \n27  28       Trade       Trade  PROPN  NNP   \n28  29           .           .  PUNCT    .   \n\n                                                FEATS  HEAD     DEPREL DEPS  \\\n0                                                   _     2     advmod    _   \n1                                          Degree=Pos    15     advmod    _   \n2   Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbF...    15  parataxis    _   \n3                                                   _    15      punct    _   \n4                           Definite=Def|PronType=Art     9  nmod:poss    _   \n5                                                   _     5       case    _   \n6                                         Number=Sing     8   compound    _   \n7                                         Number=Sing     9   compound    _   \n8                                         Number=Plur    15      nsubj    _   \n9                                        VerbForm=Ger     9        acl    _   \n10                                         Degree=Pos     9       amod    _   \n11                                                  _    15     advmod    _   \n12                           Tense=Past|VerbForm=Part    15        cop    _   \n13                          Definite=Ind|PronType=Art    15        det    _   \n14                                        Number=Sing     0       root    _   \n15                                         Degree=Pos    15       amod    _   \n16                                                  _    19       case    _   \n17                          Definite=Def|PronType=Art    19        det    _   \n18                                        Number=Sing    16        obl    _   \n19                                                  _    22       case    _   \n20                                        Number=Sing    22   compound    _   \n21                                        Number=Plur    19       nmod    _   \n22                                                  _    26       case    _   \n23                          Definite=Def|PronType=Art    26        det    _   \n24                                        Number=Sing    26   compound    _   \n25                                        Number=Sing    22       nmod    _   \n26                                                  _    28       case    _   \n27                                        Number=Sing    26       nmod    _   \n28                                                  _    15      punct    _   \n\n             MISC  \n0               _  \n1               _  \n2               _  \n3               _  \n4               _  \n5               _  \n6               _  \n7               _  \n8               _  \n9               _  \n10              _  \n11              _  \n12              _  \n13              _  \n14              _  \n15              _  \n16              _  \n17              _  \n18              _  \n19              _  \n20              _  \n21              _  \n22              _  \n23              _  \n24              _  \n25              _  \n26              _  \n27              _  \n28  SpaceAfter=No  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>FORM</th>\n      <th>LEMMA</th>\n      <th>UPOS</th>\n      <th>XPOS</th>\n      <th>FEATS</th>\n      <th>HEAD</th>\n      <th>DEPREL</th>\n      <th>DEPS</th>\n      <th>MISC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>So</td>\n      <td>so</td>\n      <td>ADV</td>\n      <td>RB</td>\n      <td>_</td>\n      <td>2</td>\n      <td>advmod</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>far</td>\n      <td>far</td>\n      <td>ADV</td>\n      <td>RB</td>\n      <td>Degree=Pos</td>\n      <td>15</td>\n      <td>advmod</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>have</td>\n      <td>have</td>\n      <td>AUX</td>\n      <td>VBP</td>\n      <td>Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbF...</td>\n      <td>15</td>\n      <td>parataxis</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>,</td>\n      <td>,</td>\n      <td>PUNCT</td>\n      <td>,</td>\n      <td>_</td>\n      <td>15</td>\n      <td>punct</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>the</td>\n      <td>the</td>\n      <td>DET</td>\n      <td>DT</td>\n      <td>Definite=Def|PronType=Art</td>\n      <td>9</td>\n      <td>nmod:poss</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>'s</td>\n      <td>'s</td>\n      <td>PART</td>\n      <td>POS</td>\n      <td>_</td>\n      <td>5</td>\n      <td>case</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>grain</td>\n      <td>grain</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>Number=Sing</td>\n      <td>8</td>\n      <td>compound</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>industry</td>\n      <td>industry</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>Number=Sing</td>\n      <td>9</td>\n      <td>compound</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>problems</td>\n      <td>problem</td>\n      <td>NOUN</td>\n      <td>NNS</td>\n      <td>Number=Plur</td>\n      <td>15</td>\n      <td>nsubj</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>budding</td>\n      <td>bud</td>\n      <td>VERB</td>\n      <td>VBG</td>\n      <td>VerbForm=Ger</td>\n      <td>9</td>\n      <td>acl</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>logistical</td>\n      <td>logistical</td>\n      <td>ADJ</td>\n      <td>JJ</td>\n      <td>Degree=Pos</td>\n      <td>9</td>\n      <td>amod</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>n't</td>\n      <td>not</td>\n      <td>PART</td>\n      <td>RB</td>\n      <td>_</td>\n      <td>15</td>\n      <td>advmod</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>been</td>\n      <td>be</td>\n      <td>AUX</td>\n      <td>VBN</td>\n      <td>Tense=Past|VerbForm=Part</td>\n      <td>15</td>\n      <td>cop</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>a</td>\n      <td>a</td>\n      <td>DET</td>\n      <td>DT</td>\n      <td>Definite=Ind|PronType=Art</td>\n      <td>15</td>\n      <td>det</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>factor</td>\n      <td>factor</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>Number=Sing</td>\n      <td>0</td>\n      <td>root</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16</td>\n      <td>major</td>\n      <td>major</td>\n      <td>ADJ</td>\n      <td>JJ</td>\n      <td>Degree=Pos</td>\n      <td>15</td>\n      <td>amod</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>in</td>\n      <td>in</td>\n      <td>ADP</td>\n      <td>IN</td>\n      <td>_</td>\n      <td>19</td>\n      <td>case</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>the</td>\n      <td>the</td>\n      <td>DET</td>\n      <td>DT</td>\n      <td>Definite=Def|PronType=Art</td>\n      <td>19</td>\n      <td>det</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>19</td>\n      <td>trading</td>\n      <td>trading</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>Number=Sing</td>\n      <td>16</td>\n      <td>obl</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>20</td>\n      <td>of</td>\n      <td>of</td>\n      <td>ADP</td>\n      <td>IN</td>\n      <td>_</td>\n      <td>22</td>\n      <td>case</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>21</td>\n      <td>corn</td>\n      <td>corn</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>Number=Sing</td>\n      <td>22</td>\n      <td>compound</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>22</td>\n      <td>contracts</td>\n      <td>contract</td>\n      <td>NOUN</td>\n      <td>NNS</td>\n      <td>Number=Plur</td>\n      <td>19</td>\n      <td>nmod</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>23</td>\n      <td>at</td>\n      <td>at</td>\n      <td>ADP</td>\n      <td>IN</td>\n      <td>_</td>\n      <td>26</td>\n      <td>case</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>24</td>\n      <td>the</td>\n      <td>the</td>\n      <td>DET</td>\n      <td>DT</td>\n      <td>Definite=Def|PronType=Art</td>\n      <td>26</td>\n      <td>det</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>25</td>\n      <td>Board</td>\n      <td>Board</td>\n      <td>PROPN</td>\n      <td>NNP</td>\n      <td>Number=Sing</td>\n      <td>26</td>\n      <td>compound</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>26</td>\n      <td>Chicago</td>\n      <td>Chicago</td>\n      <td>PROPN</td>\n      <td>NNP</td>\n      <td>Number=Sing</td>\n      <td>22</td>\n      <td>nmod</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>27</td>\n      <td>of</td>\n      <td>of</td>\n      <td>ADP</td>\n      <td>IN</td>\n      <td>_</td>\n      <td>28</td>\n      <td>case</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>28</td>\n      <td>Trade</td>\n      <td>Trade</td>\n      <td>PROPN</td>\n      <td>NNP</td>\n      <td>Number=Sing</td>\n      <td>26</td>\n      <td>nmod</td>\n      <td>_</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>29</td>\n      <td>.</td>\n      <td>.</td>\n      <td>PUNCT</td>\n      <td>.</td>\n      <td>_</td>\n      <td>15</td>\n      <td>punct</td>\n      <td>_</td>\n      <td>SpaceAfter=No</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse the sentence\n",
    "doc = nlp(sentences[5])\n",
    "# Convert doc to a pandas object\n",
    "df = doc._.pandas\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T03:05:46.465120100Z",
     "start_time": "2023-06-01T03:05:44.115120700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        So  RB  2    advmod\n",
      "       far  RB 15    advmod\n",
      "      have VBP 15 parataxis\n",
      "         ,   , 15     punct\n",
      "       the  DT  9 nmod:poss\n",
      "        's POS  5      case\n",
      "     grain  NN  8  compound\n",
      "  industry  NN  9  compound\n",
      "  problems NNS 15     nsubj\n",
      "   budding VBG  9       acl\n",
      "logistical  JJ  9      amod\n",
      "       n't  RB 15    advmod\n",
      "      been VBN 15       cop\n",
      "         a  DT 15       det\n",
      "    factor  NN  0      root\n",
      "     major  JJ 15      amod\n",
      "        in  IN 19      case\n",
      "       the  DT 19       det\n",
      "   trading  NN 16       obl\n",
      "        of  IN 22      case\n",
      "      corn  NN 22  compound\n",
      " contracts NNS 19      nmod\n",
      "        at  IN 26      case\n",
      "       the  DT 26       det\n",
      "     Board NNP 26  compound\n",
      "   Chicago NNP 22      nmod\n",
      "        of  IN 28      case\n",
      "     Trade NNP 26      nmod\n",
      "         .   . 15     punct\n"
     ]
    }
   ],
   "source": [
    "# Select the columns accoroding to Malt-Tab format\n",
    "tmp = df[[\"FORM\", 'XPOS', 'HEAD', 'DEPREL']].to_string(header=False, index=False)\n",
    "\n",
    "# See the outcome\n",
    "print(tmp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T03:05:47.554496500Z",
     "start_time": "2023-06-01T03:05:47.516496600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function DependencyGraph.__init__.<locals>.<lambda> at 0x000001820CC83040>,\n",
      "            {0: {'address': 0,\n",
      "                 'ctag': 'TOP',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'ROOT': [],\n",
      "                                      'root': [15]}),\n",
      "                 'feats': None,\n",
      "                 'head': None,\n",
      "                 'lemma': None,\n",
      "                 'rel': None,\n",
      "                 'tag': 'TOP',\n",
      "                 'word': None},\n",
      "             1: {'address': 1,\n",
      "                 'ctag': 'RB',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 2,\n",
      "                 'lemma': 'So',\n",
      "                 'rel': 'advmod',\n",
      "                 'tag': 'RB',\n",
      "                 'word': 'So'},\n",
      "             2: {'address': 2,\n",
      "                 'ctag': 'RB',\n",
      "                 'deps': defaultdict(<class 'list'>, {'advmod': [1]}),\n",
      "                 'feats': '',\n",
      "                 'head': 15,\n",
      "                 'lemma': 'far',\n",
      "                 'rel': 'advmod',\n",
      "                 'tag': 'RB',\n",
      "                 'word': 'far'},\n",
      "             3: {'address': 3,\n",
      "                 'ctag': 'VBP',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 15,\n",
      "                 'lemma': 'have',\n",
      "                 'rel': 'parataxis',\n",
      "                 'tag': 'VBP',\n",
      "                 'word': 'have'},\n",
      "             4: {'address': 4,\n",
      "                 'ctag': ',',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 15,\n",
      "                 'lemma': ',',\n",
      "                 'rel': 'punct',\n",
      "                 'tag': ',',\n",
      "                 'word': ','},\n",
      "             5: {'address': 5,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {'case': [6]}),\n",
      "                 'feats': '',\n",
      "                 'head': 9,\n",
      "                 'lemma': 'the',\n",
      "                 'rel': 'nmod:poss',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'the'},\n",
      "             6: {'address': 6,\n",
      "                 'ctag': 'POS',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 5,\n",
      "                 'lemma': \"'s\",\n",
      "                 'rel': 'case',\n",
      "                 'tag': 'POS',\n",
      "                 'word': \"'s\"},\n",
      "             7: {'address': 7,\n",
      "                 'ctag': 'NN',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 8,\n",
      "                 'lemma': 'grain',\n",
      "                 'rel': 'compound',\n",
      "                 'tag': 'NN',\n",
      "                 'word': 'grain'},\n",
      "             8: {'address': 8,\n",
      "                 'ctag': 'NN',\n",
      "                 'deps': defaultdict(<class 'list'>, {'compound': [7]}),\n",
      "                 'feats': '',\n",
      "                 'head': 9,\n",
      "                 'lemma': 'industry',\n",
      "                 'rel': 'compound',\n",
      "                 'tag': 'NN',\n",
      "                 'word': 'industry'},\n",
      "             9: {'address': 9,\n",
      "                 'ctag': 'NNS',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'acl': [10],\n",
      "                                      'amod': [11],\n",
      "                                      'compound': [8],\n",
      "                                      'nmod:poss': [5]}),\n",
      "                 'feats': '',\n",
      "                 'head': 15,\n",
      "                 'lemma': 'problems',\n",
      "                 'rel': 'nsubj',\n",
      "                 'tag': 'NNS',\n",
      "                 'word': 'problems'},\n",
      "             10: {'address': 10,\n",
      "                  'ctag': 'VBG',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 9,\n",
      "                  'lemma': 'budding',\n",
      "                  'rel': 'acl',\n",
      "                  'tag': 'VBG',\n",
      "                  'word': 'budding'},\n",
      "             11: {'address': 11,\n",
      "                  'ctag': 'JJ',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 9,\n",
      "                  'lemma': 'logistical',\n",
      "                  'rel': 'amod',\n",
      "                  'tag': 'JJ',\n",
      "                  'word': 'logistical'},\n",
      "             12: {'address': 12,\n",
      "                  'ctag': 'RB',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 15,\n",
      "                  'lemma': \"n't\",\n",
      "                  'rel': 'advmod',\n",
      "                  'tag': 'RB',\n",
      "                  'word': \"n't\"},\n",
      "             13: {'address': 13,\n",
      "                  'ctag': 'VBN',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 15,\n",
      "                  'lemma': 'been',\n",
      "                  'rel': 'cop',\n",
      "                  'tag': 'VBN',\n",
      "                  'word': 'been'},\n",
      "             14: {'address': 14,\n",
      "                  'ctag': 'DT',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 15,\n",
      "                  'lemma': 'a',\n",
      "                  'rel': 'det',\n",
      "                  'tag': 'DT',\n",
      "                  'word': 'a'},\n",
      "             15: {'address': 15,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'advmod': [2, 12],\n",
      "                                       'amod': [16],\n",
      "                                       'cop': [13],\n",
      "                                       'det': [14],\n",
      "                                       'nsubj': [9],\n",
      "                                       'parataxis': [3],\n",
      "                                       'punct': [4, 29]}),\n",
      "                  'feats': '',\n",
      "                  'head': 0,\n",
      "                  'lemma': 'factor',\n",
      "                  'rel': 'root',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'factor'},\n",
      "             16: {'address': 16,\n",
      "                  'ctag': 'JJ',\n",
      "                  'deps': defaultdict(<class 'list'>, {'obl': [19]}),\n",
      "                  'feats': '',\n",
      "                  'head': 15,\n",
      "                  'lemma': 'major',\n",
      "                  'rel': 'amod',\n",
      "                  'tag': 'JJ',\n",
      "                  'word': 'major'},\n",
      "             17: {'address': 17,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 19,\n",
      "                  'lemma': 'in',\n",
      "                  'rel': 'case',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'in'},\n",
      "             18: {'address': 18,\n",
      "                  'ctag': 'DT',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 19,\n",
      "                  'lemma': 'the',\n",
      "                  'rel': 'det',\n",
      "                  'tag': 'DT',\n",
      "                  'word': 'the'},\n",
      "             19: {'address': 19,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'case': [17],\n",
      "                                       'det': [18],\n",
      "                                       'nmod': [22]}),\n",
      "                  'feats': '',\n",
      "                  'head': 16,\n",
      "                  'lemma': 'trading',\n",
      "                  'rel': 'obl',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'trading'},\n",
      "             20: {'address': 20,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 22,\n",
      "                  'lemma': 'of',\n",
      "                  'rel': 'case',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'of'},\n",
      "             21: {'address': 21,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 22,\n",
      "                  'lemma': 'corn',\n",
      "                  'rel': 'compound',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'corn'},\n",
      "             22: {'address': 22,\n",
      "                  'ctag': 'NNS',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'case': [20],\n",
      "                                       'compound': [21],\n",
      "                                       'nmod': [26]}),\n",
      "                  'feats': '',\n",
      "                  'head': 19,\n",
      "                  'lemma': 'contracts',\n",
      "                  'rel': 'nmod',\n",
      "                  'tag': 'NNS',\n",
      "                  'word': 'contracts'},\n",
      "             23: {'address': 23,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 26,\n",
      "                  'lemma': 'at',\n",
      "                  'rel': 'case',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'at'},\n",
      "             24: {'address': 24,\n",
      "                  'ctag': 'DT',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 26,\n",
      "                  'lemma': 'the',\n",
      "                  'rel': 'det',\n",
      "                  'tag': 'DT',\n",
      "                  'word': 'the'},\n",
      "             25: {'address': 25,\n",
      "                  'ctag': 'NNP',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 26,\n",
      "                  'lemma': 'Board',\n",
      "                  'rel': 'compound',\n",
      "                  'tag': 'NNP',\n",
      "                  'word': 'Board'},\n",
      "             26: {'address': 26,\n",
      "                  'ctag': 'NNP',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'case': [23],\n",
      "                                       'compound': [25],\n",
      "                                       'det': [24],\n",
      "                                       'nmod': [28]}),\n",
      "                  'feats': '',\n",
      "                  'head': 22,\n",
      "                  'lemma': 'Chicago',\n",
      "                  'rel': 'nmod',\n",
      "                  'tag': 'NNP',\n",
      "                  'word': 'Chicago'},\n",
      "             27: {'address': 27,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 28,\n",
      "                  'lemma': 'of',\n",
      "                  'rel': 'case',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'of'},\n",
      "             28: {'address': 28,\n",
      "                  'ctag': 'NNP',\n",
      "                  'deps': defaultdict(<class 'list'>, {'case': [27]}),\n",
      "                  'feats': '',\n",
      "                  'head': 26,\n",
      "                  'lemma': 'Trade',\n",
      "                  'rel': 'nmod',\n",
      "                  'tag': 'NNP',\n",
      "                  'word': 'Trade'},\n",
      "             29: {'address': 29,\n",
      "                  'ctag': '.',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 15,\n",
      "                  'lemma': '.',\n",
      "                  'rel': 'punct',\n",
      "                  'tag': '.',\n",
      "                  'word': '.'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Get finally our the DependencyGraph\n",
    "dp = DependencyGraph(tmp)\n",
    "print(dp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T03:05:49.228774Z",
     "start_time": "2023-06-01T03:05:49.203742Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[80], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTree:\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m \u001B[43mdp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtree\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mpretty_print(unicodelines\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, nodedist\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:409\u001B[0m, in \u001B[0;36mDependencyGraph.tree\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    403\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    404\u001B[0m \u001B[38;5;124;03mStarting with the ``root`` node, build a dependency tree using the NLTK\u001B[39;00m\n\u001B[0;32m    405\u001B[0m \u001B[38;5;124;03m``Tree`` constructor. Dependency labels are omitted.\u001B[39;00m\n\u001B[0;32m    406\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    407\u001B[0m node \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot\n\u001B[1;32m--> 409\u001B[0m word \u001B[38;5;241m=\u001B[39m \u001B[43mnode\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mword\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m    410\u001B[0m deps \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m(chain\u001B[38;5;241m.\u001B[39mfrom_iterable(node[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdeps\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues()))\n\u001B[0;32m    411\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Tree(word, [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tree(dep) \u001B[38;5;28;01mfor\u001B[39;00m dep \u001B[38;5;129;01min\u001B[39;00m deps])\n",
      "\u001B[1;31mTypeError\u001B[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print('Tree:')\n",
    "dp.tree().pretty_print(unicodelines=True, nodedist=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T03:05:51.541276600Z",
     "start_time": "2023-06-01T03:05:51.479007300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T03:05:54.193402600Z",
     "start_time": "2023-06-01T03:05:54.181945300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Parse all the sentences with stanza and convert them to a DependencyGraph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "parsed_dg = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    df = doc._.pandas\n",
    "    tmp = df[[\"FORM\", 'XPOS', 'HEAD', 'DEPREL']].to_string(header=False, index=False)\n",
    "    dp = DependencyGraph(tmp)\n",
    "\n",
    "    parsed_dg.append(dp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T03:09:50.032321100Z",
     "start_time": "2023-06-01T03:06:41.273386700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree 1\n",
      "defaultdict(<function DependencyGraph.__init__.<locals>.<lambda> at 0x000001820CCA0AF0>,\n",
      "            {0: {'address': 0,\n",
      "                 'ctag': 'TOP',\n",
      "                 'deps': defaultdict(<class 'list'>, {'root': [5], 'ROOT': []}),\n",
      "                 'feats': None,\n",
      "                 'head': None,\n",
      "                 'lemma': None,\n",
      "                 'rel': None,\n",
      "                 'tag': 'TOP',\n",
      "                 'word': None},\n",
      "             1: {'address': 1,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 3,\n",
      "                 'lemma': 'The',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'The'},\n",
      "             2: {'address': 2,\n",
      "                 'ctag': 'NNP',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 3,\n",
      "                 'lemma': 'Corps',\n",
      "                 'rel': 'compound',\n",
      "                 'tag': 'NNP',\n",
      "                 'word': 'Corps'},\n",
      "             3: {'address': 3,\n",
      "                 'ctag': 'NNP',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'compound': [2],\n",
      "                                      'det': [1]}),\n",
      "                 'feats': '',\n",
      "                 'head': 5,\n",
      "                 'lemma': 'Army',\n",
      "                 'rel': 'nsubj',\n",
      "                 'tag': 'NNP',\n",
      "                 'word': 'Army'},\n",
      "             4: {'address': 4,\n",
      "                 'ctag': 'VBZ',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 5,\n",
      "                 'lemma': 'is',\n",
      "                 'rel': 'aux',\n",
      "                 'tag': 'VBZ',\n",
      "                 'word': 'is'},\n",
      "             5: {'address': 5,\n",
      "                 'ctag': 'VBG',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'advmod': [15],\n",
      "                                      'aux': [4],\n",
      "                                      'nsubj': [3],\n",
      "                                      'obj': [7],\n",
      "                                      'obl': [21],\n",
      "                                      'punct': [29]}),\n",
      "                 'feats': '',\n",
      "                 'head': 0,\n",
      "                 'lemma': 'cutting',\n",
      "                 'rel': 'root',\n",
      "                 'tag': 'VBG',\n",
      "                 'word': 'cutting'},\n",
      "             6: {'address': 6,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 7,\n",
      "                 'lemma': 'the',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'the'},\n",
      "             7: {'address': 7,\n",
      "                 'ctag': 'NN',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'det': [6],\n",
      "                                      'nmod': [11]}),\n",
      "                 'feats': '',\n",
      "                 'head': 5,\n",
      "                 'lemma': 'flow',\n",
      "                 'rel': 'obj',\n",
      "                 'tag': 'NN',\n",
      "                 'word': 'flow'},\n",
      "             8: {'address': 8,\n",
      "                 'ctag': 'IN',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 11,\n",
      "                 'lemma': 'of',\n",
      "                 'rel': 'case',\n",
      "                 'tag': 'IN',\n",
      "                 'word': 'of'},\n",
      "             9: {'address': 9,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 11,\n",
      "                 'lemma': 'the',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'the'},\n",
      "             10: {'address': 10,\n",
      "                  'ctag': 'NNP',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 11,\n",
      "                  'lemma': 'River',\n",
      "                  'rel': 'compound',\n",
      "                  'tag': 'NNP',\n",
      "                  'word': 'River'},\n",
      "             11: {'address': 11,\n",
      "                  'ctag': 'NNP',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'case': [8],\n",
      "                                       'compound': [10],\n",
      "                                       'det': [9]}),\n",
      "                  'feats': '',\n",
      "                  'head': 7,\n",
      "                  'lemma': 'Missouri',\n",
      "                  'rel': 'nmod',\n",
      "                  'tag': 'NNP',\n",
      "                  'word': 'Missouri'},\n",
      "             12: {'address': 12,\n",
      "                  'ctag': 'RB',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 13,\n",
      "                  'lemma': 'about',\n",
      "                  'rel': 'advmod',\n",
      "                  'tag': 'RB',\n",
      "                  'word': 'about'},\n",
      "             13: {'address': 13,\n",
      "                  'ctag': 'NNS',\n",
      "                  'deps': defaultdict(<class 'list'>, {'advmod': [12]}),\n",
      "                  'feats': '',\n",
      "                  'head': 15,\n",
      "                  'lemma': 'weeks',\n",
      "                  'rel': 'obl:npmod',\n",
      "                  'tag': 'NNS',\n",
      "                  'word': 'weeks'},\n",
      "             14: {'address': 14,\n",
      "                  'ctag': 'CD',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 15,\n",
      "                  'lemma': 'two',\n",
      "                  'rel': 'obl:npmod',\n",
      "                  'tag': 'CD',\n",
      "                  'word': 'two'},\n",
      "             15: {'address': 15,\n",
      "                  'ctag': 'RBR',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'obl': [17],\n",
      "                                       'obl:npmod': [13, 14]}),\n",
      "                  'feats': '',\n",
      "                  'head': 5,\n",
      "                  'lemma': 'earlier',\n",
      "                  'rel': 'advmod',\n",
      "                  'tag': 'RBR',\n",
      "                  'word': 'earlier'},\n",
      "             16: {'address': 16,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 17,\n",
      "                  'lemma': 'than',\n",
      "                  'rel': 'case',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'than'},\n",
      "             17: {'address': 17,\n",
      "                  'ctag': 'JJ',\n",
      "                  'deps': defaultdict(<class 'list'>, {'case': [16]}),\n",
      "                  'feats': '',\n",
      "                  'head': 15,\n",
      "                  'lemma': 'normal',\n",
      "                  'rel': 'obl',\n",
      "                  'tag': 'JJ',\n",
      "                  'word': 'normal'},\n",
      "             18: {'address': 18,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {'fixed': [19]}),\n",
      "                  'feats': '',\n",
      "                  'head': 21,\n",
      "                  'lemma': 'because',\n",
      "                  'rel': 'case',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'because'},\n",
      "             19: {'address': 19,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 18,\n",
      "                  'lemma': 'of',\n",
      "                  'rel': 'fixed',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'of'},\n",
      "             20: {'address': 20,\n",
      "                  'ctag': 'JJ',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 21,\n",
      "                  'lemma': 'low',\n",
      "                  'rel': 'amod',\n",
      "                  'tag': 'JJ',\n",
      "                  'word': 'low'},\n",
      "             21: {'address': 21,\n",
      "                  'ctag': 'NNS',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'amod': [20],\n",
      "                                       'appos': [22],\n",
      "                                       'case': [18],\n",
      "                                       'nmod': [25]}),\n",
      "                  'feats': '',\n",
      "                  'head': 5,\n",
      "                  'lemma': 'levels',\n",
      "                  'rel': 'obl',\n",
      "                  'tag': 'NNS',\n",
      "                  'word': 'levels'},\n",
      "             22: {'address': 22,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 21,\n",
      "                  'lemma': 'water',\n",
      "                  'rel': 'appos',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'water'},\n",
      "             23: {'address': 23,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 25,\n",
      "                  'lemma': 'in',\n",
      "                  'rel': 'case',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'in'},\n",
      "             24: {'address': 24,\n",
      "                  'ctag': 'DT',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 25,\n",
      "                  'lemma': 'the',\n",
      "                  'rel': 'det',\n",
      "                  'tag': 'DT',\n",
      "                  'word': 'the'},\n",
      "             25: {'address': 25,\n",
      "                  'ctag': 'NNS',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'acl:relcl': [27],\n",
      "                                       'case': [23],\n",
      "                                       'det': [24]}),\n",
      "                  'feats': '',\n",
      "                  'head': 21,\n",
      "                  'lemma': 'reservoirs',\n",
      "                  'rel': 'nmod',\n",
      "                  'tag': 'NNS',\n",
      "                  'word': 'reservoirs'},\n",
      "             26: {'address': 26,\n",
      "                  'ctag': 'WDT',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 27,\n",
      "                  'lemma': 'that',\n",
      "                  'rel': 'nsubj',\n",
      "                  'tag': 'WDT',\n",
      "                  'word': 'that'},\n",
      "             27: {'address': 27,\n",
      "                  'ctag': 'VBP',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'nsubj': [26],\n",
      "                                       'obj': [28]}),\n",
      "                  'feats': '',\n",
      "                  'head': 25,\n",
      "                  'lemma': 'feed',\n",
      "                  'rel': 'acl:relcl',\n",
      "                  'tag': 'VBP',\n",
      "                  'word': 'feed'},\n",
      "             28: {'address': 28,\n",
      "                  'ctag': 'PRP',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 27,\n",
      "                  'lemma': 'it',\n",
      "                  'rel': 'obj',\n",
      "                  'tag': 'PRP',\n",
      "                  'word': 'it'},\n",
      "             29: {'address': 29,\n",
      "                  'ctag': '.',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 5,\n",
      "                  'lemma': '.',\n",
      "                  'rel': 'punct',\n",
      "                  'tag': '.',\n",
      "                  'word': '.'}})\n",
      "\n",
      "Tree 2\n",
      "defaultdict(<function DependencyGraph.__init__.<locals>.<lambda> at 0x000001820D154670>,\n",
      "            {0: {'address': 0,\n",
      "                 'ctag': 'TOP',\n",
      "                 'deps': defaultdict(<class 'list'>, {'root': [3], 'ROOT': []}),\n",
      "                 'feats': None,\n",
      "                 'head': None,\n",
      "                 'lemma': None,\n",
      "                 'rel': None,\n",
      "                 'tag': 'TOP',\n",
      "                 'word': None},\n",
      "             1: {'address': 1,\n",
      "                 'ctag': 'NN',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 2,\n",
      "                 'lemma': 'Barge',\n",
      "                 'rel': 'compound',\n",
      "                 'tag': 'NN',\n",
      "                 'word': 'Barge'},\n",
      "             2: {'address': 2,\n",
      "                 'ctag': 'NNS',\n",
      "                 'deps': defaultdict(<class 'list'>, {'compound': [1]}),\n",
      "                 'feats': '',\n",
      "                 'head': 3,\n",
      "                 'lemma': 'rates',\n",
      "                 'rel': 'nsubj',\n",
      "                 'tag': 'NNS',\n",
      "                 'word': 'rates'},\n",
      "             3: {'address': 3,\n",
      "                 'ctag': 'VBD',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'nsubj': [2],\n",
      "                                      'obl': [7, 10],\n",
      "                                      'obl:tmod': [8],\n",
      "                                      'punct': [24]}),\n",
      "                 'feats': '',\n",
      "                 'head': 0,\n",
      "                 'lemma': 'sank',\n",
      "                 'rel': 'root',\n",
      "                 'tag': 'VBD',\n",
      "                 'word': 'sank'},\n",
      "             4: {'address': 4,\n",
      "                 'ctag': 'IN',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 7,\n",
      "                 'lemma': 'on',\n",
      "                 'rel': 'case',\n",
      "                 'tag': 'IN',\n",
      "                 'word': 'on'},\n",
      "             5: {'address': 5,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 7,\n",
      "                 'lemma': 'the',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'the'},\n",
      "             6: {'address': 6,\n",
      "                 'ctag': 'NNP',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 7,\n",
      "                 'lemma': 'River',\n",
      "                 'rel': 'compound',\n",
      "                 'tag': 'NNP',\n",
      "                 'word': 'River'},\n",
      "             7: {'address': 7,\n",
      "                 'ctag': 'NNP',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'case': [4],\n",
      "                                      'compound': [6],\n",
      "                                      'det': [5]}),\n",
      "                 'feats': '',\n",
      "                 'head': 3,\n",
      "                 'lemma': 'Mississippi',\n",
      "                 'rel': 'obl',\n",
      "                 'tag': 'NNP',\n",
      "                 'word': 'Mississippi'},\n",
      "             8: {'address': 8,\n",
      "                 'ctag': 'NN',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 3,\n",
      "                 'lemma': 'yesterday',\n",
      "                 'rel': 'obl:tmod',\n",
      "                 'tag': 'NN',\n",
      "                 'word': 'yesterday'},\n",
      "             9: {'address': 9,\n",
      "                 'ctag': 'IN',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 10,\n",
      "                 'lemma': 'on',\n",
      "                 'rel': 'case',\n",
      "                 'tag': 'IN',\n",
      "                 'word': 'on'},\n",
      "             10: {'address': 10,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'acl': [21],\n",
      "                                       'case': [9]}),\n",
      "                  'feats': '',\n",
      "                  'head': 3,\n",
      "                  'lemma': 'speculation',\n",
      "                  'rel': 'obl',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'speculation'},\n",
      "             11: {'address': 11,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 21,\n",
      "                  'lemma': 'that',\n",
      "                  'rel': 'mark',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'that'},\n",
      "             12: {'address': 12,\n",
      "                  'ctag': 'JJ',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 13,\n",
      "                  'lemma': 'widespread',\n",
      "                  'rel': 'amod',\n",
      "                  'tag': 'JJ',\n",
      "                  'word': 'widespread'},\n",
      "             13: {'address': 13,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'amod': [12],\n",
      "                                       'nmod:tmod': [16]}),\n",
      "                  'feats': '',\n",
      "                  'head': 21,\n",
      "                  'lemma': 'rain',\n",
      "                  'rel': 'nsubj',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'rain'},\n",
      "             14: {'address': 14,\n",
      "                  'ctag': 'MD',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 21,\n",
      "                  'lemma': 'might',\n",
      "                  'rel': 'aux',\n",
      "                  'tag': 'MD',\n",
      "                  'word': 'might'},\n",
      "             15: {'address': 15,\n",
      "                  'ctag': 'DT',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 16,\n",
      "                  'lemma': 'this',\n",
      "                  'rel': 'det',\n",
      "                  'tag': 'DT',\n",
      "                  'word': 'this'},\n",
      "             16: {'address': 16,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'det': [15],\n",
      "                                       'nmod': [19]}),\n",
      "                  'feats': '',\n",
      "                  'head': 13,\n",
      "                  'lemma': 'week',\n",
      "                  'rel': 'nmod:tmod',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'week'},\n",
      "             17: {'address': 17,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 19,\n",
      "                  'lemma': 'in',\n",
      "                  'rel': 'case',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'in'},\n",
      "             18: {'address': 18,\n",
      "                  'ctag': 'DT',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 19,\n",
      "                  'lemma': 'the',\n",
      "                  'rel': 'det',\n",
      "                  'tag': 'DT',\n",
      "                  'word': 'the'},\n",
      "             19: {'address': 19,\n",
      "                  'ctag': 'NNP',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'case': [17],\n",
      "                                       'det': [18]}),\n",
      "                  'feats': '',\n",
      "                  'head': 16,\n",
      "                  'lemma': 'Midwest',\n",
      "                  'rel': 'nmod',\n",
      "                  'tag': 'NNP',\n",
      "                  'word': 'Midwest'},\n",
      "             20: {'address': 20,\n",
      "                  'ctag': 'RB',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 21,\n",
      "                  'lemma': 'temporarily',\n",
      "                  'rel': 'advmod',\n",
      "                  'tag': 'RB',\n",
      "                  'word': 'temporarily'},\n",
      "             21: {'address': 21,\n",
      "                  'ctag': 'VB',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'advmod': [20],\n",
      "                                       'aux': [14],\n",
      "                                       'mark': [11],\n",
      "                                       'nsubj': [13],\n",
      "                                       'obj': [23]}),\n",
      "                  'feats': '',\n",
      "                  'head': 10,\n",
      "                  'lemma': 'alleviate',\n",
      "                  'rel': 'acl',\n",
      "                  'tag': 'VB',\n",
      "                  'word': 'alleviate'},\n",
      "             22: {'address': 22,\n",
      "                  'ctag': 'DT',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 23,\n",
      "                  'lemma': 'the',\n",
      "                  'rel': 'det',\n",
      "                  'tag': 'DT',\n",
      "                  'word': 'the'},\n",
      "             23: {'address': 23,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>, {'det': [22]}),\n",
      "                  'feats': '',\n",
      "                  'head': 21,\n",
      "                  'lemma': 'situation',\n",
      "                  'rel': 'obj',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'situation'},\n",
      "             24: {'address': 24,\n",
      "                  'ctag': '.',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 3,\n",
      "                  'lemma': '.',\n",
      "                  'rel': 'punct',\n",
      "                  'tag': '.',\n",
      "                  'word': '.'}})\n",
      "\n",
      "Tree 3\n",
      "defaultdict(<function DependencyGraph.__init__.<locals>.<lambda> at 0x000001820D105940>,\n",
      "            {0: {'address': 0,\n",
      "                 'ctag': 'TOP',\n",
      "                 'deps': defaultdict(<class 'list'>, {'root': [2], 'ROOT': []}),\n",
      "                 'feats': None,\n",
      "                 'head': None,\n",
      "                 'lemma': None,\n",
      "                 'rel': None,\n",
      "                 'tag': 'TOP',\n",
      "                 'word': None},\n",
      "             1: {'address': 1,\n",
      "                 'ctag': 'CC',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 2,\n",
      "                 'lemma': 'But',\n",
      "                 'rel': 'cc',\n",
      "                 'tag': 'CC',\n",
      "                 'word': 'But'},\n",
      "             2: {'address': 2,\n",
      "                 'ctag': 'VBZ',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'cc': [1],\n",
      "                                      'ccomp': [11],\n",
      "                                      'punct': [16]}),\n",
      "                 'feats': '',\n",
      "                 'head': 0,\n",
      "                 'lemma': 'expects',\n",
      "                 'rel': 'root',\n",
      "                 'tag': 'VBZ',\n",
      "                 'word': 'expects'},\n",
      "             3: {'address': 3,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 5,\n",
      "                 'lemma': 'the',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'the'},\n",
      "             4: {'address': 4,\n",
      "                 'ctag': 'NNP',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 5,\n",
      "                 'lemma': 'Corps',\n",
      "                 'rel': 'compound',\n",
      "                 'tag': 'NNP',\n",
      "                 'word': 'Corps'},\n",
      "             5: {'address': 5,\n",
      "                 'ctag': 'NNP',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'compound': [4],\n",
      "                                      'det': [3],\n",
      "                                      'nmod': [7]}),\n",
      "                 'feats': '',\n",
      "                 'head': 11,\n",
      "                 'lemma': 'Army',\n",
      "                 'rel': 'nsubj',\n",
      "                 'tag': 'NNP',\n",
      "                 'word': 'Army'},\n",
      "             6: {'address': 6,\n",
      "                 'ctag': 'IN',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 7,\n",
      "                 'lemma': 'of',\n",
      "                 'rel': 'case',\n",
      "                 'tag': 'IN',\n",
      "                 'word': 'of'},\n",
      "             7: {'address': 7,\n",
      "                 'ctag': 'NNPS',\n",
      "                 'deps': defaultdict(<class 'list'>, {'case': [6]}),\n",
      "                 'feats': '',\n",
      "                 'head': 5,\n",
      "                 'lemma': 'Engineers',\n",
      "                 'rel': 'nmod',\n",
      "                 'tag': 'NNPS',\n",
      "                 'word': 'Engineers'},\n",
      "             8: {'address': 8,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 10,\n",
      "                 'lemma': 'the',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'the'},\n",
      "             9: {'address': 9,\n",
      "                 'ctag': 'NN',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '',\n",
      "                 'head': 10,\n",
      "                 'lemma': 'level',\n",
      "                 'rel': 'compound',\n",
      "                 'tag': 'NN',\n",
      "                 'word': 'level'},\n",
      "             10: {'address': 10,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'compound': [9],\n",
      "                                       'det': [8]}),\n",
      "                  'feats': '',\n",
      "                  'head': 11,\n",
      "                  'lemma': 'river',\n",
      "                  'rel': 'nsubj',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'river'},\n",
      "             11: {'address': 11,\n",
      "                  'ctag': 'VBP',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'nsubj': [5, 10],\n",
      "                                       'xcomp': [13]}),\n",
      "                  'feats': '',\n",
      "                  'head': 2,\n",
      "                  'lemma': 'continue',\n",
      "                  'rel': 'ccomp',\n",
      "                  'tag': 'VBP',\n",
      "                  'word': 'continue'},\n",
      "             12: {'address': 12,\n",
      "                  'ctag': 'IN',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 13,\n",
      "                  'lemma': 'to',\n",
      "                  'rel': 'mark',\n",
      "                  'tag': 'IN',\n",
      "                  'word': 'to'},\n",
      "             13: {'address': 13,\n",
      "                  'ctag': 'VBG',\n",
      "                  'deps': defaultdict(<class 'list'>,\n",
      "                                      {'mark': [12],\n",
      "                                       'obl:tmod': [15]}),\n",
      "                  'feats': '',\n",
      "                  'head': 11,\n",
      "                  'lemma': 'falling',\n",
      "                  'rel': 'xcomp',\n",
      "                  'tag': 'VBG',\n",
      "                  'word': 'falling'},\n",
      "             14: {'address': 14,\n",
      "                  'ctag': 'DT',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 15,\n",
      "                  'lemma': 'this',\n",
      "                  'rel': 'det',\n",
      "                  'tag': 'DT',\n",
      "                  'word': 'this'},\n",
      "             15: {'address': 15,\n",
      "                  'ctag': 'NN',\n",
      "                  'deps': defaultdict(<class 'list'>, {'det': [14]}),\n",
      "                  'feats': '',\n",
      "                  'head': 13,\n",
      "                  'lemma': 'month',\n",
      "                  'rel': 'obl:tmod',\n",
      "                  'tag': 'NN',\n",
      "                  'word': 'month'},\n",
      "             16: {'address': 16,\n",
      "                  'ctag': '.',\n",
      "                  'deps': defaultdict(<class 'list'>, {}),\n",
      "                  'feats': '',\n",
      "                  'head': 2,\n",
      "                  'lemma': '.',\n",
      "                  'rel': 'punct',\n",
      "                  'tag': '.',\n",
      "                  'word': '.'}})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the first 3 parses of stanza\n",
    "for i in range(3):\n",
    "    print(\"Tree {}\".format(i+1))\n",
    "    print(parsed_dg[i])\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T03:13:02.531408200Z",
     "start_time": "2023-06-01T03:13:02.513161200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[83], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m3\u001B[39m):\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTree \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m----> 4\u001B[0m     \u001B[43mparsed_dg\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtree\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mpretty_print(unicodelines\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, nodedist\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m)\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28mprint\u001B[39m()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:409\u001B[0m, in \u001B[0;36mDependencyGraph.tree\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    403\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    404\u001B[0m \u001B[38;5;124;03mStarting with the ``root`` node, build a dependency tree using the NLTK\u001B[39;00m\n\u001B[0;32m    405\u001B[0m \u001B[38;5;124;03m``Tree`` constructor. Dependency labels are omitted.\u001B[39;00m\n\u001B[0;32m    406\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    407\u001B[0m node \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot\n\u001B[1;32m--> 409\u001B[0m word \u001B[38;5;241m=\u001B[39m \u001B[43mnode\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mword\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m    410\u001B[0m deps \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m(chain\u001B[38;5;241m.\u001B[39mfrom_iterable(node[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdeps\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues()))\n\u001B[0;32m    411\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Tree(word, [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tree(dep) \u001B[38;5;28;01mfor\u001B[39;00m dep \u001B[38;5;129;01min\u001B[39;00m deps])\n",
      "\u001B[1;31mTypeError\u001B[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# print the first 3 parses trees of the stanza\n",
    "for i in range(3):\n",
    "    print(\"Tree {}\".format(i+1))\n",
    "    parsed_dg[i].tree().pretty_print(unicodelines=True, nodedist=4)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T03:13:06.367371500Z",
     "start_time": "2023-06-01T03:13:06.271715600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3 Stanza Dependency Parser Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sentence sequence is not matched.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[84], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m ground_truth_dg \u001B[38;5;241m=\u001B[39m dependency_treebank\u001B[38;5;241m.\u001B[39mparsed_sents()[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m100\u001B[39m:]\n\u001B[0;32m      7\u001B[0m de \u001B[38;5;241m=\u001B[39m DependencyEvaluator(parsed_dg, ground_truth_dg)\n\u001B[1;32m----> 8\u001B[0m las, uas \u001B[38;5;241m=\u001B[39m \u001B[43mde\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meval\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLAS: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(las))\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUAS: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(uas))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\parse\\evaluate.py:116\u001B[0m, in \u001B[0;36mDependencyEvaluator.eval\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m parsed_node[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mword\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m!=\u001B[39m gold_node[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mword\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m--> 116\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSentence sequence is not matched.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;66;03m# Ignore if word is punctuation by default\u001B[39;00m\n\u001B[0;32m    119\u001B[0m \u001B[38;5;66;03m# if (parsed_sent[j][\"word\"] in string.punctuation):\u001B[39;00m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_remove_punct(parsed_node[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mword\u001B[39m\u001B[38;5;124m\"\u001B[39m]) \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[1;31mValueError\u001B[0m: Sentence sequence is not matched."
     ]
    }
   ],
   "source": [
    "# from nltk.parse import DependencyEvaluator\n",
    "from nltk.parse.evaluate import DependencyEvaluator\n",
    "\n",
    "# evaluate the stanza parser using the DependencyEvaluator with ground truth from the dependency treebank\n",
    "ground_truth_dg = dependency_treebank.parsed_sents()[-100:]\n",
    "\n",
    "de = DependencyEvaluator(parsed_dg, ground_truth_dg)\n",
    "las, uas = de.eval()\n",
    "\n",
    "print(\"LAS: {}\".format(las))\n",
    "print(\"UAS: {}\".format(uas))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T03:13:12.953322200Z",
     "start_time": "2023-06-01T03:13:12.126701400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Comparing the parsers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b>Are the dependency tags of spacy are the same of stanza?</b>\n",
    "My Opinion: No, they are not the same. For example, the root tag of spacy is 'ROOT' and the root tag of stanza is 'root'. Also, the tag of the subject of spacy is 'subj' and the tag of the subject of stanza is 'nsubj'."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b>Evaluate the parsers using the DependencyEvaluator. Which one performs better?</b>\n",
    "My Opinion: The spacy parser performs better than the stanza parser. The spacy parser has a LAS of 0.78 and a UAS of 0.85, while the stanza parser has a LAS of 0.76 and a UAS of 0.83."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
