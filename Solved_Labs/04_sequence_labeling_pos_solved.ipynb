{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sequence Labeling: Part-of-Speech Tagging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- Understanding:\n",
    "    - Relation between Classification and Sequence Labeling\n",
    "    - Relation between Ngram Modeling and Sequence Labeling\n",
    "    - General setting for Sequence Labeling\n",
    "    - Markov Model Tagging\n",
    "    - Universal Part-of-Speech Tags\n",
    "- Learning how to:\n",
    "    - perform POS-tagging using NLTK\n",
    "    - perform POS-tagging using spacy\n",
    "    - train and test (evaluate) POS-tagger with NLTK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recommended Reading\n",
    "\n",
    "- Dan Jurafsky and James H. Martin. [__Speech and Language Processing__ (SLP)](https://web.stanford.edu/~jurafsky/slp3/) (3rd ed. draft)\n",
    "- Steven Bird, Ewan Klein, and Edward Loper. [__Natural Language Processing with Python__ (NLTK)](https://www.nltk.org/book/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Covered Material\n",
    "\n",
    "- SLP\n",
    "    - [Chapter 8: Part-of-Speech Tagging (HMMs)](https://web.stanford.edu/~jurafsky/slp3/8.pdf)\n",
    "- NLTK\n",
    "    - [Chapter 5: Part of Speech Tagging](https://www.nltk.org/book/ch05.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Requirements\n",
    "\n",
    "- [spaCy](https://spacy.io/)\n",
    "- [NLTK](https://www.nltk.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sequence Labeling (Tagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Sequence Labeling and Classification\n",
    "[Classification](https://en.wikipedia.org/wiki/Statistical_classification) is the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations (or instances) whose category membership is known.\n",
    "\n",
    "[Sequence Labeling](https://en.wikipedia.org/wiki/Sequence_labeling) is a type of pattern recognition task that involves the algorithmic assignment of a categorical label to each member of a sequence of observed values. It is a sub-class of [structured (output) learning](https://en.wikipedia.org/wiki/Structured_prediction), since we are predicting a *sequence* object rather than a discrete or real value predicted in classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The problem can be treated as a set of independent classification tasks, one per member of the sequence;\n",
    "- **BUT!** performance is generally improved by making the optimal label for a given element dependent on the choices of nearby elements;\n",
    "\n",
    "Due to the complexity of the model and the interrelations of predicted variables the process of prediction using a trained model and of training itself is often computationally infeasible and [approximate inference](https://en.wikipedia.org/wiki/Approximate_inference) and learning methods are used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.2. Sequence Labeling and Ngram Modeling\n",
    "[Markov Chain](https://en.wikipedia.org/wiki/Markov_chain) is a stochastic model used to describe sequences. It is the simplest [Markov Model](https://en.wikipedia.org/wiki/Markov_model). In order to make inference tractable, a process that generated the sequence is assumed to have [Markov Property](https://en.wikipedia.org/wiki/Markov_property), i.e. future states depend only on the current state, not on the events that occurred before it. (An [ngram](https://en.wikipedia.org/wiki/N-gram) [language model](https://en.wikipedia.org/wiki/Language_model) is a $(n-1)$-order Markov Model.) \n",
    "\n",
    "In Statical Language Modeling, we are modeling *observed sequences* represented as Markov Chains. Since the states of the process are *observable*, we only need to compute __transition probabilities__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Sequence Labeling, we assume that *observed sequences* (__sentences__) have been generated by a Markov Process with *unobservable* (i.e. hidden) states (__labels__), i.e. [Hidden Markov Model](https://en.wikipedia.org/wiki/Hidden_Markov_model) (__HMM__). \n",
    "Since the states of the process are hidden and the output is observable, each state has a probability distribution over the possible output tokens, i.e. __emission probabilities__. \n",
    "\n",
    "Using these two probability distributions (__transition__ and __emission__), in sequence labeling, we are *inferring* the sequence of state transitions, given a sequence of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.3. The General Setting for Sequence Labeling\n",
    "\n",
    "- Create __training__ and __testing__ sets by tagging a certain amount of text by hand\n",
    "    - i.e. map each word in corpus to a tag\n",
    "- Train tagging model to extract generalizations from the annotated __training__ set\n",
    "- Evaluate the trained tagging model on the annotated __testing__ set\n",
    "- Use the trained tagging model too annotate new texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Part-of-speech tagging (POS tagging or PoS tagging or POST), also called grammatical tagging is the process of marking up a word in a text as corresponding to a particular part of speech, based on both its definition and its context.\n",
    "\n",
    "Tag Sets vary from corpus to corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.1. Universal Part of Speech Tags\n",
    "\n",
    "Universal POS-Tag Set represents a simplified and unified set of part-of-speech tags, that was proposed for the standardization across corpora and languages. \n",
    "The number of defined tags varies from 12 ([Petrov et al/Google/NLTK](https://github.com/slavpetrov/universal-pos-tags)) to 17 ([Universal Dependencies/spaCy](https://universaldependencies.org/u/pos/index.html), in *Italics*).\n",
    "\n",
    "\n",
    "\n",
    "| Tag  | Meaning | English Examples |\n",
    "|:-----|:--------|:-----------------|\n",
    "| __Open Class__ |||\n",
    "| NOUN | noun (common and proper) | year, home, costs, time, Africa\n",
    "| VERB | verb (all tenses and modes) | is, say, told, given, playing, would\n",
    "| ADJ  | adjective           | new, good, high, special, big, local\n",
    "| ADV  | adverb              | really, already, still, early, now\n",
    "| *PROPN* | proper noun (split from NOUN) | Africa\n",
    "| *INTJ*  | interjection (split from X) | oh, ouch\n",
    "| __Closed Class__ |||\n",
    "| DET  | determiner, article | the, a, some, most, every, no, which\n",
    "| PRON | pronoun             | he, their, her, its, my, I, us\n",
    "| ADP  | adposition\t(prepositions and postpositions) | on, of, at, with, by, into, under\n",
    "| NUM  | numeral             | twenty-four, fourth, 1991, 14:24\n",
    "| PRT (*PART*) | particles or other function words | at, on, out, over per, that, up, with\n",
    "| CONJ | conjunction         | and, or, but, if, while, although\n",
    "| *AUX* | auxiliary (split from VERB) | have, is, should\n",
    "| *CCONJ*  | coordinating conjunction (splits CONJ) | or, and\n",
    "| *SCONJ*  | subordinating conjunction (splits CONJ) | if, while\n",
    "| __Other__ |||\n",
    "| .    | punctuation marks   | . , ; !\n",
    "| X    | other               | foreign words, typos, abbreviations: ersatz, esprit, dunno, gr8, univeristy\n",
    "| *SYM* | symbols (split from X) | $, :) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Part-of-Speech Tagging with Spacy & NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.1. Part-of-Speech Tagging with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "ExecuteTime": {
     "end_time": "2023-07-21T19:22:47.063978900Z",
     "start_time": "2023-07-21T19:22:46.461979100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# nlp = spacy.load(\"en-core-web-sm\")\n",
    "\n",
    "# un-comment the lines below, if you get 'ModuleNotFoundError'\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "\n",
    "# let's print spaCy pipeline\n",
    "print([key for key, model in nlp.pipeline])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "ExecuteTime": {
     "end_time": "2023-05-25T17:58:39.851843600Z",
     "start_time": "2023-05-25T17:58:39.800843800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Oh', '.', 'I', 'have', 'seen', 'a', 'man', 'with', 'a', 'telescope', 'in', 'Antarctica', '.']\n",
      "['UH', '.', 'PRP', 'VBP', 'VBN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNP', '.']\n",
      "['INTJ', 'PUNCT', 'PRON', 'AUX', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "text = \"Oh. I have seen a man with a telescope in Antarctica.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "# tokens\n",
    "print([t.text for t in doc])\n",
    "\n",
    "# Fine grained POS-tags\n",
    "print([t.tag_ for t in doc])\n",
    "\n",
    "# Coarse POS-tags (from Universal POS Tag set)\n",
    "print([t.pos_ for t in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.2. Part-of-Speech Tagging with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "ExecuteTime": {
     "end_time": "2023-05-25T17:58:42.138246300Z",
     "start_time": "2023-05-25T17:58:39.830844300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "ExecuteTime": {
     "end_time": "2023-05-25T17:58:42.249246800Z",
     "start_time": "2023-05-25T17:58:42.141246800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Oh', '.', 'I', 'have', 'seen', 'a', 'man', 'with', 'a', 'telescope', 'in', 'Antarctica', '.']\n",
      "[('Oh', 'UH'), ('.', '.'), ('I', 'PRP'), ('have', 'VBP'), ('seen', 'VBN'), ('a', 'DT'), ('man', 'NN'), ('with', 'IN'), ('a', 'DT'), ('telescope', 'NN'), ('in', 'IN'), ('Antarctica', 'NNP'), ('.', '.')]\n",
      "[('Oh', 'X'), ('.', '.'), ('I', 'PRON'), ('have', 'VERB'), ('seen', 'VERB'), ('a', 'DET'), ('man', 'NOUN'), ('with', 'ADP'), ('a', 'DET'), ('telescope', 'NOUN'), ('in', 'ADP'), ('Antarctica', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "text = \"Oh. I have seen a man with a telescope in Antarctica.\"\n",
    "\n",
    "# tokenization\n",
    "tokens = nltk.word_tokenize(text)\n",
    "print(tokens)\n",
    "\n",
    "# POS-tagging (with WSJ Tags)\n",
    "print(nltk.pos_tag(tokens))\n",
    "\n",
    "# POS-tagging with Universal Tags\n",
    "print(nltk.pos_tag(tokens, tagset='universal'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.3. Training POS-Tagger with NLTK\n",
    "\n",
    "- Manually POS-tagged corpus\n",
    "- Sequence Labeling (Tagging) Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.3.1. Corpora for POS-Tagging\n",
    "NLTK provides several corpora, most of them are POS-tagged. We will use WSJ with universal tag set (automatically converted using internal mapping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-25T17:58:42.379249800Z",
     "start_time": "2023-05-25T17:58:42.251247700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download treebank\n",
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "ExecuteTime": {
     "end_time": "2023-05-25T17:58:42.439246800Z",
     "start_time": "2023-05-25T17:58:42.378251200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]]\n",
      "[[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "\n",
    "# WSJ POS-Tags\n",
    "print(treebank.tagged_sents()[:1])\n",
    "\n",
    "# Universal POS-Tags\n",
    "print(treebank.tagged_sents(tagset='universal')[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.3.2. NLTK Taggers\n",
    "\n",
    "NLTK provides several tagging algorithms, including \n",
    "\n",
    "- rule-based taggers\n",
    "    - Regular Expression Tagger: assigns tags to tokens by comparing their word strings to a series of regular expressions.\n",
    "\n",
    "- [Pre-Trained Taggers](http://www.nltk.org/api/nltk.tag.html)\n",
    "    - HunPoS\n",
    "    - Senna\n",
    "    - Stanford Tagger\n",
    "    \n",
    "- trainable taggers\n",
    "    - `Brill Tagger`: Brill's transformational rule-based tagger assigns an initial tag sequence to a text; and then appies an ordered list of transformational rules to correct the tags of individual tokens. Learns rules from corpus.\n",
    "    - [Greedy Averaged Perceptron](https://explosion.ai/blog/part-of-speech-pos-tagger-in-python)\n",
    "    - [TnT](http://acl.ldc.upenn.edu/A/A00/A00-1031.pdf)\n",
    "    - Hidden Markov Models\n",
    "    - Conditional Random Fields\n",
    "    - Sequential:\n",
    "        - Affix Tagger: A tagger that chooses a token's tag based on a leading or trailing substring of its word string.\n",
    "        - Ngram Tagger: A tagger that chooses a token's tag based on its word string and on the preceding _n_ word's tags.\n",
    "            - Unigram Tagger\n",
    "            - Bigram Tagger\n",
    "            - Trigram Tagger\n",
    "\n",
    "        - Classifier-based POS Tagger: A sequential tagger that uses a classifier to choose the tag for each token in a sentence.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.3.3. Testing a POS Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "ExecuteTime": {
     "end_time": "2023-05-25T17:58:46.047282100Z",
     "start_time": "2023-05-25T17:58:42.443247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 3914; Train: 3132; Test: 782\n"
     ]
    }
   ],
   "source": [
    "# Prepare Training & Test Splits as 80%/20%\n",
    "import math\n",
    "\n",
    "total_size = len(treebank.tagged_sents())\n",
    "train_indx = math.ceil(total_size * 0.8)\n",
    "trn_data = treebank.tagged_sents(tagset='universal')[:train_indx]\n",
    "tst_data = treebank.tagged_sents(tagset='universal')[train_indx:]\n",
    "\n",
    "print(\"Total: {}; Train: {}; Test: {}\".format(total_size, len(trn_data), len(tst_data)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Rule-based POS-Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "ExecuteTime": {
     "end_time": "2023-05-25T17:58:47.487249700Z",
     "start_time": "2023-05-25T17:58:46.055248400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n",
      "TAG  : [('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'NOUN'), (',', '.'), ('will', 'NOUN'), ('join', 'NOUN'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'NOUN'), ('a', 'DET'), ('nonexecutive', 'NOUN'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')]\n",
      "Accuracy: 0.5360\n"
     ]
    }
   ],
   "source": [
    "# rule-based tagging\n",
    "from nltk.tag import RegexpTagger\n",
    "\n",
    "# rules from NLTK adapted to Universal Tag Set & extended\n",
    "rules = [\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'),   # cardinal numbers\n",
    "    (r'(The|the|A|a|An|an)$', 'DET'),   # articles\n",
    "    (r'.*able$', 'ADJ'),                # adjectives\n",
    "    (r'.*ness$', 'NOUN'),               # nouns formed from adjectives\n",
    "    (r'.*ly$', 'ADV'),                  # adverbs\n",
    "    (r'.*s$', 'NOUN'),                  # plural nouns\n",
    "    (r'.*ing$', 'VERB'),                # gerunds\n",
    "    (r'.*ed$', 'VERB'),                 # past tense verbs\n",
    "    (r'[\\.,!\\?:;\\'\"]', '.'),            # punctuation (extension) \n",
    "    (r'.*', 'NOUN')                     # nouns (default)\n",
    "]\n",
    "\n",
    "re_tagger = RegexpTagger(rules)\n",
    "\n",
    "# tagging sentences in test set\n",
    "for s in treebank.sents()[:train_indx]:\n",
    "    print(\"INPUT: {}\".format(s))\n",
    "    print(\"TAG  : {}\".format(re_tagger.tag(s)))\n",
    "    break\n",
    "    \n",
    "# evaluation\n",
    "accuracy = re_tagger.accuracy(tst_data)\n",
    "\n",
    "print(\"Accuracy: {:6.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Exercise\n",
    "\n",
    "- Extend rule-set of RegexpTagger to handle close-class words (similar to punctuation & DET):\n",
    "\n",
    "    - prepositions (ADP)\n",
    "        - in, among, of, above, etc (add as many you want)\n",
    "    - particles (PRT)\n",
    "        - to, well, up, now, not (add as many you want)\n",
    "    - pronouns (PRON)\n",
    "        - I, you, he, she, it, they, we (add as many you want)\n",
    "    - conjunctions (CONJ)\n",
    "        - and, or, but, while, when, since (add as many you want)\n",
    "\n",
    "- Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "ExecuteTime": {
     "end_time": "2023-05-25T17:58:49.006248600Z",
     "start_time": "2023-05-25T17:58:47.491249100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n",
      "TAG  : [('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'NOUN'), (',', '.'), ('will', 'NOUN'), ('join', 'NOUN'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'NOUN'), ('a', 'DET'), ('nonexecutive', 'NOUN'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')]\n",
      "Accuracy: 0.6029\n"
     ]
    }
   ],
   "source": [
    "aug_rules = [\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'),   # cardinal numbers\n",
    "    (r'(The|the|A|a|An|an)$', 'DET'),   # articles\n",
    "    (r'.*able$', 'ADJ'),                # adjectives\n",
    "    (r'.*ness$', 'NOUN'),               # nouns formed from adjectives\n",
    "    (r'.*ly$', 'ADV'),                  # adverbs\n",
    "    (r'.*s$', 'NOUN'),                  # plural nouns\n",
    "    (r'.*ing$', 'VERB'),                # gerunds\n",
    "    (r'.*ed$', 'VERB'),                 # past tense verbs\n",
    "    (r'.*ed$', 'VERB'),                 # past tense verbs\n",
    "    (r'[\\.,!\\?:;\\'\"]', '.'),            # punctuation (extension) \n",
    "    (r'(In|in|Among|among|Above|above|as|As)$', 'ADP'),   # prepositions\n",
    "    (r'(to|To|well|Well|Up|up|Not|not|Now|now)$', 'PRT'),   # particles\n",
    "    (r'(I|you|You|He|he|She|she|It|it|They|they|We|we)$', 'PRON'),   # pronouns\n",
    "    (r'(and| or|But|but|while|since)$', 'CONJ'),# conjunctions\n",
    "    (r'.*', 'NOUN'),                     # nouns (default)\n",
    "]\n",
    "aug_re_tagger = RegexpTagger(aug_rules)\n",
    "\n",
    "# tagging sentences in test set\n",
    "for s in treebank.sents()[:train_indx]:\n",
    "    print(\"INPUT: {}\".format(s))\n",
    "    print(\"TAG  : {}\".format(re_tagger.tag(s)))\n",
    "    break\n",
    "\n",
    "accuracy = aug_re_tagger.accuracy(tst_data)\n",
    "\n",
    "print(\"Accuracy: {:6.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.3.4. Training HMM POS Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "ExecuteTime": {
     "end_time": "2023-05-25T17:58:52.926249600Z",
     "start_time": "2023-05-25T17:58:49.010248800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\tag\\hmm.py:336: RuntimeWarning: overflow encountered in cast\n",
      "  O[i, k] = self._output_logprob(si, self._symbols[k])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAG  : [('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')]\n",
      "PATH : ['NOUN', 'NOUN', '.', 'NUM', 'NOUN', 'ADJ', '.', 'VERB', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'NUM', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adnan\\anaconda3\\envs\\NLU-LABs-venv\\lib\\site-packages\\nltk\\tag\\hmm.py:364: RuntimeWarning: overflow encountered in cast\n",
      "  O[i, k] = self._output_logprob(si, self._symbols[k])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5135\n"
     ]
    }
   ],
   "source": [
    "# training hmm on treebank\n",
    "import nltk.tag.hmm as hmm\n",
    "\n",
    "hmm_model = hmm.HiddenMarkovModelTrainer()\n",
    "hmm_tagger = hmm_model.train(trn_data)\n",
    "\n",
    "# tagging sentences in test set\n",
    "for s in treebank.sents()[:train_indx]:\n",
    "    print(\"INPUT: {}\".format(s))\n",
    "    print(\"TAG  : {}\".format(hmm_tagger.tag(s)))\n",
    "    print(\"PATH : {}\".format(hmm_tagger.best_path(s)))\n",
    "    break\n",
    "    \n",
    "# evaluation\n",
    "accuracy = hmm_tagger.accuracy(tst_data)\n",
    "\n",
    "print(\"Accuracy: {:6.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lab Exercise: Comparative Evaluation of NLTK Tagger and Spacy Tagger\n",
    "\n",
    "\n",
    "Train and evaluate NgramTagger\n",
    "- experiment with different tagger parameters\n",
    "- some of them have *cut-off*\n",
    "\n",
    "Evaluate `spacy` POS-tags on the same test set\n",
    "- create mapping from spacy to NLTK POS-tags \n",
    "    - SPACY list https://universaldependencies.org/u/pos/index.html\n",
    "    - NLTK list https://github.com/slavpetrov/universal-pos-tags\n",
    "- convert output to the required format (see format above)\n",
    "    - flatten into a list\n",
    "- evaluate using `accuracy` from `nltk.metrics` \n",
    "    - [link](https://www.nltk.org/_modules/nltk/metrics/scores.html#accuracy)\n",
    "        \n",
    "**Dataset**: treebank <br>\n",
    "**Expected output**: NLTK: Accuracy SPACY: Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Importing libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank\n",
    "import en_core_web_sm\n",
    "from spacy.tokenizer import Tokenizer\n",
    "import math\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T18:13:21.682209700Z",
     "start_time": "2023-05-25T18:13:21.662214Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Loading data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('treebank')\n",
    "nltk.download('universal_tagset')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T18:14:51.231240Z",
     "start_time": "2023-05-25T18:14:51.210196800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "['we', \"don't\", 'do', 'that.']"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "# We overwrite the spacy tokenizer with a custom one, that split by whitespace only\n",
    "nlp.tokenizer = Tokenizer(nlp.vocab) # Tokenize by whitespace\n",
    "\n",
    "# Sanity check\n",
    "for id_sent, sent in enumerate(treebank.sents()):\n",
    "    doc = nlp(\" \".join(sent))\n",
    "    if len([x.text for x in doc]) != len(sent):\n",
    "        print(id_sent, sent)\n",
    "\n",
    "[x.text for x in nlp(\"we don't do that.\")]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T18:15:21.775734300Z",
     "start_time": "2023-05-25T18:14:52.626686600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split the treebank dataset into train and test sets\n",
    "dataset = treebank.tagged_sents(tagset='universal')\n",
    "trn_data = dataset[:3000]\n",
    "tst_data = dataset[3000:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Training and evaluating NgramTagger"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "from nltk import NgramTagger"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T18:15:55.251666Z",
     "start_time": "2023-05-25T18:15:55.230665900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "ngram_tagger = NgramTagger(1, trn_data)  # UnigramTagger\n",
    "accuracy_unigram = ngram_tagger.evaluate(tst_data)\n",
    "ngram_tagger_cutoff = NgramTagger(1, trn_data, cutoff=3)  # UnigramTagger with cut-off\n",
    "accuracy_unigram_cutoff = ngram_tagger_cutoff.evaluate(tst_data)\n",
    "\n",
    "ngram_tagger = NgramTagger(2, trn_data)  # BigramTagger\n",
    "accuracy_bigram = ngram_tagger.evaluate(tst_data)\n",
    "ngram_tagger = NgramTagger(2, trn_data, cutoff=3)  # BigramTagger with cut-off\n",
    "accuracy_bigram_cutoff = ngram_tagger.evaluate(tst_data)\n",
    "\n",
    "ngram_tagger = NgramTagger(3, trn_data)  # TrigramTagger\n",
    "accuracy_trigram = ngram_tagger.evaluate(tst_data)\n",
    "ngram_tagger = NgramTagger(3, trn_data, cutoff=3)  # TrigramTagger with cut-off\n",
    "accuracy_trigram_cutoff = ngram_tagger.evaluate(tst_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T18:16:19.623630800Z",
     "start_time": "2023-05-25T18:16:08.914240100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Tagger Accuracy:  0.8761493632635441\n",
      "Unigram Tagger Accuracy with cut-off:  0.7901575652924671\n",
      "\n",
      "Bigram Tagger Accuracy:  0.13580833153464278\n",
      "Bigram Tagger Accuracy with cut-off:  0.0584070796460177\n",
      "\n",
      "Trigram Tagger Accuracy:  0.07930066911288582\n",
      "Trigram Tagger Accuracy with cut-off:  0.03863587308439456\n"
     ]
    }
   ],
   "source": [
    "print(\"Unigram Tagger Accuracy: \", accuracy_unigram)\n",
    "print(\"Unigram Tagger Accuracy with cut-off: \", accuracy_unigram_cutoff)\n",
    "\n",
    "print(\"\\nBigram Tagger Accuracy: \", accuracy_bigram)\n",
    "print(\"Bigram Tagger Accuracy with cut-off: \", accuracy_bigram_cutoff)\n",
    "\n",
    "print(\"\\nTrigram Tagger Accuracy: \", accuracy_trigram)\n",
    "print(\"Trigram Tagger Accuracy with cut-off: \", accuracy_trigram_cutoff)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T18:16:56.042029900Z",
     "start_time": "2023-05-25T18:16:56.018031600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Evaluate `spacy` POS-tags on the same test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "ExecuteTime": {
     "end_time": "2023-05-25T18:17:47.401195800Z",
     "start_time": "2023-05-25T18:17:47.389195300Z"
    }
   },
   "outputs": [],
   "source": [
    "# spacy to nltk mapping dictionary\n",
    "mapping_spacy_to_NLTK = {\n",
    "    \"ADJ\": \"ADJ\",\n",
    "    \"ADP\": \"ADP\",\n",
    "    \"ADV\": \"ADV\",\n",
    "    \"AUX\": \"VERB\",\n",
    "    \"CCONJ\": \"CONJ\",\n",
    "    \"DET\": \"DET\",\n",
    "    \"INTJ\": \"X\",\n",
    "    \"NOUN\": \"NOUN\",\n",
    "    \"NUM\": \"NUM\",\n",
    "    \"PART\": \"PRT\",\n",
    "    \"PRON\": \"PRON\",\n",
    "    \"PROPN\": \"NOUN\",\n",
    "    \"PUNCT\": \".\",\n",
    "    \"SCONJ\": \"CONJ\",\n",
    "    \"SYM\": \"X\",\n",
    "    \"VERB\": \"VERB\",\n",
    "    \"X\": \"X\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# convert output to the required format: flatten into a list\n",
    "spacy_tags = []\n",
    "nltk_tags = []\n",
    "for sent in tst_data:\n",
    "    tokens = [token[0] for token in sent]\n",
    "    spacy_doc = nlp(\" \".join(tokens))\n",
    "    spacy_tags.extend([token.pos_ for token in spacy_doc])\n",
    "    nltk_tags.extend([mapping_spacy_to_NLTK[token.pos_] for token in spacy_doc])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T18:19:06.447279700Z",
     "start_time": "2023-05-25T18:19:00.063282500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacy Tags:  ['ADP', 'PROPN', 'PUNCT', 'DET', 'PROPN', 'NOUN', 'ADP', 'NUM', 'VERB', 'NOUN']\n",
      "NLTK Tags:  ['ADP', 'NOUN', '.', 'DET', 'NOUN', 'NOUN', 'ADP', 'NUM', 'VERB', 'NOUN']\n"
     ]
    }
   ],
   "source": [
    "print(\"Spacy Tags: \", spacy_tags[:10])\n",
    "print(\"NLTK Tags: \", nltk_tags[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T18:19:42.167310200Z",
     "start_time": "2023-05-25T18:19:42.152310800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Evaluate using `accuracy` from `nltk.metrics`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# evaluate using accuracy from nltk.metrics\n",
    "from nltk.metrics import accuracy\n",
    "\n",
    "spacy_accuracy = accuracy(nltk_tags, spacy_tags)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T18:22:43.925920100Z",
     "start_time": "2023-05-25T18:22:43.907920300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK: Accuracy\n",
      "Unigram Tagger:  0.8761493632635441\n",
      "Bigram Tagger:  0.13580833153464278\n",
      "Trigram Tagger:  0.07930066911288582\n",
      "\n",
      "Spacy: Accuracy\n",
      "Spacy Tagger:  0.6716598316425643\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy results for both NLTK and Spacy taggers\n",
    "print(\"NLTK: Accuracy\")\n",
    "print(\"Unigram Tagger: \", accuracy_unigram)\n",
    "print(\"Bigram Tagger: \", accuracy_bigram)\n",
    "print(\"Trigram Tagger: \", accuracy_trigram)\n",
    "\n",
    "print(\"\\nSpacy: Accuracy\")\n",
    "print(\"Spacy Tagger: \", spacy_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T18:23:01.833787900Z",
     "start_time": "2023-05-25T18:23:01.798755Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
